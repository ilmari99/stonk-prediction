{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import locale\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from stock_modules.stock_transform import (create_batch_xy,\n",
    "                                           create_transformer_onehot_xy)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from stock_modules.stock_ml import (create_transformer_model,\n",
    "                                    MultiSoftmaxLoss, MultiAccuracy)\n",
    "\n",
    "from invest_strategies import (calculate_optimal_invest_strategy,\n",
    "                               calculate_profit_on_invest_strategy,\n",
    "                               strategy_mask_from_direction_model)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "from stock_modules.stock_plot import plot_mask_and_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = locale.getpreferredencoding()\n",
    "DF_PATH = \"HEL_12-10-21to08-11-23.csv\"\n",
    "MODEL_SERIAL = None\n",
    "SELECTED_TICKERS_PATH = \"./TICKERS_TO_FOLLOW.json\"\n",
    "\n",
    "TEST_FRAC = 0.2\n",
    "PREDICT_PRICES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected tickers: \n",
      " ['ALBBV.HE', 'CGCBV.HE', 'EQV1V.HE', 'KNEBV.HE', 'ORNBV.HE', 'OLVAS.HE', 'DETEC.HE', 'PON1V.HE', 'ORNAV.HE', 'VALMT.HE', 'NESTE.HE', 'HUH1V.HE', 'REG1V.HE', 'VAIAS.HE']\n",
      "Dataframe columns: \n",
      " Index(['REG1V.HE', 'NESTE.HE', 'ORNBV.HE', 'KNEBV.HE', 'OLVAS.HE', 'HUH1V.HE',\n",
      "       'DETEC.HE', 'ORNAV.HE', 'CGCBV.HE', 'VAIAS.HE', 'ALBBV.HE', 'VALMT.HE',\n",
      "       'EQV1V.HE', 'PON1V.HE'],\n",
      "      dtype='object')\n",
      "Dataframe shape:  (4389, 14)\n",
      "Dataframe head: \n",
      "                       REG1V.HE   NESTE.HE   ORNBV.HE   KNEBV.HE   OLVAS.HE  \\\n",
      "date                                                                         \n",
      "2021-10-12 07:00:00  55.950001  41.820000  35.689999  60.220001  53.099998   \n",
      "2021-10-12 08:00:00  55.799999  41.720001  35.630001  60.419998  53.299999   \n",
      "\n",
      "                      HUH1V.HE  DETEC.HE   ORNAV.HE   CGCBV.HE   VAIAS.HE  \\\n",
      "date                                                                        \n",
      "2021-10-12 07:00:00  38.529999      23.0  38.049999  43.139999  46.150002   \n",
      "2021-10-12 08:00:00  38.560001      23.0  38.049999  43.500000  45.950001   \n",
      "\n",
      "                      ALBBV.HE   VALMT.HE   EQV1V.HE   PON1V.HE  \n",
      "date                                                             \n",
      "2021-10-12 07:00:00  28.700001  36.459999  24.850000  39.150002  \n",
      "2021-10-12 08:00:00  28.799999  36.599998  24.950001  39.200001  \n",
      "Index conversion: \n",
      " {0: 'REG1V.HE', 1: 'NESTE.HE', 2: 'ORNBV.HE', 3: 'KNEBV.HE', 4: 'OLVAS.HE', 5: 'HUH1V.HE', 6: 'DETEC.HE', 7: 'ORNAV.HE', 8: 'CGCBV.HE', 9: 'VAIAS.HE', 10: 'ALBBV.HE', 11: 'VALMT.HE', 12: 'EQV1V.HE', 13: 'PON1V.HE'}\n"
     ]
    }
   ],
   "source": [
    "SELECTED_TICKERS = json.load(open(SELECTED_TICKERS_PATH,\n",
    "                                  \"r\", encoding=ENCODING))\n",
    "DATAFRAME = pd.read_csv(DF_PATH, encoding=ENCODING)\n",
    "\n",
    "DATAFRAME.set_index(\"date\", inplace=True)\n",
    "HAS_TIMEDELTA = \"Time Delta\" in DATAFRAME.columns\n",
    "\n",
    "# ind transformation tells the label of each index in the np_arr_test\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(DATAFRAME.columns) if ticker in SELECTED_TICKERS}\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(IND_CONVERSION.values())}\n",
    "\n",
    "print(\"Selected tickers: \\n\", SELECTED_TICKERS)\n",
    "print(\"Dataframe columns: \\n\", DATAFRAME.columns)\n",
    "print(\"Dataframe shape: \", DATAFRAME.shape)\n",
    "print(\"Dataframe head: \\n\", DATAFRAME.head(2))\n",
    "print(f\"Index conversion: \\n {IND_CONVERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed df: \n",
      "                      REG1V.HE  NESTE.HE  ORNBV.HE  KNEBV.HE  OLVAS.HE  \\\n",
      "date                                                                    \n",
      "2021-10-12 07:00:00 -0.150002 -0.099998 -0.059998  0.199997  0.200001   \n",
      "2021-10-12 08:00:00 -0.150002 -0.099998 -0.059998  0.199997  0.200001   \n",
      "\n",
      "                     HUH1V.HE  DETEC.HE  ORNAV.HE  CGCBV.HE  VAIAS.HE  \\\n",
      "date                                                                    \n",
      "2021-10-12 07:00:00  0.030003       0.0       0.0  0.360001 -0.200001   \n",
      "2021-10-12 08:00:00  0.030003       0.0       0.0  0.360001 -0.200001   \n",
      "\n",
      "                     ALBBV.HE  VALMT.HE  EQV1V.HE  PON1V.HE  \n",
      "date                                                         \n",
      "2021-10-12 07:00:00  0.099998  0.139999       0.1  0.049999  \n",
      "2021-10-12 08:00:00  0.099998  0.139999       0.1  0.049999  \n",
      "Transformed df shape:  (4389, 14)\n"
     ]
    }
   ],
   "source": [
    "test_begin_idx = int(DATAFRAME.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "if PREDICT_PRICES:\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaler.fit(DATAFRAME.iloc[:test_begin_idx, :])\n",
    "    transformed_df = pd.DataFrame(scaler.transform(DATAFRAME), columns=DATAFRAME.columns, index=DATAFRAME.index)\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            return pd.DataFrame(scaler.inverse_transform(df), columns=df.columns, index=df.index)\n",
    "        elif isinstance(df, np.ndarray):\n",
    "            return scaler.inverse_transform(df)\n",
    "\n",
    "# If we are predicting the up/down, we create a dataframe where we subtract the previous value from the current value\n",
    "else:\n",
    "    # Do not diff the Time Delta column\n",
    "    df = DATAFRAME.copy()\n",
    "    if HAS_TIMEDELTA:\n",
    "        td_col = df[\"Time Delta\"]\n",
    "        df.drop(\"Time Delta\", axis=1, inplace=True)\n",
    "    transformed_df = df.diff()\n",
    "    # The first row is NaN, so lets copy the second row there\n",
    "    transformed_df.iloc[0, :] = transformed_df.iloc[1, :]\n",
    "    # Add back the Time Delta column\n",
    "    if HAS_TIMEDELTA:\n",
    "        transformed_df[\"Time Delta\"] = td_col\n",
    "        # Make Time Delta the first column\n",
    "        cols = transformed_df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        transformed_df = transformed_df[cols]\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        return df\n",
    "\n",
    "print(\"Transformed df: \\n\", transformed_df.head(2))\n",
    "print(\"Transformed df shape: \", transformed_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "82/82 [==============================] - 55s 560ms/step - loss: 2.3403 - multi_accuracy_1: 0.3325 - val_loss: 1.6939 - val_multi_accuracy_1: 0.3425\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 45s 555ms/step - loss: 1.7888 - multi_accuracy_1: 0.3344 - val_loss: 1.6803 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 44s 535ms/step - loss: 1.7882 - multi_accuracy_1: 0.3285 - val_loss: 1.6785 - val_multi_accuracy_1: 0.3265\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 45s 553ms/step - loss: 1.7872 - multi_accuracy_1: 0.3243 - val_loss: 1.6804 - val_multi_accuracy_1: 0.3238\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 47s 572ms/step - loss: 1.7866 - multi_accuracy_1: 0.3218 - val_loss: 1.6781 - val_multi_accuracy_1: 0.3212\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 43s 527ms/step - loss: 1.7870 - multi_accuracy_1: 0.3201 - val_loss: 1.6863 - val_multi_accuracy_1: 0.3201\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 46s 566ms/step - loss: 1.7871 - multi_accuracy_1: 0.3198 - val_loss: 1.6813 - val_multi_accuracy_1: 0.3199\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 47s 574ms/step - loss: 1.7865 - multi_accuracy_1: 0.3187 - val_loss: 1.6808 - val_multi_accuracy_1: 0.3188\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 46s 561ms/step - loss: 1.7864 - multi_accuracy_1: 0.3179 - val_loss: 1.6778 - val_multi_accuracy_1: 0.3181\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 47s 569ms/step - loss: 1.7856 - multi_accuracy_1: 0.3174 - val_loss: 1.6744 - val_multi_accuracy_1: 0.3170\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 46s 558ms/step - loss: 1.7853 - multi_accuracy_1: 0.3164 - val_loss: 1.6767 - val_multi_accuracy_1: 0.3163\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 46s 556ms/step - loss: 1.7854 - multi_accuracy_1: 0.3159 - val_loss: 1.6802 - val_multi_accuracy_1: 0.3159\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 46s 564ms/step - loss: 1.7850 - multi_accuracy_1: 0.3154 - val_loss: 1.6830 - val_multi_accuracy_1: 0.3156\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 44s 543ms/step - loss: 1.7850 - multi_accuracy_1: 0.3151 - val_loss: 1.6793 - val_multi_accuracy_1: 0.3149\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 44s 535ms/step - loss: 1.7849 - multi_accuracy_1: 0.3145 - val_loss: 1.6816 - val_multi_accuracy_1: 0.3144\n",
      "28/28 [==============================] - 5s 177ms/step - loss: 1.6631 - multi_accuracy_1: 0.3143\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 57s 573ms/step - loss: 3.1155 - multi_accuracy_1: 0.3145 - val_loss: 2.8270 - val_multi_accuracy_1: 0.3154\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 46s 564ms/step - loss: 3.0000 - multi_accuracy_1: 0.3153 - val_loss: 2.8263 - val_multi_accuracy_1: 0.3160\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 46s 559ms/step - loss: 2.9970 - multi_accuracy_1: 0.3158 - val_loss: 2.8276 - val_multi_accuracy_1: 0.3165\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 48s 588ms/step - loss: 2.9987 - multi_accuracy_1: 0.3162 - val_loss: 2.8260 - val_multi_accuracy_1: 0.3169\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 47s 577ms/step - loss: 2.9940 - multi_accuracy_1: 0.3166 - val_loss: 2.8282 - val_multi_accuracy_1: 0.3172\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 39s 478ms/step - loss: 2.9892 - multi_accuracy_1: 0.3167 - val_loss: 2.8280 - val_multi_accuracy_1: 0.3173\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 35s 421ms/step - loss: 2.9854 - multi_accuracy_1: 0.3169 - val_loss: 2.8230 - val_multi_accuracy_1: 0.3174\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 39s 476ms/step - loss: 2.9975 - multi_accuracy_1: 0.3169 - val_loss: 2.8251 - val_multi_accuracy_1: 0.3173\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 32s 388ms/step - loss: 2.9978 - multi_accuracy_1: 0.3167 - val_loss: 2.8242 - val_multi_accuracy_1: 0.3171\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 33s 406ms/step - loss: 2.9895 - multi_accuracy_1: 0.3166 - val_loss: 2.8239 - val_multi_accuracy_1: 0.3170\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 42s 518ms/step - loss: 2.9933 - multi_accuracy_1: 0.3165 - val_loss: 2.8209 - val_multi_accuracy_1: 0.3168\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 46s 564ms/step - loss: 2.9939 - multi_accuracy_1: 0.3164 - val_loss: 2.8222 - val_multi_accuracy_1: 0.3168\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 36s 442ms/step - loss: 2.9986 - multi_accuracy_1: 0.3163 - val_loss: 2.8232 - val_multi_accuracy_1: 0.3167\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 44s 544ms/step - loss: 3.0083 - multi_accuracy_1: 0.3162 - val_loss: 2.8236 - val_multi_accuracy_1: 0.3165\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 44s 541ms/step - loss: 3.0068 - multi_accuracy_1: 0.3160 - val_loss: 2.8274 - val_multi_accuracy_1: 0.3164\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 43s 530ms/step - loss: 3.0211 - multi_accuracy_1: 0.3159 - val_loss: 2.8205 - val_multi_accuracy_1: 0.3161\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 45s 553ms/step - loss: 3.0554 - multi_accuracy_1: 0.3157 - val_loss: 2.8210 - val_multi_accuracy_1: 0.3159\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 41s 502ms/step - loss: 3.0697 - multi_accuracy_1: 0.3155 - val_loss: 2.8272 - val_multi_accuracy_1: 0.3158\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 33s 400ms/step - loss: 3.1644 - multi_accuracy_1: 0.3154 - val_loss: 2.8226 - val_multi_accuracy_1: 0.3155\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 30s 372ms/step - loss: 3.3451 - multi_accuracy_1: 0.3152 - val_loss: 3.1867 - val_multi_accuracy_1: 0.3155\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 44s 536ms/step - loss: 3.3277 - multi_accuracy_1: 0.3151 - val_loss: 2.8308 - val_multi_accuracy_1: 0.3152\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 2.9114 - multi_accuracy_1: 0.3154\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 50s 494ms/step - loss: 1.3114 - multi_accuracy_1: 0.3158 - val_loss: 1.1112 - val_multi_accuracy_1: 0.3159\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 33s 401ms/step - loss: 1.0981 - multi_accuracy_1: 0.3163 - val_loss: 1.1037 - val_multi_accuracy_1: 0.3163\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 32s 385ms/step - loss: 1.0965 - multi_accuracy_1: 0.3166 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3166\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 32s 395ms/step - loss: 1.0962 - multi_accuracy_1: 0.3168 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3167\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 35s 431ms/step - loss: 1.0950 - multi_accuracy_1: 0.3170 - val_loss: 1.1028 - val_multi_accuracy_1: 0.3168\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 42s 512ms/step - loss: 1.0950 - multi_accuracy_1: 0.3170 - val_loss: 1.1014 - val_multi_accuracy_1: 0.3169\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 34s 419ms/step - loss: 1.0946 - multi_accuracy_1: 0.3170 - val_loss: 1.1026 - val_multi_accuracy_1: 0.3169\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 40s 491ms/step - loss: 1.0937 - multi_accuracy_1: 0.3171 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3169\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 42s 506ms/step - loss: 1.0935 - multi_accuracy_1: 0.3170 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3169\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 37s 448ms/step - loss: 1.0936 - multi_accuracy_1: 0.3170 - val_loss: 1.0983 - val_multi_accuracy_1: 0.3170\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 42s 512ms/step - loss: 1.0929 - multi_accuracy_1: 0.3170 - val_loss: 1.0971 - val_multi_accuracy_1: 0.3170\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 44s 536ms/step - loss: 1.0923 - multi_accuracy_1: 0.3170 - val_loss: 1.0965 - val_multi_accuracy_1: 0.3170\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 44s 535ms/step - loss: 1.0925 - multi_accuracy_1: 0.3170 - val_loss: 1.1032 - val_multi_accuracy_1: 0.3170\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 43s 519ms/step - loss: 1.0915 - multi_accuracy_1: 0.3170 - val_loss: 1.1004 - val_multi_accuracy_1: 0.3169\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 45s 550ms/step - loss: 1.0919 - multi_accuracy_1: 0.3169 - val_loss: 1.0984 - val_multi_accuracy_1: 0.3168\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 44s 542ms/step - loss: 1.0917 - multi_accuracy_1: 0.3169 - val_loss: 1.0962 - val_multi_accuracy_1: 0.3168\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 38s 459ms/step - loss: 1.0919 - multi_accuracy_1: 0.3169 - val_loss: 1.0971 - val_multi_accuracy_1: 0.3169\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 31s 377ms/step - loss: 1.0917 - multi_accuracy_1: 0.3169 - val_loss: 1.0973 - val_multi_accuracy_1: 0.3169\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 31s 382ms/step - loss: 1.0917 - multi_accuracy_1: 0.3170 - val_loss: 1.0965 - val_multi_accuracy_1: 0.3170\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 35s 424ms/step - loss: 1.0917 - multi_accuracy_1: 0.3171 - val_loss: 1.0963 - val_multi_accuracy_1: 0.3171\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 39s 473ms/step - loss: 1.0916 - multi_accuracy_1: 0.3171 - val_loss: 1.0994 - val_multi_accuracy_1: 0.3170\n",
      "28/28 [==============================] - 5s 169ms/step - loss: 1.1011 - multi_accuracy_1: 0.3171\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 28s 267ms/step - loss: 3.2895 - multi_accuracy_1: 0.3173 - val_loss: 3.1055 - val_multi_accuracy_1: 0.3173\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 22s 265ms/step - loss: 3.2209 - multi_accuracy_1: 0.3177 - val_loss: 3.0999 - val_multi_accuracy_1: 0.3176\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 18s 224ms/step - loss: 3.2256 - multi_accuracy_1: 0.3180 - val_loss: 3.0895 - val_multi_accuracy_1: 0.3179\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 3.2292 - multi_accuracy_1: 0.3183 - val_loss: 3.0656 - val_multi_accuracy_1: 0.3183\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 17s 213ms/step - loss: 3.2365 - multi_accuracy_1: 0.3186 - val_loss: 3.0813 - val_multi_accuracy_1: 0.3186\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 22s 264ms/step - loss: 3.2239 - multi_accuracy_1: 0.3189 - val_loss: 3.0981 - val_multi_accuracy_1: 0.3189\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 3.2396 - multi_accuracy_1: 0.3192 - val_loss: 3.1004 - val_multi_accuracy_1: 0.3192\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 19s 237ms/step - loss: 3.2300 - multi_accuracy_1: 0.3195 - val_loss: 3.1032 - val_multi_accuracy_1: 0.3194\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 21s 261ms/step - loss: 3.2313 - multi_accuracy_1: 0.3198 - val_loss: 3.1202 - val_multi_accuracy_1: 0.3197\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 3.0737 - multi_accuracy_1: 0.3197\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 30s 296ms/step - loss: 2.2089 - multi_accuracy_1: 0.3198 - val_loss: 1.1140 - val_multi_accuracy_1: 0.3199\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 23s 278ms/step - loss: 1.0990 - multi_accuracy_1: 0.3201 - val_loss: 1.1097 - val_multi_accuracy_1: 0.3202\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 22s 272ms/step - loss: 1.0981 - multi_accuracy_1: 0.3204 - val_loss: 1.1096 - val_multi_accuracy_1: 0.3204\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 23s 277ms/step - loss: 1.0978 - multi_accuracy_1: 0.3207 - val_loss: 1.1100 - val_multi_accuracy_1: 0.3207\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 22s 271ms/step - loss: 1.0977 - multi_accuracy_1: 0.3209 - val_loss: 1.1066 - val_multi_accuracy_1: 0.3209\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 21s 254ms/step - loss: 1.0974 - multi_accuracy_1: 0.3211 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3211\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 21s 259ms/step - loss: 1.0974 - multi_accuracy_1: 0.3213 - val_loss: 1.1098 - val_multi_accuracy_1: 0.3213\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 23s 277ms/step - loss: 1.0972 - multi_accuracy_1: 0.3215 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3215\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 21s 253ms/step - loss: 1.0968 - multi_accuracy_1: 0.3217 - val_loss: 1.1078 - val_multi_accuracy_1: 0.3217\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 16s 200ms/step - loss: 1.0967 - multi_accuracy_1: 0.3219 - val_loss: 1.1072 - val_multi_accuracy_1: 0.3220\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 1.0965 - multi_accuracy_1: 0.3222 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3222\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 21s 256ms/step - loss: 1.0962 - multi_accuracy_1: 0.3224 - val_loss: 1.1022 - val_multi_accuracy_1: 0.3224\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 21s 258ms/step - loss: 1.0958 - multi_accuracy_1: 0.3226 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3227\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 1.0946 - multi_accuracy_1: 0.3229 - val_loss: 1.1004 - val_multi_accuracy_1: 0.3229\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 1.0943 - multi_accuracy_1: 0.3232 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3232\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0938 - multi_accuracy_1: 0.3234 - val_loss: 1.1087 - val_multi_accuracy_1: 0.3235\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 1.0933 - multi_accuracy_1: 0.3237 - val_loss: 1.0971 - val_multi_accuracy_1: 0.3238\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 1.0929 - multi_accuracy_1: 0.3240 - val_loss: 1.1032 - val_multi_accuracy_1: 0.3241\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 18s 217ms/step - loss: 1.0922 - multi_accuracy_1: 0.3243 - val_loss: 1.1010 - val_multi_accuracy_1: 0.3244\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 1.0922 - multi_accuracy_1: 0.3246 - val_loss: 1.0980 - val_multi_accuracy_1: 0.3247\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 20s 247ms/step - loss: 1.0927 - multi_accuracy_1: 0.3250 - val_loss: 1.0998 - val_multi_accuracy_1: 0.3251\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 22s 265ms/step - loss: 1.0919 - multi_accuracy_1: 0.3254 - val_loss: 1.0984 - val_multi_accuracy_1: 0.3254\n",
      "28/28 [==============================] - 2s 74ms/step - loss: 1.1009 - multi_accuracy_1: 0.3255\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 23s 211ms/step - loss: 3.2465 - multi_accuracy_1: 0.3256 - val_loss: 3.4684 - val_multi_accuracy_1: 0.3257\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 18s 224ms/step - loss: 3.7892 - multi_accuracy_1: 0.3256 - val_loss: 3.4654 - val_multi_accuracy_1: 0.3257\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 16s 198ms/step - loss: 3.8054 - multi_accuracy_1: 0.3256 - val_loss: 3.4657 - val_multi_accuracy_1: 0.3257\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 21s 262ms/step - loss: 3.7801 - multi_accuracy_1: 0.3255 - val_loss: 3.4647 - val_multi_accuracy_1: 0.3256\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 18s 215ms/step - loss: 3.8048 - multi_accuracy_1: 0.3255 - val_loss: 3.4658 - val_multi_accuracy_1: 0.3256\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 3.7417 - multi_accuracy_1: 0.3254 - val_loss: 3.4653 - val_multi_accuracy_1: 0.3255\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 16s 197ms/step - loss: 3.7744 - multi_accuracy_1: 0.3254 - val_loss: 3.4652 - val_multi_accuracy_1: 0.3255\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 16s 196ms/step - loss: 3.7949 - multi_accuracy_1: 0.3253 - val_loss: 3.4627 - val_multi_accuracy_1: 0.3254\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 3.7780 - multi_accuracy_1: 0.3253 - val_loss: 3.4643 - val_multi_accuracy_1: 0.3254\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 3.7757 - multi_accuracy_1: 0.3252 - val_loss: 3.4641 - val_multi_accuracy_1: 0.3253\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 16s 190ms/step - loss: 3.7933 - multi_accuracy_1: 0.3251 - val_loss: 3.4607 - val_multi_accuracy_1: 0.3252\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 3.8225 - multi_accuracy_1: 0.3251 - val_loss: 3.4628 - val_multi_accuracy_1: 0.3251\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 16s 198ms/step - loss: 3.8259 - multi_accuracy_1: 0.3250 - val_loss: 3.4604 - val_multi_accuracy_1: 0.3250\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 16s 196ms/step - loss: 3.8215 - multi_accuracy_1: 0.3249 - val_loss: 3.4635 - val_multi_accuracy_1: 0.3250\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 19s 234ms/step - loss: 3.8246 - multi_accuracy_1: 0.3248 - val_loss: 3.4638 - val_multi_accuracy_1: 0.3249\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 16s 190ms/step - loss: 3.8268 - multi_accuracy_1: 0.3248 - val_loss: 3.4581 - val_multi_accuracy_1: 0.3248\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 16s 191ms/step - loss: 3.8317 - multi_accuracy_1: 0.3247 - val_loss: 3.4646 - val_multi_accuracy_1: 0.3247\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 3.8250 - multi_accuracy_1: 0.3246 - val_loss: 3.4655 - val_multi_accuracy_1: 0.3247\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 3.8334 - multi_accuracy_1: 0.3246 - val_loss: 3.4688 - val_multi_accuracy_1: 0.3247\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 22s 270ms/step - loss: 3.8338 - multi_accuracy_1: 0.3245 - val_loss: 3.4626 - val_multi_accuracy_1: 0.3246\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 21s 253ms/step - loss: 3.7497 - multi_accuracy_1: 0.3245 - val_loss: 3.4679 - val_multi_accuracy_1: 0.3245\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 3.3746 - multi_accuracy_1: 0.3246\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 15s 140ms/step - loss: 1.6327 - multi_accuracy_1: 0.3248 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3247\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 12s 144ms/step - loss: 1.0976 - multi_accuracy_1: 0.3249 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3249\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 12s 142ms/step - loss: 1.0969 - multi_accuracy_1: 0.3251 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3251\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 12s 142ms/step - loss: 1.0966 - multi_accuracy_1: 0.3252 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3252\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 11s 140ms/step - loss: 1.0962 - multi_accuracy_1: 0.3254 - val_loss: 1.1041 - val_multi_accuracy_1: 0.3253\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 1.0959 - multi_accuracy_1: 0.3255 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3255\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 1.0957 - multi_accuracy_1: 0.3256 - val_loss: 1.1014 - val_multi_accuracy_1: 0.3256\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 12s 140ms/step - loss: 1.0957 - multi_accuracy_1: 0.3258 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3257\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 1.0956 - multi_accuracy_1: 0.3259 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3259\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 10s 119ms/step - loss: 1.0954 - multi_accuracy_1: 0.3260 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3260\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 11s 135ms/step - loss: 1.0951 - multi_accuracy_1: 0.3262 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3261\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 12s 143ms/step - loss: 1.0947 - multi_accuracy_1: 0.3263 - val_loss: 1.1008 - val_multi_accuracy_1: 0.3263\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 8s 104ms/step - loss: 1.0940 - multi_accuracy_1: 0.3264 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3264\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 11s 136ms/step - loss: 1.0936 - multi_accuracy_1: 0.3265 - val_loss: 1.0977 - val_multi_accuracy_1: 0.3265\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 1.0930 - multi_accuracy_1: 0.3267 - val_loss: 1.0988 - val_multi_accuracy_1: 0.3267\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 1.0925 - multi_accuracy_1: 0.3269 - val_loss: 1.1020 - val_multi_accuracy_1: 0.3269\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 12s 142ms/step - loss: 1.0924 - multi_accuracy_1: 0.3270 - val_loss: 1.0973 - val_multi_accuracy_1: 0.3270\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 1.0917 - multi_accuracy_1: 0.3272 - val_loss: 1.0990 - val_multi_accuracy_1: 0.3272\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 1.0920 - multi_accuracy_1: 0.3273 - val_loss: 1.0948 - val_multi_accuracy_1: 0.3273\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 10s 128ms/step - loss: 1.0917 - multi_accuracy_1: 0.3275 - val_loss: 1.0980 - val_multi_accuracy_1: 0.3275\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 10s 127ms/step - loss: 1.0919 - multi_accuracy_1: 0.3276 - val_loss: 1.0984 - val_multi_accuracy_1: 0.3276\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 10s 124ms/step - loss: 1.0911 - multi_accuracy_1: 0.3278 - val_loss: 1.1019 - val_multi_accuracy_1: 0.3278\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 11s 129ms/step - loss: 1.0916 - multi_accuracy_1: 0.3279 - val_loss: 1.1008 - val_multi_accuracy_1: 0.3280\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 11s 128ms/step - loss: 1.0910 - multi_accuracy_1: 0.3281 - val_loss: 1.0982 - val_multi_accuracy_1: 0.3281\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.0968 - multi_accuracy_1: 0.3282\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 15s 135ms/step - loss: 1.5949 - multi_accuracy_1: 0.3281 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3282\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 10s 127ms/step - loss: 1.0979 - multi_accuracy_1: 0.3281 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3282\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 10s 122ms/step - loss: 1.0974 - multi_accuracy_1: 0.3281 - val_loss: 1.1052 - val_multi_accuracy_1: 0.3282\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 10s 128ms/step - loss: 1.0968 - multi_accuracy_1: 0.3281 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3282\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 10s 127ms/step - loss: 1.0964 - multi_accuracy_1: 0.3281 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3282\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 9s 114ms/step - loss: 1.0963 - multi_accuracy_1: 0.3281 - val_loss: 1.1062 - val_multi_accuracy_1: 0.3281\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 9s 106ms/step - loss: 1.0960 - multi_accuracy_1: 0.3280 - val_loss: 1.1033 - val_multi_accuracy_1: 0.3281\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 8s 97ms/step - loss: 1.0955 - multi_accuracy_1: 0.3280 - val_loss: 1.1039 - val_multi_accuracy_1: 0.3281\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 9s 106ms/step - loss: 1.0950 - multi_accuracy_1: 0.3279 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3280\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0946 - multi_accuracy_1: 0.3279 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3279\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 7s 84ms/step - loss: 1.0946 - multi_accuracy_1: 0.3278 - val_loss: 1.0971 - val_multi_accuracy_1: 0.3278\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.0938 - multi_accuracy_1: 0.3276 - val_loss: 1.1014 - val_multi_accuracy_1: 0.3277\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0931 - multi_accuracy_1: 0.3275 - val_loss: 1.0998 - val_multi_accuracy_1: 0.3275\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.0928 - multi_accuracy_1: 0.3273 - val_loss: 1.1030 - val_multi_accuracy_1: 0.3273\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 9s 112ms/step - loss: 1.0922 - multi_accuracy_1: 0.3272 - val_loss: 1.1012 - val_multi_accuracy_1: 0.3272\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 1.0920 - multi_accuracy_1: 0.3270 - val_loss: 1.0991 - val_multi_accuracy_1: 0.3269\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 1.0991 - multi_accuracy_1: 0.3269\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 13s 110ms/step - loss: 3.2093 - multi_accuracy_1: 0.3270 - val_loss: 2.7145 - val_multi_accuracy_1: 0.3270\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 10s 118ms/step - loss: 2.5395 - multi_accuracy_1: 0.3271 - val_loss: 2.5284 - val_multi_accuracy_1: 0.3270\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 2.5206 - multi_accuracy_1: 0.3271 - val_loss: 2.5312 - val_multi_accuracy_1: 0.3271\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 96ms/step - loss: 2.5023 - multi_accuracy_1: 0.3272 - val_loss: 2.5655 - val_multi_accuracy_1: 0.3272\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 99ms/step - loss: 2.4765 - multi_accuracy_1: 0.3273 - val_loss: 2.4927 - val_multi_accuracy_1: 0.3273\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 9s 108ms/step - loss: 2.4994 - multi_accuracy_1: 0.3274 - val_loss: 2.5837 - val_multi_accuracy_1: 0.3274\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 8s 100ms/step - loss: 2.4981 - multi_accuracy_1: 0.3275 - val_loss: 2.4877 - val_multi_accuracy_1: 0.3275\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 10s 118ms/step - loss: 2.4291 - multi_accuracy_1: 0.3277 - val_loss: 2.4377 - val_multi_accuracy_1: 0.3277\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 10s 118ms/step - loss: 2.4775 - multi_accuracy_1: 0.3278 - val_loss: 2.5938 - val_multi_accuracy_1: 0.3278\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 10s 117ms/step - loss: 2.6024 - multi_accuracy_1: 0.3279 - val_loss: 2.5737 - val_multi_accuracy_1: 0.3279\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 2.4808 - multi_accuracy_1: 0.3281 - val_loss: 2.6329 - val_multi_accuracy_1: 0.3281\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 9s 107ms/step - loss: 2.5630 - multi_accuracy_1: 0.3282 - val_loss: 2.4752 - val_multi_accuracy_1: 0.3282\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 9s 104ms/step - loss: 2.4279 - multi_accuracy_1: 0.3284 - val_loss: 2.5049 - val_multi_accuracy_1: 0.3284\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 2.4050 - multi_accuracy_1: 0.3284\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 50s 493ms/step - loss: 1.1860 - multi_accuracy_1: 0.3284 - val_loss: 1.1092 - val_multi_accuracy_1: 0.3284\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 39s 479ms/step - loss: 1.0959 - multi_accuracy_1: 0.3285 - val_loss: 1.1143 - val_multi_accuracy_1: 0.3285\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 36s 434ms/step - loss: 1.0952 - multi_accuracy_1: 0.3286 - val_loss: 1.1079 - val_multi_accuracy_1: 0.3286\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 37s 451ms/step - loss: 1.0950 - multi_accuracy_1: 0.3287 - val_loss: 1.1082 - val_multi_accuracy_1: 0.3287\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 43s 529ms/step - loss: 1.0938 - multi_accuracy_1: 0.3289 - val_loss: 1.1005 - val_multi_accuracy_1: 0.3289\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 40s 490ms/step - loss: 1.0932 - multi_accuracy_1: 0.3291 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3290\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 40s 486ms/step - loss: 1.0923 - multi_accuracy_1: 0.3292 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3292\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 41s 503ms/step - loss: 1.0920 - multi_accuracy_1: 0.3294 - val_loss: 1.1037 - val_multi_accuracy_1: 0.3294\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 33s 400ms/step - loss: 1.0920 - multi_accuracy_1: 0.3296 - val_loss: 1.0974 - val_multi_accuracy_1: 0.3296\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 32s 391ms/step - loss: 1.0920 - multi_accuracy_1: 0.3298 - val_loss: 1.0958 - val_multi_accuracy_1: 0.3299\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 32s 387ms/step - loss: 1.0917 - multi_accuracy_1: 0.3300 - val_loss: 1.1007 - val_multi_accuracy_1: 0.3300\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 32s 389ms/step - loss: 1.0919 - multi_accuracy_1: 0.3302 - val_loss: 1.1009 - val_multi_accuracy_1: 0.3302\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 32s 393ms/step - loss: 1.0918 - multi_accuracy_1: 0.3304 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3304\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 32s 395ms/step - loss: 1.0919 - multi_accuracy_1: 0.3305 - val_loss: 1.0982 - val_multi_accuracy_1: 0.3306\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 32s 393ms/step - loss: 1.0919 - multi_accuracy_1: 0.3307 - val_loss: 1.1009 - val_multi_accuracy_1: 0.3308\n",
      "28/28 [==============================] - 3s 126ms/step - loss: 1.0996 - multi_accuracy_1: 0.3308\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 42s 404ms/step - loss: 5.5323 - multi_accuracy_1: 0.3309 - val_loss: 5.5045 - val_multi_accuracy_1: 0.3308\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 5.3014 - multi_accuracy_1: 0.3309 - val_loss: 5.5045 - val_multi_accuracy_1: 0.3308\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 32s 390ms/step - loss: 5.3000 - multi_accuracy_1: 0.3309 - val_loss: 5.5045 - val_multi_accuracy_1: 0.3308\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 32s 390ms/step - loss: 5.3005 - multi_accuracy_1: 0.3309 - val_loss: 5.5045 - val_multi_accuracy_1: 0.3309\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 5.3022 - multi_accuracy_1: 0.3309 - val_loss: 5.5045 - val_multi_accuracy_1: 0.3309\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 5.3031 - multi_accuracy_1: 0.3309 - val_loss: 5.5045 - val_multi_accuracy_1: 0.3309\n",
      "28/28 [==============================] - 3s 123ms/step - loss: 5.6517 - multi_accuracy_1: 0.3308\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 42s 406ms/step - loss: 1.5296 - multi_accuracy_1: 0.3308 - val_loss: 1.1020 - val_multi_accuracy_1: 0.3308\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 32s 393ms/step - loss: 1.0962 - multi_accuracy_1: 0.3309 - val_loss: 1.1009 - val_multi_accuracy_1: 0.3309\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 32s 387ms/step - loss: 1.0963 - multi_accuracy_1: 0.3310 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 1.0953 - multi_accuracy_1: 0.3311 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 1.0945 - multi_accuracy_1: 0.3312 - val_loss: 1.0957 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 32s 391ms/step - loss: 1.0935 - multi_accuracy_1: 0.3313 - val_loss: 1.0982 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 1.0929 - multi_accuracy_1: 0.3314 - val_loss: 1.0947 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 32s 392ms/step - loss: 1.0931 - multi_accuracy_1: 0.3315 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 32s 391ms/step - loss: 1.0927 - multi_accuracy_1: 0.3317 - val_loss: 1.1006 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 32s 386ms/step - loss: 1.0924 - multi_accuracy_1: 0.3318 - val_loss: 1.0962 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 32s 390ms/step - loss: 1.0922 - multi_accuracy_1: 0.3320 - val_loss: 1.0963 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 1.0922 - multi_accuracy_1: 0.3322 - val_loss: 1.0976 - val_multi_accuracy_1: 0.3322\n",
      "28/28 [==============================] - 3s 126ms/step - loss: 1.0996 - multi_accuracy_1: 0.3323\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 23s 205ms/step - loss: 1.3714 - multi_accuracy_1: 0.3322 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 16s 197ms/step - loss: 1.0974 - multi_accuracy_1: 0.3322 - val_loss: 1.1090 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 16s 196ms/step - loss: 1.0969 - multi_accuracy_1: 0.3321 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 1.0965 - multi_accuracy_1: 0.3321 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0958 - multi_accuracy_1: 0.3321 - val_loss: 1.0991 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 1.0955 - multi_accuracy_1: 0.3321 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 1.0948 - multi_accuracy_1: 0.3321 - val_loss: 1.1022 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 1.0939 - multi_accuracy_1: 0.3320 - val_loss: 1.0967 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 1.0938 - multi_accuracy_1: 0.3321 - val_loss: 1.1016 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 16s 196ms/step - loss: 1.0927 - multi_accuracy_1: 0.3321 - val_loss: 1.1044 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0927 - multi_accuracy_1: 0.3321 - val_loss: 1.0983 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 16s 197ms/step - loss: 1.1037 - multi_accuracy_1: 0.3322 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 1.0953 - multi_accuracy_1: 0.3321 - val_loss: 1.0977 - val_multi_accuracy_1: 0.3322\n",
      "28/28 [==============================] - 2s 61ms/step - loss: 1.1008 - multi_accuracy_1: 0.3322\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 22s 205ms/step - loss: 1.2234 - multi_accuracy_1: 0.3322 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 16s 197ms/step - loss: 1.0957 - multi_accuracy_1: 0.3322 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 16s 196ms/step - loss: 1.0949 - multi_accuracy_1: 0.3322 - val_loss: 1.1013 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 1.0949 - multi_accuracy_1: 0.3321 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0942 - multi_accuracy_1: 0.3321 - val_loss: 1.0999 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 1.0942 - multi_accuracy_1: 0.3321 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0940 - multi_accuracy_1: 0.3320 - val_loss: 1.0985 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 1.0940 - multi_accuracy_1: 0.3320 - val_loss: 1.1000 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 1.0936 - multi_accuracy_1: 0.3320 - val_loss: 1.1028 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 1.0934 - multi_accuracy_1: 0.3320 - val_loss: 1.1012 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 1.0931 - multi_accuracy_1: 0.3319 - val_loss: 1.1009 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 16s 197ms/step - loss: 1.0925 - multi_accuracy_1: 0.3318 - val_loss: 1.1008 - val_multi_accuracy_1: 0.3318\n",
      "28/28 [==============================] - 2s 61ms/step - loss: 1.1018 - multi_accuracy_1: 0.3319\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 22s 203ms/step - loss: 1.8352 - multi_accuracy_1: 0.3319 - val_loss: 1.1455 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 1.1089 - multi_accuracy_1: 0.3320 - val_loss: 1.1201 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 16s 196ms/step - loss: 1.0991 - multi_accuracy_1: 0.3320 - val_loss: 1.1103 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 1.0962 - multi_accuracy_1: 0.3320 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0955 - multi_accuracy_1: 0.3320 - val_loss: 1.1031 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0951 - multi_accuracy_1: 0.3321 - val_loss: 1.1031 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 1.0949 - multi_accuracy_1: 0.3321 - val_loss: 1.1014 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0944 - multi_accuracy_1: 0.3321 - val_loss: 1.1037 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 1.0947 - multi_accuracy_1: 0.3322 - val_loss: 1.1023 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 16s 197ms/step - loss: 1.0940 - multi_accuracy_1: 0.3322 - val_loss: 1.1002 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 1.0942 - multi_accuracy_1: 0.3322 - val_loss: 1.0996 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0936 - multi_accuracy_1: 0.3323 - val_loss: 1.0998 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 16s 196ms/step - loss: 1.0933 - multi_accuracy_1: 0.3323 - val_loss: 1.0988 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 16s 196ms/step - loss: 1.0929 - multi_accuracy_1: 0.3323 - val_loss: 1.1003 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 1.0929 - multi_accuracy_1: 0.3324 - val_loss: 1.0988 - val_multi_accuracy_1: 0.3325\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0926 - multi_accuracy_1: 0.3325 - val_loss: 1.0990 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0921 - multi_accuracy_1: 0.3326 - val_loss: 1.0973 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 1.0920 - multi_accuracy_1: 0.3327 - val_loss: 1.1013 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 1.0920 - multi_accuracy_1: 0.3327 - val_loss: 1.0975 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0917 - multi_accuracy_1: 0.3328 - val_loss: 1.1011 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 16s 191ms/step - loss: 1.0917 - multi_accuracy_1: 0.3329 - val_loss: 1.0961 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 16s 191ms/step - loss: 1.0913 - multi_accuracy_1: 0.3329 - val_loss: 1.0955 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 1.0913 - multi_accuracy_1: 0.3330 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 15s 188ms/step - loss: 1.0912 - multi_accuracy_1: 0.3331 - val_loss: 1.1003 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 16s 195ms/step - loss: 1.0910 - multi_accuracy_1: 0.3331 - val_loss: 1.1032 - val_multi_accuracy_1: 0.3332\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 1.1073 - multi_accuracy_1: 0.3332\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 12s 101ms/step - loss: 2.2333 - multi_accuracy_1: 0.3332 - val_loss: 1.1037 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0989 - multi_accuracy_1: 0.3332 - val_loss: 1.1076 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.0980 - multi_accuracy_1: 0.3333 - val_loss: 1.1059 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.0974 - multi_accuracy_1: 0.3333 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.0967 - multi_accuracy_1: 0.3333 - val_loss: 1.1089 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.0967 - multi_accuracy_1: 0.3333 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3333\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.1030 - multi_accuracy_1: 0.3333\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 12s 100ms/step - loss: 2.8507 - multi_accuracy_1: 0.3333 - val_loss: 1.1207 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.1029 - multi_accuracy_1: 0.3333 - val_loss: 1.1086 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.1011 - multi_accuracy_1: 0.3333 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.1000 - multi_accuracy_1: 0.3333 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0990 - multi_accuracy_1: 0.3333 - val_loss: 1.1084 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0986 - multi_accuracy_1: 0.3332 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0982 - multi_accuracy_1: 0.3332 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.0978 - multi_accuracy_1: 0.3332 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.0975 - multi_accuracy_1: 0.3332 - val_loss: 1.1044 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.0970 - multi_accuracy_1: 0.3331 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.0968 - multi_accuracy_1: 0.3331 - val_loss: 1.1093 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0968 - multi_accuracy_1: 0.3331 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0962 - multi_accuracy_1: 0.3331 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0962 - multi_accuracy_1: 0.3331 - val_loss: 1.1078 - val_multi_accuracy_1: 0.3331\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.1050 - multi_accuracy_1: 0.3331\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 12s 104ms/step - loss: 2.9383 - multi_accuracy_1: 0.3330 - val_loss: 3.1300 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 2.1074 - multi_accuracy_1: 0.3330 - val_loss: 1.3860 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.1495 - multi_accuracy_1: 0.3330 - val_loss: 1.1124 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.1035 - multi_accuracy_1: 0.3330 - val_loss: 1.1090 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.1015 - multi_accuracy_1: 0.3330 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0999 - multi_accuracy_1: 0.3330 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0990 - multi_accuracy_1: 0.3330 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.0985 - multi_accuracy_1: 0.3331 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.0978 - multi_accuracy_1: 0.3331 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0977 - multi_accuracy_1: 0.3331 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.0973 - multi_accuracy_1: 0.3331 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.0973 - multi_accuracy_1: 0.3332 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.0970 - multi_accuracy_1: 0.3332 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.0971 - multi_accuracy_1: 0.3332 - val_loss: 1.1041 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0970 - multi_accuracy_1: 0.3333 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0968 - multi_accuracy_1: 0.3333 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0968 - multi_accuracy_1: 0.3333 - val_loss: 1.1037 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 1.0965 - multi_accuracy_1: 0.3334 - val_loss: 1.1019 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 1.0965 - multi_accuracy_1: 0.3334 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 1.0965 - multi_accuracy_1: 0.3335 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0963 - multi_accuracy_1: 0.3335 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0959 - multi_accuracy_1: 0.3335 - val_loss: 1.1050 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.0957 - multi_accuracy_1: 0.3336 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 1.1012 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 27s 221ms/step - loss: 3.5721 - multi_accuracy_1: 0.3336 - val_loss: 3.0454 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 3.4196 - multi_accuracy_1: 0.3336 - val_loss: 3.0444 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 3.4190 - multi_accuracy_1: 0.3336 - val_loss: 3.0450 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 3.4198 - multi_accuracy_1: 0.3336 - val_loss: 3.0458 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 17s 210ms/step - loss: 3.4190 - multi_accuracy_1: 0.3336 - val_loss: 3.0444 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 3.4187 - multi_accuracy_1: 0.3336 - val_loss: 3.0444 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 3.4184 - multi_accuracy_1: 0.3336 - val_loss: 3.0439 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 3.4190 - multi_accuracy_1: 0.3335 - val_loss: 3.0431 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 3.4182 - multi_accuracy_1: 0.3335 - val_loss: 3.0424 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 3.4185 - multi_accuracy_1: 0.3335 - val_loss: 3.0446 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 3.4208 - multi_accuracy_1: 0.3335 - val_loss: 3.0446 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 3.4165 - multi_accuracy_1: 0.3334 - val_loss: 3.0456 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 3.4190 - multi_accuracy_1: 0.3334 - val_loss: 3.0423 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 3.4193 - multi_accuracy_1: 0.3334 - val_loss: 3.0442 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 3.4209 - multi_accuracy_1: 0.3334 - val_loss: 3.0424 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 17s 209ms/step - loss: 3.4202 - multi_accuracy_1: 0.3333 - val_loss: 3.0413 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 3.4227 - multi_accuracy_1: 0.3333 - val_loss: 3.0428 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 3.4270 - multi_accuracy_1: 0.3333 - val_loss: 3.0405 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 3.4354 - multi_accuracy_1: 0.3332 - val_loss: 3.0409 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 3.4199 - multi_accuracy_1: 0.3332 - val_loss: 3.0415 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 3.4520 - multi_accuracy_1: 0.3331 - val_loss: 3.0406 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 3.4410 - multi_accuracy_1: 0.3331 - val_loss: 3.0417 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 3.4309 - multi_accuracy_1: 0.3331 - val_loss: 3.0448 - val_multi_accuracy_1: 0.3331\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 3.1715 - multi_accuracy_1: 0.3331\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 25s 211ms/step - loss: 8.5993 - multi_accuracy_1: 0.3331 - val_loss: 8.7368 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 17s 202ms/step - loss: 9.9423 - multi_accuracy_1: 0.3331 - val_loss: 8.7368 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 9.9123 - multi_accuracy_1: 0.3332 - val_loss: 8.7368 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 9.9198 - multi_accuracy_1: 0.3332 - val_loss: 8.7368 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 9.9061 - multi_accuracy_1: 0.3332 - val_loss: 8.7368 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 9.8994 - multi_accuracy_1: 0.3333 - val_loss: 8.7368 - val_multi_accuracy_1: 0.3332\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 8.6718 - multi_accuracy_1: 0.3332\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 26s 217ms/step - loss: 5.1949 - multi_accuracy_1: 0.3332 - val_loss: 6.0538 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 6.0257 - multi_accuracy_1: 0.3332 - val_loss: 6.9032 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 6.2280 - multi_accuracy_1: 0.3332 - val_loss: 6.9023 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 6.2659 - multi_accuracy_1: 0.3332 - val_loss: 6.8995 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 6.2709 - multi_accuracy_1: 0.3332 - val_loss: 6.9009 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 6.2810 - multi_accuracy_1: 0.3332 - val_loss: 6.9012 - val_multi_accuracy_1: 0.3332\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 6.1882 - multi_accuracy_1: 0.3332\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 15s 110ms/step - loss: 1.7306 - multi_accuracy_1: 0.3332 - val_loss: 1.1082 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 1.0977 - multi_accuracy_1: 0.3332 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 1.0972 - multi_accuracy_1: 0.3332 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 1.0966 - multi_accuracy_1: 0.3331 - val_loss: 1.1066 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 1.0959 - multi_accuracy_1: 0.3331 - val_loss: 1.1015 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 1.0953 - multi_accuracy_1: 0.3331 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 1.0947 - multi_accuracy_1: 0.3331 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 1.0938 - multi_accuracy_1: 0.3331 - val_loss: 1.1026 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 8s 104ms/step - loss: 1.0935 - multi_accuracy_1: 0.3331 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 1.0933 - multi_accuracy_1: 0.3331 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3332\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.1030 - multi_accuracy_1: 0.3332\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 15s 114ms/step - loss: 3.5504 - multi_accuracy_1: 0.3332 - val_loss: 2.3925 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 2.6381 - multi_accuracy_1: 0.3332 - val_loss: 2.3898 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 2.6373 - multi_accuracy_1: 0.3332 - val_loss: 2.3884 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 2.6402 - multi_accuracy_1: 0.3333 - val_loss: 2.3903 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 2.6400 - multi_accuracy_1: 0.3333 - val_loss: 2.3892 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 2.6440 - multi_accuracy_1: 0.3333 - val_loss: 2.3888 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 2.6453 - multi_accuracy_1: 0.3333 - val_loss: 2.3892 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 2.6570 - multi_accuracy_1: 0.3333 - val_loss: 2.3958 - val_multi_accuracy_1: 0.3333\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.4401 - multi_accuracy_1: 0.3333\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 14s 110ms/step - loss: 1.9369 - multi_accuracy_1: 0.3333 - val_loss: 1.1079 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 8s 101ms/step - loss: 1.1037 - multi_accuracy_1: 0.3333 - val_loss: 1.1030 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 1.0983 - multi_accuracy_1: 0.3333 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 101ms/step - loss: 1.0974 - multi_accuracy_1: 0.3333 - val_loss: 1.1033 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 100ms/step - loss: 1.0971 - multi_accuracy_1: 0.3333 - val_loss: 1.1065 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 100ms/step - loss: 1.0967 - multi_accuracy_1: 0.3334 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 8s 100ms/step - loss: 1.0960 - multi_accuracy_1: 0.3334 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 8s 101ms/step - loss: 1.0953 - multi_accuracy_1: 0.3334 - val_loss: 1.0992 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 8s 101ms/step - loss: 1.0949 - multi_accuracy_1: 0.3334 - val_loss: 1.0985 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 1.0945 - multi_accuracy_1: 0.3335 - val_loss: 1.1127 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 1.0946 - multi_accuracy_1: 0.3335 - val_loss: 1.0978 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 8s 101ms/step - loss: 1.0945 - multi_accuracy_1: 0.3335 - val_loss: 1.1003 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 1.0938 - multi_accuracy_1: 0.3335 - val_loss: 1.1023 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 1.0935 - multi_accuracy_1: 0.3336 - val_loss: 1.1012 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 1.0932 - multi_accuracy_1: 0.3336 - val_loss: 1.0975 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 8s 101ms/step - loss: 1.0932 - multi_accuracy_1: 0.3336 - val_loss: 1.1007 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 8s 101ms/step - loss: 1.0930 - multi_accuracy_1: 0.3336 - val_loss: 1.1012 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 1.0929 - multi_accuracy_1: 0.3336 - val_loss: 1.1080 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 8s 101ms/step - loss: 1.0927 - multi_accuracy_1: 0.3336 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 8s 101ms/step - loss: 1.0922 - multi_accuracy_1: 0.3337 - val_loss: 1.1026 - val_multi_accuracy_1: 0.3337\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.0999 - multi_accuracy_1: 0.3337\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 9s 57ms/step - loss: 1.4514 - multi_accuracy_1: 0.3337 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0988 - multi_accuracy_1: 0.3337 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0978 - multi_accuracy_1: 0.3337 - val_loss: 1.1032 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0978 - multi_accuracy_1: 0.3336 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0972 - multi_accuracy_1: 0.3336 - val_loss: 1.1044 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 4s 48ms/step - loss: 1.0969 - multi_accuracy_1: 0.3336 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0966 - multi_accuracy_1: 0.3335 - val_loss: 1.1026 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0963 - multi_accuracy_1: 0.3335 - val_loss: 1.1031 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0957 - multi_accuracy_1: 0.3334 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 4s 48ms/step - loss: 1.0956 - multi_accuracy_1: 0.3334 - val_loss: 1.1014 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 4s 48ms/step - loss: 1.0952 - multi_accuracy_1: 0.3333 - val_loss: 1.0980 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0946 - multi_accuracy_1: 0.3333 - val_loss: 1.0998 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0938 - multi_accuracy_1: 0.3332 - val_loss: 1.1009 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0934 - multi_accuracy_1: 0.3332 - val_loss: 1.0960 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 4s 48ms/step - loss: 1.0921 - multi_accuracy_1: 0.3331 - val_loss: 1.0987 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0918 - multi_accuracy_1: 0.3330 - val_loss: 1.1002 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0911 - multi_accuracy_1: 0.3329 - val_loss: 1.0998 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0904 - multi_accuracy_1: 0.3328 - val_loss: 1.1002 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0903 - multi_accuracy_1: 0.3327 - val_loss: 1.1028 - val_multi_accuracy_1: 0.3327\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.0997 - multi_accuracy_1: 0.3327\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 8s 55ms/step - loss: 5.0361 - multi_accuracy_1: 0.3327 - val_loss: 3.5150 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.3932 - multi_accuracy_1: 0.3327 - val_loss: 1.1224 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.1012 - multi_accuracy_1: 0.3327 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0991 - multi_accuracy_1: 0.3326 - val_loss: 1.1065 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0985 - multi_accuracy_1: 0.3326 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0977 - multi_accuracy_1: 0.3325 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3325\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0975 - multi_accuracy_1: 0.3325 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3325\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0973 - multi_accuracy_1: 0.3325 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3325\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0969 - multi_accuracy_1: 0.3324 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0968 - multi_accuracy_1: 0.3324 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0963 - multi_accuracy_1: 0.3324 - val_loss: 1.1037 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0962 - multi_accuracy_1: 0.3323 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0961 - multi_accuracy_1: 0.3323 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0960 - multi_accuracy_1: 0.3323 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 1.0960 - multi_accuracy_1: 0.3322 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 1.0958 - multi_accuracy_1: 0.3322 - val_loss: 1.1038 - val_multi_accuracy_1: 0.3322\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.1042 - multi_accuracy_1: 0.3322\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 8s 60ms/step - loss: 4.5457 - multi_accuracy_1: 0.3322 - val_loss: 3.2258 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 3.5848 - multi_accuracy_1: 0.3322 - val_loss: 3.2272 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 3.5838 - multi_accuracy_1: 0.3322 - val_loss: 3.2276 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 3.5835 - multi_accuracy_1: 0.3322 - val_loss: 3.2271 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 4s 49ms/step - loss: 3.5827 - multi_accuracy_1: 0.3321 - val_loss: 3.2267 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 4s 50ms/step - loss: 3.5824 - multi_accuracy_1: 0.3321 - val_loss: 3.2265 - val_multi_accuracy_1: 0.3321\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.0304 - multi_accuracy_1: 0.3321\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 26s 220ms/step - loss: 1.6019 - multi_accuracy_1: 0.3321 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 1.0953 - multi_accuracy_1: 0.3321 - val_loss: 1.1007 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 1.0946 - multi_accuracy_1: 0.3320 - val_loss: 1.0976 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 1.0941 - multi_accuracy_1: 0.3320 - val_loss: 1.1009 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 1.0932 - multi_accuracy_1: 0.3320 - val_loss: 1.0974 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 1.0928 - multi_accuracy_1: 0.3319 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 1.0926 - multi_accuracy_1: 0.3319 - val_loss: 1.1010 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 1.0925 - multi_accuracy_1: 0.3318 - val_loss: 1.0934 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 1.0932 - multi_accuracy_1: 0.3318 - val_loss: 1.0934 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 1.0925 - multi_accuracy_1: 0.3317 - val_loss: 1.0949 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 1.0924 - multi_accuracy_1: 0.3317 - val_loss: 1.0970 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 1.0920 - multi_accuracy_1: 0.3316 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 1.0919 - multi_accuracy_1: 0.3316 - val_loss: 1.0966 - val_multi_accuracy_1: 0.3315\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 1.0975 - multi_accuracy_1: 0.3315\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 26s 215ms/step - loss: 1.3529 - multi_accuracy_1: 0.3315 - val_loss: 1.1159 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 1.1030 - multi_accuracy_1: 0.3315 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 1.0983 - multi_accuracy_1: 0.3315 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 1.0967 - multi_accuracy_1: 0.3315 - val_loss: 1.1065 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 1.0962 - multi_accuracy_1: 0.3315 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 1.0958 - multi_accuracy_1: 0.3315 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 1.0953 - multi_accuracy_1: 0.3315 - val_loss: 1.1013 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 1.0946 - multi_accuracy_1: 0.3315 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 1.0943 - multi_accuracy_1: 0.3315 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 1.0938 - multi_accuracy_1: 0.3315 - val_loss: 1.1003 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 1.0939 - multi_accuracy_1: 0.3315 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 1.0933 - multi_accuracy_1: 0.3315 - val_loss: 1.0999 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 1.0927 - multi_accuracy_1: 0.3315 - val_loss: 1.0991 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 1.0925 - multi_accuracy_1: 0.3315 - val_loss: 1.1007 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 17s 202ms/step - loss: 1.0924 - multi_accuracy_1: 0.3314 - val_loss: 1.0997 - val_multi_accuracy_1: 0.3314\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 1.0925 - multi_accuracy_1: 0.3314 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3314\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 1.0923 - multi_accuracy_1: 0.3314 - val_loss: 1.0983 - val_multi_accuracy_1: 0.3314\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 1.0918 - multi_accuracy_1: 0.3313 - val_loss: 1.0987 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 1.0918 - multi_accuracy_1: 0.3313 - val_loss: 1.0994 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 1.0918 - multi_accuracy_1: 0.3312 - val_loss: 1.0957 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 1.0917 - multi_accuracy_1: 0.3312 - val_loss: 1.1008 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 1.0916 - multi_accuracy_1: 0.3312 - val_loss: 1.0966 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 1.0911 - multi_accuracy_1: 0.3311 - val_loss: 1.0944 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 1.0918 - multi_accuracy_1: 0.3311 - val_loss: 1.0967 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 1.0918 - multi_accuracy_1: 0.3311 - val_loss: 1.0990 - val_multi_accuracy_1: 0.3311\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 1.1031 - multi_accuracy_1: 0.3311\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 27s 213ms/step - loss: 7.0030 - multi_accuracy_1: 0.3310 - val_loss: 8.6042 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 9.0967 - multi_accuracy_1: 0.3310 - val_loss: 8.6175 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 9.0118 - multi_accuracy_1: 0.3310 - val_loss: 8.5936 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 8.9326 - multi_accuracy_1: 0.3310 - val_loss: 8.4517 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 8.8839 - multi_accuracy_1: 0.3310 - val_loss: 8.4185 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 8.9326 - multi_accuracy_1: 0.3310 - val_loss: 8.4503 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 8.9702 - multi_accuracy_1: 0.3310 - val_loss: 8.4503 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 8.9251 - multi_accuracy_1: 0.3310 - val_loss: 8.4503 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 8.9047 - multi_accuracy_1: 0.3309 - val_loss: 8.5220 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 9.0657 - multi_accuracy_1: 0.3309 - val_loss: 8.6612 - val_multi_accuracy_1: 0.3310\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 8.1691 - multi_accuracy_1: 0.3310\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 15s 111ms/step - loss: 3.4041 - multi_accuracy_1: 0.3310 - val_loss: 3.3435 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 3.1923 - multi_accuracy_1: 0.3310 - val_loss: 3.4613 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 3.4228 - multi_accuracy_1: 0.3310 - val_loss: 3.5621 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 3.5979 - multi_accuracy_1: 0.3310 - val_loss: 3.6697 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 3.6762 - multi_accuracy_1: 0.3310 - val_loss: 3.7069 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 3.7257 - multi_accuracy_1: 0.3309 - val_loss: 3.7345 - val_multi_accuracy_1: 0.3310\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 3.5122 - multi_accuracy_1: 0.3310\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 14s 105ms/step - loss: 3.3286 - multi_accuracy_1: 0.3310 - val_loss: 3.1442 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 10s 118ms/step - loss: 3.1673 - multi_accuracy_1: 0.3311 - val_loss: 3.1302 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 10s 123ms/step - loss: 3.1292 - multi_accuracy_1: 0.3311 - val_loss: 3.0865 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 10s 124ms/step - loss: 3.1559 - multi_accuracy_1: 0.3311 - val_loss: 3.0610 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 9s 115ms/step - loss: 3.0946 - multi_accuracy_1: 0.3311 - val_loss: 3.0591 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 10s 127ms/step - loss: 3.0708 - multi_accuracy_1: 0.3312 - val_loss: 3.0374 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 11s 129ms/step - loss: 3.0664 - multi_accuracy_1: 0.3312 - val_loss: 3.0218 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 11s 135ms/step - loss: 3.0500 - multi_accuracy_1: 0.3312 - val_loss: 3.0177 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 11s 136ms/step - loss: 3.0520 - multi_accuracy_1: 0.3313 - val_loss: 3.0141 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 12s 147ms/step - loss: 3.0442 - multi_accuracy_1: 0.3313 - val_loss: 3.0166 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 12s 143ms/step - loss: 3.0340 - multi_accuracy_1: 0.3314 - val_loss: 3.0034 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 11s 136ms/step - loss: 3.0244 - multi_accuracy_1: 0.3314 - val_loss: 2.9690 - val_multi_accuracy_1: 0.3314\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 3.0026 - multi_accuracy_1: 0.3314 - val_loss: 2.9928 - val_multi_accuracy_1: 0.3314\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 12s 140ms/step - loss: 3.0402 - multi_accuracy_1: 0.3315 - val_loss: 3.0082 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 3.0159 - multi_accuracy_1: 0.3315 - val_loss: 2.9888 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 11s 136ms/step - loss: 3.0138 - multi_accuracy_1: 0.3316 - val_loss: 2.9790 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 10s 123ms/step - loss: 2.9944 - multi_accuracy_1: 0.3316 - val_loss: 2.9757 - val_multi_accuracy_1: 0.3316\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 2.7748 - multi_accuracy_1: 0.3316\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 16s 131ms/step - loss: 3.2689 - multi_accuracy_1: 0.3316 - val_loss: 1.1131 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 10s 122ms/step - loss: 1.1050 - multi_accuracy_1: 0.3316 - val_loss: 1.1023 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 1.0997 - multi_accuracy_1: 0.3316 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 1.0982 - multi_accuracy_1: 0.3316 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 10s 128ms/step - loss: 1.0973 - multi_accuracy_1: 0.3316 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 1.0962 - multi_accuracy_1: 0.3316 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 1.0963 - multi_accuracy_1: 0.3317 - val_loss: 1.1050 - val_multi_accuracy_1: 0.3317\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.1042 - multi_accuracy_1: 0.3316\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 11s 73ms/step - loss: 2.0446 - multi_accuracy_1: 0.3317 - val_loss: 1.1081 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0974 - multi_accuracy_1: 0.3317 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0969 - multi_accuracy_1: 0.3317 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0967 - multi_accuracy_1: 0.3317 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0965 - multi_accuracy_1: 0.3317 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0961 - multi_accuracy_1: 0.3317 - val_loss: 1.1030 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0963 - multi_accuracy_1: 0.3317 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0960 - multi_accuracy_1: 0.3317 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 1.0959 - multi_accuracy_1: 0.3317 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3317\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.1018 - multi_accuracy_1: 0.3317\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 10s 77ms/step - loss: 4.0264 - multi_accuracy_1: 0.3317 - val_loss: 1.4088 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.1934 - multi_accuracy_1: 0.3317 - val_loss: 1.1257 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.1138 - multi_accuracy_1: 0.3318 - val_loss: 1.1172 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.1050 - multi_accuracy_1: 0.3318 - val_loss: 1.1116 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.1013 - multi_accuracy_1: 0.3318 - val_loss: 1.1076 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.0995 - multi_accuracy_1: 0.3318 - val_loss: 1.1062 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0982 - multi_accuracy_1: 0.3318 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0975 - multi_accuracy_1: 0.3318 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0973 - multi_accuracy_1: 0.3318 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0970 - multi_accuracy_1: 0.3318 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 6s 67ms/step - loss: 1.0965 - multi_accuracy_1: 0.3319 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0966 - multi_accuracy_1: 0.3319 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0964 - multi_accuracy_1: 0.3319 - val_loss: 1.1022 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.0958 - multi_accuracy_1: 0.3319 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0959 - multi_accuracy_1: 0.3319 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0955 - multi_accuracy_1: 0.3320 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0952 - multi_accuracy_1: 0.3320 - val_loss: 1.1011 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0953 - multi_accuracy_1: 0.3320 - val_loss: 1.1013 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0949 - multi_accuracy_1: 0.3320 - val_loss: 1.1013 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.0947 - multi_accuracy_1: 0.3321 - val_loss: 1.1008 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0949 - multi_accuracy_1: 0.3321 - val_loss: 1.1041 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0943 - multi_accuracy_1: 0.3321 - val_loss: 1.0996 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0942 - multi_accuracy_1: 0.3321 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0944 - multi_accuracy_1: 0.3322 - val_loss: 1.1022 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 6s 67ms/step - loss: 1.0940 - multi_accuracy_1: 0.3322 - val_loss: 1.1003 - val_multi_accuracy_1: 0.3322\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 1.1041 - multi_accuracy_1: 0.3322\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 11s 74ms/step - loss: 4.6939 - multi_accuracy_1: 0.3322 - val_loss: 3.9312 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 4.2492 - multi_accuracy_1: 0.3322 - val_loss: 4.0966 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 4.3617 - multi_accuracy_1: 0.3322 - val_loss: 4.2194 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 4.4286 - multi_accuracy_1: 0.3322 - val_loss: 4.2483 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 4.4179 - multi_accuracy_1: 0.3322 - val_loss: 4.2642 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 4.4132 - multi_accuracy_1: 0.3322 - val_loss: 4.2119 - val_multi_accuracy_1: 0.3322\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 3.9086 - multi_accuracy_1: 0.3322\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 34s 298ms/step - loss: 2.6364 - multi_accuracy_1: 0.3322 - val_loss: 2.7010 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 24s 294ms/step - loss: 2.2377 - multi_accuracy_1: 0.3322 - val_loss: 2.7009 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 24s 290ms/step - loss: 2.2372 - multi_accuracy_1: 0.3322 - val_loss: 2.6981 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 23s 286ms/step - loss: 2.2368 - multi_accuracy_1: 0.3322 - val_loss: 2.6998 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 23s 280ms/step - loss: 2.2365 - multi_accuracy_1: 0.3322 - val_loss: 2.6980 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 23s 282ms/step - loss: 2.2359 - multi_accuracy_1: 0.3322 - val_loss: 2.6995 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 23s 278ms/step - loss: 2.2358 - multi_accuracy_1: 0.3323 - val_loss: 2.6993 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 23s 284ms/step - loss: 2.2359 - multi_accuracy_1: 0.3323 - val_loss: 2.6974 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 23s 286ms/step - loss: 2.2350 - multi_accuracy_1: 0.3323 - val_loss: 2.7001 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 23s 281ms/step - loss: 2.2348 - multi_accuracy_1: 0.3323 - val_loss: 2.6940 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 24s 294ms/step - loss: 2.2357 - multi_accuracy_1: 0.3323 - val_loss: 2.6992 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 22s 267ms/step - loss: 2.2354 - multi_accuracy_1: 0.3324 - val_loss: 2.7002 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 23s 280ms/step - loss: 2.2361 - multi_accuracy_1: 0.3324 - val_loss: 2.6956 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 2.2348 - multi_accuracy_1: 0.3324 - val_loss: 2.7006 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 2.2343 - multi_accuracy_1: 0.3324 - val_loss: 2.6994 - val_multi_accuracy_1: 0.3324\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 2.6797 - multi_accuracy_1: 0.3324\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 30s 227ms/step - loss: 3.5882 - multi_accuracy_1: 0.3324 - val_loss: 2.7210 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 23s 275ms/step - loss: 3.1260 - multi_accuracy_1: 0.3324 - val_loss: 2.7198 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 22s 271ms/step - loss: 3.1350 - multi_accuracy_1: 0.3324 - val_loss: 2.7182 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 23s 283ms/step - loss: 3.1075 - multi_accuracy_1: 0.3324 - val_loss: 2.7201 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 22s 272ms/step - loss: 3.1212 - multi_accuracy_1: 0.3323 - val_loss: 2.7200 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 23s 282ms/step - loss: 3.1556 - multi_accuracy_1: 0.3323 - val_loss: 2.8614 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 23s 281ms/step - loss: 3.1802 - multi_accuracy_1: 0.3323 - val_loss: 3.1487 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 23s 282ms/step - loss: 3.2148 - multi_accuracy_1: 0.3322 - val_loss: 3.1631 - val_multi_accuracy_1: 0.3322\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 2.8053 - multi_accuracy_1: 0.3322\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 35s 305ms/step - loss: 5.1997 - multi_accuracy_1: 0.3322 - val_loss: 4.8819 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 23s 284ms/step - loss: 5.3092 - multi_accuracy_1: 0.3321 - val_loss: 5.0966 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 23s 280ms/step - loss: 5.6982 - multi_accuracy_1: 0.3321 - val_loss: 5.0946 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 23s 281ms/step - loss: 5.6994 - multi_accuracy_1: 0.3321 - val_loss: 5.0946 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 23s 285ms/step - loss: 5.7003 - multi_accuracy_1: 0.3321 - val_loss: 5.0946 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 23s 283ms/step - loss: 5.6888 - multi_accuracy_1: 0.3321 - val_loss: 5.0946 - val_multi_accuracy_1: 0.3320\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 5.0014 - multi_accuracy_1: 0.3320\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 17s 144ms/step - loss: 1.7535 - multi_accuracy_1: 0.3320 - val_loss: 1.1106 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 1.0977 - multi_accuracy_1: 0.3320 - val_loss: 1.1082 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 11s 129ms/step - loss: 1.0974 - multi_accuracy_1: 0.3320 - val_loss: 1.1071 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 1.0972 - multi_accuracy_1: 0.3320 - val_loss: 1.1077 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 12s 142ms/step - loss: 1.0971 - multi_accuracy_1: 0.3320 - val_loss: 1.1065 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 11s 140ms/step - loss: 1.0967 - multi_accuracy_1: 0.3320 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 1.0967 - multi_accuracy_1: 0.3320 - val_loss: 1.1041 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 9s 107ms/step - loss: 1.0962 - multi_accuracy_1: 0.3320 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 1.0960 - multi_accuracy_1: 0.3320 - val_loss: 1.1078 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 8s 102ms/step - loss: 1.0957 - multi_accuracy_1: 0.3320 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 9s 108ms/step - loss: 1.0952 - multi_accuracy_1: 0.3320 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 8s 95ms/step - loss: 1.0948 - multi_accuracy_1: 0.3320 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0947 - multi_accuracy_1: 0.3320 - val_loss: 1.1018 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0938 - multi_accuracy_1: 0.3320 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 11s 136ms/step - loss: 1.0936 - multi_accuracy_1: 0.3320 - val_loss: 1.1003 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 1.0933 - multi_accuracy_1: 0.3320 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 1.0926 - multi_accuracy_1: 0.3320 - val_loss: 1.1032 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 1.0924 - multi_accuracy_1: 0.3320 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 1.0923 - multi_accuracy_1: 0.3320 - val_loss: 1.1007 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 1.0920 - multi_accuracy_1: 0.3319 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3319\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.1035 - multi_accuracy_1: 0.3319\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 15s 98ms/step - loss: 2.7155 - multi_accuracy_1: 0.3319 - val_loss: 2.2495 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 2.3863 - multi_accuracy_1: 0.3319 - val_loss: 2.2472 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 2.3842 - multi_accuracy_1: 0.3319 - val_loss: 2.2471 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 2.3873 - multi_accuracy_1: 0.3319 - val_loss: 2.2464 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 10s 128ms/step - loss: 2.3916 - multi_accuracy_1: 0.3319 - val_loss: 2.2454 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 2.3863 - multi_accuracy_1: 0.3319 - val_loss: 2.2480 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 9s 115ms/step - loss: 2.3857 - multi_accuracy_1: 0.3318 - val_loss: 2.2436 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 9s 107ms/step - loss: 2.3777 - multi_accuracy_1: 0.3318 - val_loss: 2.2405 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 8s 101ms/step - loss: 2.3815 - multi_accuracy_1: 0.3318 - val_loss: 2.2457 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 8s 98ms/step - loss: 2.3781 - multi_accuracy_1: 0.3318 - val_loss: 2.2424 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 8s 99ms/step - loss: 2.3823 - multi_accuracy_1: 0.3318 - val_loss: 2.2473 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 8s 103ms/step - loss: 2.3927 - multi_accuracy_1: 0.3318 - val_loss: 2.2429 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 9s 106ms/step - loss: 2.3904 - multi_accuracy_1: 0.3317 - val_loss: 2.2416 - val_multi_accuracy_1: 0.3317\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 2.2573 - multi_accuracy_1: 0.3317\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 18s 144ms/step - loss: 1.3819 - multi_accuracy_1: 0.3318 - val_loss: 1.1030 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 11s 135ms/step - loss: 1.0963 - multi_accuracy_1: 0.3317 - val_loss: 1.1050 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 11s 128ms/step - loss: 1.0956 - multi_accuracy_1: 0.3317 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 1.0947 - multi_accuracy_1: 0.3317 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 1.0946 - multi_accuracy_1: 0.3316 - val_loss: 1.1018 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 1.0935 - multi_accuracy_1: 0.3316 - val_loss: 1.1000 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 10s 119ms/step - loss: 1.0927 - multi_accuracy_1: 0.3315 - val_loss: 1.0963 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 9s 116ms/step - loss: 1.0927 - multi_accuracy_1: 0.3314 - val_loss: 1.0967 - val_multi_accuracy_1: 0.3314\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 11s 135ms/step - loss: 1.0953 - multi_accuracy_1: 0.3314 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3314\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 9s 111ms/step - loss: 1.0957 - multi_accuracy_1: 0.3314 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3314\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 10s 124ms/step - loss: 1.0951 - multi_accuracy_1: 0.3313 - val_loss: 1.1052 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 10s 118ms/step - loss: 1.0948 - multi_accuracy_1: 0.3313 - val_loss: 1.1001 - val_multi_accuracy_1: 0.3313\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.0980 - multi_accuracy_1: 0.3313\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 11s 73ms/step - loss: 2.6187 - multi_accuracy_1: 0.3313 - val_loss: 2.5042 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.3664 - multi_accuracy_1: 0.3313 - val_loss: 1.1154 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 4s 52ms/step - loss: 1.1031 - multi_accuracy_1: 0.3313 - val_loss: 1.1097 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 1.1002 - multi_accuracy_1: 0.3313 - val_loss: 1.1076 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0993 - multi_accuracy_1: 0.3313 - val_loss: 1.1066 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0986 - multi_accuracy_1: 0.3313 - val_loss: 1.1038 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0984 - multi_accuracy_1: 0.3312 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0980 - multi_accuracy_1: 0.3312 - val_loss: 1.1079 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0978 - multi_accuracy_1: 0.3312 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.0975 - multi_accuracy_1: 0.3312 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 1.0974 - multi_accuracy_1: 0.3312 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0970 - multi_accuracy_1: 0.3312 - val_loss: 1.1028 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0969 - multi_accuracy_1: 0.3312 - val_loss: 1.1066 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0964 - multi_accuracy_1: 0.3311 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 1.0962 - multi_accuracy_1: 0.3311 - val_loss: 1.1050 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.0962 - multi_accuracy_1: 0.3311 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3311\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 1.1031 - multi_accuracy_1: 0.3311\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 10s 72ms/step - loss: 1.7463 - multi_accuracy_1: 0.3311 - val_loss: 1.1073 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.1045 - multi_accuracy_1: 0.3311 - val_loss: 1.1065 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.1000 - multi_accuracy_1: 0.3311 - val_loss: 1.1066 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0988 - multi_accuracy_1: 0.3311 - val_loss: 1.1071 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0982 - multi_accuracy_1: 0.3311 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.0975 - multi_accuracy_1: 0.3311 - val_loss: 1.1075 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0971 - multi_accuracy_1: 0.3310 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0963 - multi_accuracy_1: 0.3310 - val_loss: 1.1089 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 6s 67ms/step - loss: 1.0964 - multi_accuracy_1: 0.3310 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0960 - multi_accuracy_1: 0.3310 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0960 - multi_accuracy_1: 0.3310 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 6s 67ms/step - loss: 1.0955 - multi_accuracy_1: 0.3310 - val_loss: 1.1032 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0951 - multi_accuracy_1: 0.3310 - val_loss: 1.1050 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0947 - multi_accuracy_1: 0.3310 - val_loss: 1.1039 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0945 - multi_accuracy_1: 0.3310 - val_loss: 1.1044 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0941 - multi_accuracy_1: 0.3310 - val_loss: 1.1041 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 5s 55ms/step - loss: 1.0939 - multi_accuracy_1: 0.3310 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3310\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.1044 - multi_accuracy_1: 0.3310\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 11s 74ms/step - loss: 1.6067 - multi_accuracy_1: 0.3310 - val_loss: 1.1073 - val_multi_accuracy_1: 0.3310\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0988 - multi_accuracy_1: 0.3311 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0981 - multi_accuracy_1: 0.3311 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0974 - multi_accuracy_1: 0.3311 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.0968 - multi_accuracy_1: 0.3311 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0963 - multi_accuracy_1: 0.3311 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3311\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 1.0958 - multi_accuracy_1: 0.3312 - val_loss: 1.1001 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0952 - multi_accuracy_1: 0.3312 - val_loss: 1.1018 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 1.0947 - multi_accuracy_1: 0.3312 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3312\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 1.0943 - multi_accuracy_1: 0.3313 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.0937 - multi_accuracy_1: 0.3313 - val_loss: 1.0983 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.0933 - multi_accuracy_1: 0.3313 - val_loss: 1.0984 - val_multi_accuracy_1: 0.3313\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0934 - multi_accuracy_1: 0.3314 - val_loss: 1.0978 - val_multi_accuracy_1: 0.3314\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0928 - multi_accuracy_1: 0.3314 - val_loss: 1.1000 - val_multi_accuracy_1: 0.3314\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0926 - multi_accuracy_1: 0.3314 - val_loss: 1.0991 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0925 - multi_accuracy_1: 0.3315 - val_loss: 1.0979 - val_multi_accuracy_1: 0.3315\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0922 - multi_accuracy_1: 0.3315 - val_loss: 1.0946 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0923 - multi_accuracy_1: 0.3316 - val_loss: 1.0975 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0917 - multi_accuracy_1: 0.3316 - val_loss: 1.0947 - val_multi_accuracy_1: 0.3316\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0914 - multi_accuracy_1: 0.3317 - val_loss: 1.0988 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.0913 - multi_accuracy_1: 0.3317 - val_loss: 1.0961 - val_multi_accuracy_1: 0.3317\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0910 - multi_accuracy_1: 0.3317 - val_loss: 1.0967 - val_multi_accuracy_1: 0.3317\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 1.0986 - multi_accuracy_1: 0.3318\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 26s 194ms/step - loss: 4.5632 - multi_accuracy_1: 0.3318 - val_loss: 4.8490 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 5.2005 - multi_accuracy_1: 0.3318 - val_loss: 4.8482 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 5.2220 - multi_accuracy_1: 0.3318 - val_loss: 4.8708 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 5.2373 - multi_accuracy_1: 0.3318 - val_loss: 4.8793 - val_multi_accuracy_1: 0.3318\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 5.2380 - multi_accuracy_1: 0.3319 - val_loss: 4.8772 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 13s 164ms/step - loss: 5.2654 - multi_accuracy_1: 0.3319 - val_loss: 4.8692 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 14s 174ms/step - loss: 5.2119 - multi_accuracy_1: 0.3319 - val_loss: 4.8296 - val_multi_accuracy_1: 0.3319\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 14s 176ms/step - loss: 5.2118 - multi_accuracy_1: 0.3320 - val_loss: 4.8719 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 16s 197ms/step - loss: 5.2114 - multi_accuracy_1: 0.3320 - val_loss: 4.8529 - val_multi_accuracy_1: 0.3320\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 5.1742 - multi_accuracy_1: 0.3320 - val_loss: 4.8416 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 16s 190ms/step - loss: 5.1334 - multi_accuracy_1: 0.3321 - val_loss: 4.7997 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 15s 182ms/step - loss: 5.0811 - multi_accuracy_1: 0.3321 - val_loss: 4.8279 - val_multi_accuracy_1: 0.3321\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 15s 182ms/step - loss: 5.1230 - multi_accuracy_1: 0.3322 - val_loss: 4.8376 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 15s 178ms/step - loss: 5.1422 - multi_accuracy_1: 0.3322 - val_loss: 4.7969 - val_multi_accuracy_1: 0.3322\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 15s 188ms/step - loss: 5.1887 - multi_accuracy_1: 0.3322 - val_loss: 4.8834 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 15s 187ms/step - loss: 5.1978 - multi_accuracy_1: 0.3323 - val_loss: 4.7789 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 15s 187ms/step - loss: 5.0360 - multi_accuracy_1: 0.3323 - val_loss: 4.7491 - val_multi_accuracy_1: 0.3323\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 15s 187ms/step - loss: 5.0475 - multi_accuracy_1: 0.3324 - val_loss: 4.7283 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 16s 191ms/step - loss: 4.9382 - multi_accuracy_1: 0.3324 - val_loss: 4.4758 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 16s 196ms/step - loss: 4.9950 - multi_accuracy_1: 0.3324 - val_loss: 4.7857 - val_multi_accuracy_1: 0.3324\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 5.1952 - multi_accuracy_1: 0.3325 - val_loss: 5.0851 - val_multi_accuracy_1: 0.3325\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 16s 189ms/step - loss: 5.4149 - multi_accuracy_1: 0.3325 - val_loss: 5.0781 - val_multi_accuracy_1: 0.3325\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 4.6591 - multi_accuracy_1: 0.3326 - val_loss: 1.6928 - val_multi_accuracy_1: 0.3325\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 15s 188ms/step - loss: 1.7113 - multi_accuracy_1: 0.3326 - val_loss: 2.1898 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.8573 - multi_accuracy_1: 0.3326 - val_loss: 2.1779 - val_multi_accuracy_1: 0.3326\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 2.2038 - multi_accuracy_1: 0.3326\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 26s 194ms/step - loss: 1.4423 - multi_accuracy_1: 0.3326 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 1.0984 - multi_accuracy_1: 0.3326 - val_loss: 1.1097 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 1.0980 - multi_accuracy_1: 0.3326 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 14s 175ms/step - loss: 1.0980 - multi_accuracy_1: 0.3326 - val_loss: 1.1052 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 14s 174ms/step - loss: 1.0974 - multi_accuracy_1: 0.3326 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 15s 178ms/step - loss: 1.0973 - multi_accuracy_1: 0.3326 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 15s 182ms/step - loss: 1.0970 - multi_accuracy_1: 0.3326 - val_loss: 1.1086 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 12s 152ms/step - loss: 1.0969 - multi_accuracy_1: 0.3326 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 13s 164ms/step - loss: 1.0967 - multi_accuracy_1: 0.3326 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3326\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.1056 - multi_accuracy_1: 0.3326\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 26s 195ms/step - loss: 1.6701 - multi_accuracy_1: 0.3326 - val_loss: 1.1142 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 14s 167ms/step - loss: 1.1014 - multi_accuracy_1: 0.3326 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 182ms/step - loss: 1.0992 - multi_accuracy_1: 0.3326 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 14s 169ms/step - loss: 1.0984 - multi_accuracy_1: 0.3327 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 14s 171ms/step - loss: 1.0982 - multi_accuracy_1: 0.3327 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 1.0977 - multi_accuracy_1: 0.3327 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 15s 183ms/step - loss: 1.0969 - multi_accuracy_1: 0.3327 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 14s 171ms/step - loss: 1.0970 - multi_accuracy_1: 0.3327 - val_loss: 1.1062 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 13s 153ms/step - loss: 1.0966 - multi_accuracy_1: 0.3327 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 1.0966 - multi_accuracy_1: 0.3327 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 1.0961 - multi_accuracy_1: 0.3327 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 14s 167ms/step - loss: 1.0954 - multi_accuracy_1: 0.3328 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 13s 157ms/step - loss: 1.0954 - multi_accuracy_1: 0.3328 - val_loss: 1.1019 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 12s 141ms/step - loss: 1.0952 - multi_accuracy_1: 0.3328 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 1.0949 - multi_accuracy_1: 0.3328 - val_loss: 1.0977 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 1.0948 - multi_accuracy_1: 0.3328 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 11s 135ms/step - loss: 1.0942 - multi_accuracy_1: 0.3328 - val_loss: 1.1018 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 1.0934 - multi_accuracy_1: 0.3328 - val_loss: 1.0970 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 1.0932 - multi_accuracy_1: 0.3328 - val_loss: 1.1023 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 12s 145ms/step - loss: 1.0934 - multi_accuracy_1: 0.3328 - val_loss: 1.0996 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 12s 141ms/step - loss: 1.0930 - multi_accuracy_1: 0.3329 - val_loss: 1.0969 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 1.0928 - multi_accuracy_1: 0.3329 - val_loss: 1.0982 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 1.0923 - multi_accuracy_1: 0.3329 - val_loss: 1.0966 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 1.0923 - multi_accuracy_1: 0.3329 - val_loss: 1.0966 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 11s 135ms/step - loss: 1.0923 - multi_accuracy_1: 0.3329 - val_loss: 1.0968 - val_multi_accuracy_1: 0.3329\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 1.1005 - multi_accuracy_1: 0.3329\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 11s 76ms/step - loss: 2.4401 - multi_accuracy_1: 0.3329 - val_loss: 1.6875 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 1.8080 - multi_accuracy_1: 0.3329 - val_loss: 1.6884 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.8076 - multi_accuracy_1: 0.3329 - val_loss: 1.6881 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.8070 - multi_accuracy_1: 0.3329 - val_loss: 1.6852 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.8056 - multi_accuracy_1: 0.3329 - val_loss: 1.6841 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.8060 - multi_accuracy_1: 0.3329 - val_loss: 1.6825 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.8063 - multi_accuracy_1: 0.3329 - val_loss: 1.6834 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 6s 79ms/step - loss: 1.8056 - multi_accuracy_1: 0.3329 - val_loss: 1.6804 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.8048 - multi_accuracy_1: 0.3329 - val_loss: 1.6806 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 1.8036 - multi_accuracy_1: 0.3329 - val_loss: 1.6790 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 1.8035 - multi_accuracy_1: 0.3328 - val_loss: 1.6775 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.8026 - multi_accuracy_1: 0.3328 - val_loss: 1.6804 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 6s 67ms/step - loss: 1.8040 - multi_accuracy_1: 0.3328 - val_loss: 1.6825 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 1.8040 - multi_accuracy_1: 0.3327 - val_loss: 1.6775 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.8020 - multi_accuracy_1: 0.3327 - val_loss: 1.6781 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.8026 - multi_accuracy_1: 0.3327 - val_loss: 1.6796 - val_multi_accuracy_1: 0.3327\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 1.6977 - multi_accuracy_1: 0.3327\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 13s 78ms/step - loss: 2.4373 - multi_accuracy_1: 0.3327 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 6s 74ms/step - loss: 1.0989 - multi_accuracy_1: 0.3327 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 6s 74ms/step - loss: 1.0982 - multi_accuracy_1: 0.3327 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0981 - multi_accuracy_1: 0.3327 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0978 - multi_accuracy_1: 0.3327 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 6s 67ms/step - loss: 1.0977 - multi_accuracy_1: 0.3327 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0976 - multi_accuracy_1: 0.3327 - val_loss: 1.1095 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0974 - multi_accuracy_1: 0.3327 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 1.0973 - multi_accuracy_1: 0.3327 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3327\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 1.1049 - multi_accuracy_1: 0.3327\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 13s 76ms/step - loss: 1.6740 - multi_accuracy_1: 0.3327 - val_loss: 1.1148 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.1015 - multi_accuracy_1: 0.3327 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0988 - multi_accuracy_1: 0.3327 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 6s 67ms/step - loss: 1.0984 - multi_accuracy_1: 0.3327 - val_loss: 1.1039 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0977 - multi_accuracy_1: 0.3328 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0977 - multi_accuracy_1: 0.3328 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0972 - multi_accuracy_1: 0.3328 - val_loss: 1.1020 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0970 - multi_accuracy_1: 0.3328 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0966 - multi_accuracy_1: 0.3328 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 1.0962 - multi_accuracy_1: 0.3328 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0961 - multi_accuracy_1: 0.3328 - val_loss: 1.1031 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0961 - multi_accuracy_1: 0.3328 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3328\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 1.1038 - multi_accuracy_1: 0.3328\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 7s 42ms/step - loss: 3.1622 - multi_accuracy_1: 0.3328 - val_loss: 1.1161 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.1052 - multi_accuracy_1: 0.3328 - val_loss: 1.1110 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.1006 - multi_accuracy_1: 0.3328 - val_loss: 1.1094 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.0993 - multi_accuracy_1: 0.3328 - val_loss: 1.1075 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 3s 37ms/step - loss: 1.0990 - multi_accuracy_1: 0.3328 - val_loss: 1.1072 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0986 - multi_accuracy_1: 0.3328 - val_loss: 1.1082 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.0985 - multi_accuracy_1: 0.3328 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.0982 - multi_accuracy_1: 0.3328 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.0982 - multi_accuracy_1: 0.3328 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 3s 40ms/step - loss: 1.0982 - multi_accuracy_1: 0.3328 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.0978 - multi_accuracy_1: 0.3328 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.0978 - multi_accuracy_1: 0.3328 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0974 - multi_accuracy_1: 0.3328 - val_loss: 1.1083 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.0973 - multi_accuracy_1: 0.3328 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0972 - multi_accuracy_1: 0.3328 - val_loss: 1.1052 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.0971 - multi_accuracy_1: 0.3328 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.0969 - multi_accuracy_1: 0.3328 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3328\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.1052 - multi_accuracy_1: 0.3328\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 7s 47ms/step - loss: 4.3375 - multi_accuracy_1: 0.3328 - val_loss: 2.9143 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 3s 37ms/step - loss: 3.2548 - multi_accuracy_1: 0.3328 - val_loss: 3.1796 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 3.4582 - multi_accuracy_1: 0.3328 - val_loss: 3.3850 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 3.7371 - multi_accuracy_1: 0.3328 - val_loss: 2.5804 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 2.0537 - multi_accuracy_1: 0.3328 - val_loss: 1.8577 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.9524 - multi_accuracy_1: 0.3329 - val_loss: 1.8664 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.9568 - multi_accuracy_1: 0.3329 - val_loss: 1.8630 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.9497 - multi_accuracy_1: 0.3329 - val_loss: 1.8720 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.9402 - multi_accuracy_1: 0.3329 - val_loss: 1.8750 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.9482 - multi_accuracy_1: 0.3329 - val_loss: 1.8886 - val_multi_accuracy_1: 0.3329\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.9056 - multi_accuracy_1: 0.3329\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 7s 42ms/step - loss: 2.4355 - multi_accuracy_1: 0.3329 - val_loss: 1.1762 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.1324 - multi_accuracy_1: 0.3329 - val_loss: 1.1232 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.1081 - multi_accuracy_1: 0.3329 - val_loss: 1.1109 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.1017 - multi_accuracy_1: 0.3329 - val_loss: 1.1097 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.1001 - multi_accuracy_1: 0.3329 - val_loss: 1.1116 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.0996 - multi_accuracy_1: 0.3329 - val_loss: 1.1097 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.0993 - multi_accuracy_1: 0.3329 - val_loss: 1.1091 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0988 - multi_accuracy_1: 0.3329 - val_loss: 1.1090 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.0985 - multi_accuracy_1: 0.3329 - val_loss: 1.1082 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.0981 - multi_accuracy_1: 0.3329 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.0979 - multi_accuracy_1: 0.3329 - val_loss: 1.1080 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 3s 37ms/step - loss: 1.0978 - multi_accuracy_1: 0.3329 - val_loss: 1.1097 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.0979 - multi_accuracy_1: 0.3329 - val_loss: 1.1083 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.0974 - multi_accuracy_1: 0.3329 - val_loss: 1.1075 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0972 - multi_accuracy_1: 0.3329 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.0971 - multi_accuracy_1: 0.3328 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0971 - multi_accuracy_1: 0.3328 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0970 - multi_accuracy_1: 0.3328 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0967 - multi_accuracy_1: 0.3328 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0965 - multi_accuracy_1: 0.3328 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.0962 - multi_accuracy_1: 0.3328 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.0958 - multi_accuracy_1: 0.3328 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.0957 - multi_accuracy_1: 0.3328 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0948 - multi_accuracy_1: 0.3328 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0946 - multi_accuracy_1: 0.3328 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3328\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.1064 - multi_accuracy_1: 0.3328\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 21s 142ms/step - loss: 1.3104 - multi_accuracy_1: 0.3328 - val_loss: 1.1082 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 1.0974 - multi_accuracy_1: 0.3328 - val_loss: 1.1028 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 1.0972 - multi_accuracy_1: 0.3328 - val_loss: 1.1076 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 1.0972 - multi_accuracy_1: 0.3328 - val_loss: 1.0980 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 1.0968 - multi_accuracy_1: 0.3328 - val_loss: 1.1078 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 1.0955 - multi_accuracy_1: 0.3328 - val_loss: 1.0999 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 11s 140ms/step - loss: 1.0947 - multi_accuracy_1: 0.3329 - val_loss: 1.1032 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 1.0931 - multi_accuracy_1: 0.3329 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 1.0924 - multi_accuracy_1: 0.3329 - val_loss: 1.0970 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 1.0924 - multi_accuracy_1: 0.3329 - val_loss: 1.1018 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 1.0922 - multi_accuracy_1: 0.3330 - val_loss: 1.0936 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 11s 136ms/step - loss: 1.0923 - multi_accuracy_1: 0.3330 - val_loss: 1.0978 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 1.0918 - multi_accuracy_1: 0.3330 - val_loss: 1.1044 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 1.0919 - multi_accuracy_1: 0.3331 - val_loss: 1.1019 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 1.0915 - multi_accuracy_1: 0.3331 - val_loss: 1.0973 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 1.0917 - multi_accuracy_1: 0.3331 - val_loss: 1.0972 - val_multi_accuracy_1: 0.3331\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 1.0972 - multi_accuracy_1: 0.3332\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 21s 143ms/step - loss: 4.2821 - multi_accuracy_1: 0.3331 - val_loss: 3.5239 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 4.0222 - multi_accuracy_1: 0.3331 - val_loss: 3.5214 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 4.0060 - multi_accuracy_1: 0.3331 - val_loss: 3.5159 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 12s 144ms/step - loss: 3.9816 - multi_accuracy_1: 0.3331 - val_loss: 3.5175 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 3.9990 - multi_accuracy_1: 0.3331 - val_loss: 3.5177 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 4.0102 - multi_accuracy_1: 0.3331 - val_loss: 3.5174 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 3.9959 - multi_accuracy_1: 0.3331 - val_loss: 3.5158 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 4.0107 - multi_accuracy_1: 0.3331 - val_loss: 3.5154 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 3.9982 - multi_accuracy_1: 0.3331 - val_loss: 3.5145 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 4.0017 - multi_accuracy_1: 0.3331 - val_loss: 3.5149 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 3.9990 - multi_accuracy_1: 0.3331 - val_loss: 3.5160 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 10s 128ms/step - loss: 4.0057 - multi_accuracy_1: 0.3332 - val_loss: 3.5163 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 4.0040 - multi_accuracy_1: 0.3332 - val_loss: 3.5186 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 4.0133 - multi_accuracy_1: 0.3332 - val_loss: 3.5180 - val_multi_accuracy_1: 0.3332\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 3.3888 - multi_accuracy_1: 0.3332\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 22s 151ms/step - loss: 1.6686 - multi_accuracy_1: 0.3332 - val_loss: 1.1192 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 12s 145ms/step - loss: 1.0990 - multi_accuracy_1: 0.3332 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 1.0980 - multi_accuracy_1: 0.3332 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 1.0978 - multi_accuracy_1: 0.3332 - val_loss: 1.1065 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 11s 136ms/step - loss: 1.0973 - multi_accuracy_1: 0.3332 - val_loss: 1.1077 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 1.0972 - multi_accuracy_1: 0.3332 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 11s 137ms/step - loss: 1.0967 - multi_accuracy_1: 0.3332 - val_loss: 1.1065 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 11s 140ms/step - loss: 1.0968 - multi_accuracy_1: 0.3332 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 1.0962 - multi_accuracy_1: 0.3332 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 1.0958 - multi_accuracy_1: 0.3333 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 11s 136ms/step - loss: 1.0963 - multi_accuracy_1: 0.3333 - val_loss: 1.1021 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 12s 141ms/step - loss: 1.0956 - multi_accuracy_1: 0.3333 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 12s 140ms/step - loss: 1.0954 - multi_accuracy_1: 0.3333 - val_loss: 1.1019 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 11s 140ms/step - loss: 1.0952 - multi_accuracy_1: 0.3333 - val_loss: 1.1037 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 11s 128ms/step - loss: 1.0943 - multi_accuracy_1: 0.3333 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 1.0942 - multi_accuracy_1: 0.3333 - val_loss: 1.1012 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 12s 144ms/step - loss: 1.0937 - multi_accuracy_1: 0.3333 - val_loss: 1.1018 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 11s 132ms/step - loss: 1.0956 - multi_accuracy_1: 0.3333 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 11s 138ms/step - loss: 1.0946 - multi_accuracy_1: 0.3333 - val_loss: 1.1011 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 1.0933 - multi_accuracy_1: 0.3334 - val_loss: 1.1023 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 1.0934 - multi_accuracy_1: 0.3334 - val_loss: 1.1016 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 11s 134ms/step - loss: 1.0928 - multi_accuracy_1: 0.3334 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 12s 143ms/step - loss: 1.0926 - multi_accuracy_1: 0.3334 - val_loss: 1.0951 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 1.0924 - multi_accuracy_1: 0.3335 - val_loss: 1.0994 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 1.0919 - multi_accuracy_1: 0.3335 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3335\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 1.1096 - multi_accuracy_1: 0.3335\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 11s 73ms/step - loss: 1.8659 - multi_accuracy_1: 0.3335 - val_loss: 1.1159 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 6s 67ms/step - loss: 1.0999 - multi_accuracy_1: 0.3335 - val_loss: 1.1081 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0991 - multi_accuracy_1: 0.3335 - val_loss: 1.1075 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0983 - multi_accuracy_1: 0.3335 - val_loss: 1.1072 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0982 - multi_accuracy_1: 0.3335 - val_loss: 1.1072 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0977 - multi_accuracy_1: 0.3335 - val_loss: 1.1078 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0975 - multi_accuracy_1: 0.3335 - val_loss: 1.1044 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0971 - multi_accuracy_1: 0.3335 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0966 - multi_accuracy_1: 0.3336 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 6s 67ms/step - loss: 1.0960 - multi_accuracy_1: 0.3336 - val_loss: 1.1031 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0956 - multi_accuracy_1: 0.3336 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0950 - multi_accuracy_1: 0.3336 - val_loss: 1.1014 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0949 - multi_accuracy_1: 0.3336 - val_loss: 1.1019 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0945 - multi_accuracy_1: 0.3336 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0940 - multi_accuracy_1: 0.3336 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 6s 67ms/step - loss: 1.0935 - multi_accuracy_1: 0.3336 - val_loss: 1.1007 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0929 - multi_accuracy_1: 0.3336 - val_loss: 1.1083 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0928 - multi_accuracy_1: 0.3336 - val_loss: 1.1010 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0925 - multi_accuracy_1: 0.3336 - val_loss: 1.1014 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0920 - multi_accuracy_1: 0.3336 - val_loss: 1.0959 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0924 - multi_accuracy_1: 0.3336 - val_loss: 1.1021 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0912 - multi_accuracy_1: 0.3335 - val_loss: 1.1026 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0912 - multi_accuracy_1: 0.3335 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 5s 56ms/step - loss: 1.0912 - multi_accuracy_1: 0.3335 - val_loss: 1.0981 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 1.0911 - multi_accuracy_1: 0.3335 - val_loss: 1.0959 - val_multi_accuracy_1: 0.3335\n",
      "28/28 [==============================] - 1s 23ms/step - loss: 1.0994 - multi_accuracy_1: 0.3335\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 14s 88ms/step - loss: 4.6975 - multi_accuracy_1: 0.3335 - val_loss: 3.7215 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 3.1477 - multi_accuracy_1: 0.3335 - val_loss: 3.7521 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 3.1785 - multi_accuracy_1: 0.3335 - val_loss: 3.7644 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 3.2179 - multi_accuracy_1: 0.3336 - val_loss: 3.7764 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 3.2389 - multi_accuracy_1: 0.3336 - val_loss: 3.7925 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 6s 79ms/step - loss: 3.2580 - multi_accuracy_1: 0.3336 - val_loss: 3.7925 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.8466 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 14s 89ms/step - loss: 3.6952 - multi_accuracy_1: 0.3336 - val_loss: 1.9066 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.7550 - multi_accuracy_1: 0.3336 - val_loss: 1.8975 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 96ms/step - loss: 1.7524 - multi_accuracy_1: 0.3336 - val_loss: 1.8911 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 95ms/step - loss: 1.7514 - multi_accuracy_1: 0.3336 - val_loss: 1.8874 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 95ms/step - loss: 1.7510 - multi_accuracy_1: 0.3336 - val_loss: 1.8857 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.7503 - multi_accuracy_1: 0.3336 - val_loss: 1.8847 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 8s 96ms/step - loss: 1.7506 - multi_accuracy_1: 0.3336 - val_loss: 1.8845 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 8s 95ms/step - loss: 1.7502 - multi_accuracy_1: 0.3336 - val_loss: 1.8845 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.7499 - multi_accuracy_1: 0.3336 - val_loss: 1.8840 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 8s 97ms/step - loss: 1.7499 - multi_accuracy_1: 0.3336 - val_loss: 1.8837 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.7497 - multi_accuracy_1: 0.3336 - val_loss: 1.8837 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 8s 96ms/step - loss: 1.7495 - multi_accuracy_1: 0.3336 - val_loss: 1.8831 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 8s 97ms/step - loss: 1.7495 - multi_accuracy_1: 0.3337 - val_loss: 1.8820 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 8s 96ms/step - loss: 1.7488 - multi_accuracy_1: 0.3337 - val_loss: 1.8829 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 8s 97ms/step - loss: 1.7484 - multi_accuracy_1: 0.3337 - val_loss: 1.8827 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 8s 97ms/step - loss: 1.7485 - multi_accuracy_1: 0.3337 - val_loss: 1.8827 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 8s 97ms/step - loss: 1.7485 - multi_accuracy_1: 0.3337 - val_loss: 1.8822 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 8s 100ms/step - loss: 1.7480 - multi_accuracy_1: 0.3337 - val_loss: 1.8816 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 8s 99ms/step - loss: 1.7478 - multi_accuracy_1: 0.3337 - val_loss: 1.8832 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 8s 95ms/step - loss: 1.7480 - multi_accuracy_1: 0.3337 - val_loss: 1.8812 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 8s 97ms/step - loss: 1.7476 - multi_accuracy_1: 0.3337 - val_loss: 1.8818 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.7474 - multi_accuracy_1: 0.3338 - val_loss: 1.8814 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.7471 - multi_accuracy_1: 0.3338 - val_loss: 1.8798 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 8s 96ms/step - loss: 1.7472 - multi_accuracy_1: 0.3338 - val_loss: 1.8798 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 8s 96ms/step - loss: 1.7464 - multi_accuracy_1: 0.3338 - val_loss: 1.8790 - val_multi_accuracy_1: 0.3338\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 2.0062 - multi_accuracy_1: 0.3338\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 9s 54ms/step - loss: 3.2761 - multi_accuracy_1: 0.3338 - val_loss: 1.1289 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 4s 48ms/step - loss: 1.1063 - multi_accuracy_1: 0.3338 - val_loss: 1.1165 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.1019 - multi_accuracy_1: 0.3338 - val_loss: 1.1123 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0996 - multi_accuracy_1: 0.3338 - val_loss: 1.1093 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.0989 - multi_accuracy_1: 0.3338 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0981 - multi_accuracy_1: 0.3339 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0975 - multi_accuracy_1: 0.3339 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0975 - multi_accuracy_1: 0.3339 - val_loss: 1.1062 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 1.0972 - multi_accuracy_1: 0.3339 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 4s 48ms/step - loss: 1.0970 - multi_accuracy_1: 0.3339 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 1.0966 - multi_accuracy_1: 0.3339 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 1.0964 - multi_accuracy_1: 0.3339 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 1.0963 - multi_accuracy_1: 0.3339 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 1.0962 - multi_accuracy_1: 0.3339 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 1.0958 - multi_accuracy_1: 0.3339 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 1.0957 - multi_accuracy_1: 0.3339 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 4s 48ms/step - loss: 1.0955 - multi_accuracy_1: 0.3339 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.0954 - multi_accuracy_1: 0.3339 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.0950 - multi_accuracy_1: 0.3339 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3339\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1065 - multi_accuracy_1: 0.3339\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 10s 56ms/step - loss: 4.9225 - multi_accuracy_1: 0.3339 - val_loss: 3.5783 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 3.3415 - multi_accuracy_1: 0.3339 - val_loss: 2.9858 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0768 - multi_accuracy_1: 0.3339 - val_loss: 2.8935 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 3.0498 - multi_accuracy_1: 0.3339 - val_loss: 2.8906 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0477 - multi_accuracy_1: 0.3339 - val_loss: 2.8897 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 3.0467 - multi_accuracy_1: 0.3339 - val_loss: 2.8889 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0480 - multi_accuracy_1: 0.3339 - val_loss: 2.8884 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0481 - multi_accuracy_1: 0.3339 - val_loss: 2.8878 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0462 - multi_accuracy_1: 0.3339 - val_loss: 2.8878 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 3.0458 - multi_accuracy_1: 0.3339 - val_loss: 2.8872 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0467 - multi_accuracy_1: 0.3339 - val_loss: 2.8870 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 3.0459 - multi_accuracy_1: 0.3339 - val_loss: 2.8868 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0449 - multi_accuracy_1: 0.3339 - val_loss: 2.8882 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0434 - multi_accuracy_1: 0.3340 - val_loss: 2.8875 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0444 - multi_accuracy_1: 0.3340 - val_loss: 2.8863 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 3.0446 - multi_accuracy_1: 0.3340 - val_loss: 2.8863 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 4s 48ms/step - loss: 3.0448 - multi_accuracy_1: 0.3340 - val_loss: 2.8860 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0452 - multi_accuracy_1: 0.3340 - val_loss: 2.8856 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 3.0450 - multi_accuracy_1: 0.3340 - val_loss: 2.8866 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0442 - multi_accuracy_1: 0.3340 - val_loss: 2.8856 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 3.0449 - multi_accuracy_1: 0.3340 - val_loss: 2.8861 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0439 - multi_accuracy_1: 0.3340 - val_loss: 2.8857 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 3.0438 - multi_accuracy_1: 0.3340 - val_loss: 2.8866 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 3.0429 - multi_accuracy_1: 0.3340 - val_loss: 2.8842 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 3.0438 - multi_accuracy_1: 0.3340 - val_loss: 2.8846 - val_multi_accuracy_1: 0.3340\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.7526 - multi_accuracy_1: 0.3340\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 9s 55ms/step - loss: 1.7989 - multi_accuracy_1: 0.3340 - val_loss: 1.1030 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.1022 - multi_accuracy_1: 0.3340 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0993 - multi_accuracy_1: 0.3340 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.0983 - multi_accuracy_1: 0.3340 - val_loss: 1.1071 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.0978 - multi_accuracy_1: 0.3340 - val_loss: 1.1072 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.0974 - multi_accuracy_1: 0.3340 - val_loss: 1.1072 - val_multi_accuracy_1: 0.3340\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.0983 - multi_accuracy_1: 0.3340\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 28s 213ms/step - loss: 2.8229 - multi_accuracy_1: 0.3340 - val_loss: 2.8448 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 2.6455 - multi_accuracy_1: 0.3340 - val_loss: 2.7687 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 2.4151 - multi_accuracy_1: 0.3340 - val_loss: 2.3105 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 2.2039 - multi_accuracy_1: 0.3340 - val_loss: 1.9080 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 15s 189ms/step - loss: 2.1031 - multi_accuracy_1: 0.3340 - val_loss: 1.9055 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 16s 199ms/step - loss: 2.1340 - multi_accuracy_1: 0.3340 - val_loss: 1.9107 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 16s 199ms/step - loss: 2.0719 - multi_accuracy_1: 0.3340 - val_loss: 1.9109 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 2.0543 - multi_accuracy_1: 0.3340 - val_loss: 1.9007 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 16s 200ms/step - loss: 2.0743 - multi_accuracy_1: 0.3341 - val_loss: 1.9089 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 17s 202ms/step - loss: 2.0622 - multi_accuracy_1: 0.3341 - val_loss: 1.8978 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 16s 200ms/step - loss: 2.0802 - multi_accuracy_1: 0.3341 - val_loss: 1.9527 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 16s 199ms/step - loss: 2.1005 - multi_accuracy_1: 0.3341 - val_loss: 1.9018 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 16s 197ms/step - loss: 2.0881 - multi_accuracy_1: 0.3341 - val_loss: 2.0588 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 16s 198ms/step - loss: 2.1932 - multi_accuracy_1: 0.3342 - val_loss: 2.1025 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 16s 197ms/step - loss: 2.1987 - multi_accuracy_1: 0.3342 - val_loss: 2.2503 - val_multi_accuracy_1: 0.3342\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 1.9212 - multi_accuracy_1: 0.3342\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 27s 200ms/step - loss: 1.2038 - multi_accuracy_1: 0.3342 - val_loss: 1.1151 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 1.0974 - multi_accuracy_1: 0.3342 - val_loss: 1.1081 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 16s 191ms/step - loss: 1.0962 - multi_accuracy_1: 0.3342 - val_loss: 1.1000 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 14s 176ms/step - loss: 1.0948 - multi_accuracy_1: 0.3342 - val_loss: 1.1028 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 16s 191ms/step - loss: 1.0937 - multi_accuracy_1: 0.3343 - val_loss: 1.1020 - val_multi_accuracy_1: 0.3343\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 15s 187ms/step - loss: 1.0934 - multi_accuracy_1: 0.3343 - val_loss: 1.0932 - val_multi_accuracy_1: 0.3343\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 15s 183ms/step - loss: 1.0932 - multi_accuracy_1: 0.3343 - val_loss: 1.1002 - val_multi_accuracy_1: 0.3343\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 1.0930 - multi_accuracy_1: 0.3343 - val_loss: 1.0995 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 15s 187ms/step - loss: 1.0928 - multi_accuracy_1: 0.3344 - val_loss: 1.0961 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 16s 197ms/step - loss: 1.0924 - multi_accuracy_1: 0.3344 - val_loss: 1.1016 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 16s 190ms/step - loss: 1.0921 - multi_accuracy_1: 0.3344 - val_loss: 1.1026 - val_multi_accuracy_1: 0.3344\n",
      "28/28 [==============================] - 2s 58ms/step - loss: 1.0960 - multi_accuracy_1: 0.3344\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 26s 194ms/step - loss: 3.6375 - multi_accuracy_1: 0.3345 - val_loss: 3.2267 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 3.4679 - multi_accuracy_1: 0.3345 - val_loss: 3.2249 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 189ms/step - loss: 3.4967 - multi_accuracy_1: 0.3345 - val_loss: 3.2233 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 15s 182ms/step - loss: 3.5224 - multi_accuracy_1: 0.3345 - val_loss: 3.2212 - val_multi_accuracy_1: 0.3345\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 15s 188ms/step - loss: 3.5514 - multi_accuracy_1: 0.3345 - val_loss: 3.2283 - val_multi_accuracy_1: 0.3345\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 15s 184ms/step - loss: 3.5480 - multi_accuracy_1: 0.3345 - val_loss: 3.2212 - val_multi_accuracy_1: 0.3345\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 15s 182ms/step - loss: 3.5504 - multi_accuracy_1: 0.3345 - val_loss: 3.2303 - val_multi_accuracy_1: 0.3345\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 16s 198ms/step - loss: 3.5379 - multi_accuracy_1: 0.3345 - val_loss: 3.2294 - val_multi_accuracy_1: 0.3345\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 3.5445 - multi_accuracy_1: 0.3345 - val_loss: 3.2356 - val_multi_accuracy_1: 0.3345\n",
      "28/28 [==============================] - 2s 57ms/step - loss: 3.2357 - multi_accuracy_1: 0.3345\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 16s 103ms/step - loss: 1.3527 - multi_accuracy_1: 0.3345 - val_loss: 1.1033 - val_multi_accuracy_1: 0.3345\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 92ms/step - loss: 1.0977 - multi_accuracy_1: 0.3344 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0970 - multi_accuracy_1: 0.3344 - val_loss: 1.1039 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.0965 - multi_accuracy_1: 0.3344 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0962 - multi_accuracy_1: 0.3344 - val_loss: 1.1083 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0961 - multi_accuracy_1: 0.3344 - val_loss: 1.1002 - val_multi_accuracy_1: 0.3344\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.0957 - multi_accuracy_1: 0.3344 - val_loss: 1.0997 - val_multi_accuracy_1: 0.3343\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0955 - multi_accuracy_1: 0.3343 - val_loss: 1.0972 - val_multi_accuracy_1: 0.3343\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0951 - multi_accuracy_1: 0.3343 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3343\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0948 - multi_accuracy_1: 0.3343 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3343\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0938 - multi_accuracy_1: 0.3343 - val_loss: 1.0998 - val_multi_accuracy_1: 0.3343\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.0931 - multi_accuracy_1: 0.3342 - val_loss: 1.1030 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 8s 91ms/step - loss: 1.0923 - multi_accuracy_1: 0.3342 - val_loss: 1.1002 - val_multi_accuracy_1: 0.3342\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.1000 - multi_accuracy_1: 0.3342\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 14s 97ms/step - loss: 1.6288 - multi_accuracy_1: 0.3342 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.0987 - multi_accuracy_1: 0.3342 - val_loss: 1.1111 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0984 - multi_accuracy_1: 0.3342 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0981 - multi_accuracy_1: 0.3342 - val_loss: 1.1101 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.0979 - multi_accuracy_1: 0.3342 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0979 - multi_accuracy_1: 0.3342 - val_loss: 1.1103 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0978 - multi_accuracy_1: 0.3342 - val_loss: 1.1106 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0974 - multi_accuracy_1: 0.3342 - val_loss: 1.1073 - val_multi_accuracy_1: 0.3342\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.1057 - multi_accuracy_1: 0.3342\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 16s 102ms/step - loss: 3.9682 - multi_accuracy_1: 0.3342 - val_loss: 2.9758 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 3.3062 - multi_accuracy_1: 0.3342 - val_loss: 2.9714 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 3.3056 - multi_accuracy_1: 0.3342 - val_loss: 2.9740 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 3.3052 - multi_accuracy_1: 0.3342 - val_loss: 2.9709 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 3.3047 - multi_accuracy_1: 0.3342 - val_loss: 2.9717 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 3.3044 - multi_accuracy_1: 0.3342 - val_loss: 2.9716 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 3.3043 - multi_accuracy_1: 0.3342 - val_loss: 2.9715 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 3.3038 - multi_accuracy_1: 0.3342 - val_loss: 2.9717 - val_multi_accuracy_1: 0.3342\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 3.3035 - multi_accuracy_1: 0.3341 - val_loss: 2.9700 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 3.3035 - multi_accuracy_1: 0.3341 - val_loss: 2.9703 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 3.3031 - multi_accuracy_1: 0.3341 - val_loss: 2.9716 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 3.3030 - multi_accuracy_1: 0.3341 - val_loss: 2.9697 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 3.3027 - multi_accuracy_1: 0.3341 - val_loss: 2.9696 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 3.3028 - multi_accuracy_1: 0.3341 - val_loss: 2.9722 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 3.3023 - multi_accuracy_1: 0.3341 - val_loss: 2.9706 - val_multi_accuracy_1: 0.3341\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 3.3022 - multi_accuracy_1: 0.3340 - val_loss: 2.9710 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 3.3023 - multi_accuracy_1: 0.3340 - val_loss: 2.9704 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 3.3022 - multi_accuracy_1: 0.3340 - val_loss: 2.9683 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 3.3021 - multi_accuracy_1: 0.3340 - val_loss: 2.9684 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 3.3019 - multi_accuracy_1: 0.3340 - val_loss: 2.9691 - val_multi_accuracy_1: 0.3340\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 3.3019 - multi_accuracy_1: 0.3340 - val_loss: 2.9694 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 3.3020 - multi_accuracy_1: 0.3339 - val_loss: 2.9688 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 3.3019 - multi_accuracy_1: 0.3339 - val_loss: 2.9681 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 3.3018 - multi_accuracy_1: 0.3339 - val_loss: 2.9693 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 3.3017 - multi_accuracy_1: 0.3339 - val_loss: 2.9676 - val_multi_accuracy_1: 0.3339\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.7573 - multi_accuracy_1: 0.3339\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 9s 53ms/step - loss: 1.6535 - multi_accuracy_1: 0.3339 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 3s 42ms/step - loss: 1.0984 - multi_accuracy_1: 0.3338 - val_loss: 1.1082 - val_multi_accuracy_1: 0.3339\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 1.0974 - multi_accuracy_1: 0.3338 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 3s 42ms/step - loss: 1.0962 - multi_accuracy_1: 0.3338 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0951 - multi_accuracy_1: 0.3338 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 1.0946 - multi_accuracy_1: 0.3338 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0936 - multi_accuracy_1: 0.3337 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 1.0934 - multi_accuracy_1: 0.3337 - val_loss: 1.0984 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 4s 43ms/step - loss: 1.0924 - multi_accuracy_1: 0.3337 - val_loss: 1.0989 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0922 - multi_accuracy_1: 0.3336 - val_loss: 1.0937 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 4s 43ms/step - loss: 1.0916 - multi_accuracy_1: 0.3336 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0916 - multi_accuracy_1: 0.3336 - val_loss: 1.0960 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 1.0908 - multi_accuracy_1: 0.3335 - val_loss: 1.0951 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 1.0909 - multi_accuracy_1: 0.3335 - val_loss: 1.0975 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 4s 43ms/step - loss: 1.0906 - multi_accuracy_1: 0.3335 - val_loss: 1.1011 - val_multi_accuracy_1: 0.3334\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.0971 - multi_accuracy_1: 0.3334\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 10s 53ms/step - loss: 2.5108 - multi_accuracy_1: 0.3334 - val_loss: 1.1226 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.1091 - multi_accuracy_1: 0.3334 - val_loss: 1.1113 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.1042 - multi_accuracy_1: 0.3334 - val_loss: 1.1104 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.1020 - multi_accuracy_1: 0.3334 - val_loss: 1.1092 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.1007 - multi_accuracy_1: 0.3334 - val_loss: 1.1078 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 1.1006 - multi_accuracy_1: 0.3334 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 4s 48ms/step - loss: 1.0996 - multi_accuracy_1: 0.3334 - val_loss: 1.1063 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 4s 43ms/step - loss: 1.0990 - multi_accuracy_1: 0.3334 - val_loss: 1.1066 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0989 - multi_accuracy_1: 0.3334 - val_loss: 1.1059 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0984 - multi_accuracy_1: 0.3334 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.0982 - multi_accuracy_1: 0.3334 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0979 - multi_accuracy_1: 0.3334 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 4s 47ms/step - loss: 1.0977 - multi_accuracy_1: 0.3334 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0976 - multi_accuracy_1: 0.3334 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0972 - multi_accuracy_1: 0.3334 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0973 - multi_accuracy_1: 0.3334 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 4s 48ms/step - loss: 1.0971 - multi_accuracy_1: 0.3334 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0969 - multi_accuracy_1: 0.3334 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.0967 - multi_accuracy_1: 0.3334 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3334\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1058 - multi_accuracy_1: 0.3334\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 9s 56ms/step - loss: 2.2994 - multi_accuracy_1: 0.3334 - val_loss: 1.1126 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.1050 - multi_accuracy_1: 0.3334 - val_loss: 1.1071 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.1010 - multi_accuracy_1: 0.3334 - val_loss: 1.1080 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.1001 - multi_accuracy_1: 0.3334 - val_loss: 1.1082 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 4s 46ms/step - loss: 1.0992 - multi_accuracy_1: 0.3334 - val_loss: 1.1077 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 1.0990 - multi_accuracy_1: 0.3334 - val_loss: 1.1075 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 1.0984 - multi_accuracy_1: 0.3334 - val_loss: 1.1075 - val_multi_accuracy_1: 0.3334\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.1055 - multi_accuracy_1: 0.3334\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 43s 389ms/step - loss: 1.6989 - multi_accuracy_1: 0.3334 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 29s 353ms/step - loss: 1.0957 - multi_accuracy_1: 0.3334 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 30s 371ms/step - loss: 1.0950 - multi_accuracy_1: 0.3334 - val_loss: 1.1063 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 31s 373ms/step - loss: 1.0951 - multi_accuracy_1: 0.3334 - val_loss: 1.1005 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 30s 370ms/step - loss: 1.0940 - multi_accuracy_1: 0.3335 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 31s 383ms/step - loss: 1.0940 - multi_accuracy_1: 0.3335 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 31s 376ms/step - loss: 1.0936 - multi_accuracy_1: 0.3335 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 31s 378ms/step - loss: 1.0933 - multi_accuracy_1: 0.3335 - val_loss: 1.1050 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 31s 374ms/step - loss: 1.0933 - multi_accuracy_1: 0.3336 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 1.1017 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 43s 393ms/step - loss: 2.6938 - multi_accuracy_1: 0.3336 - val_loss: 2.0748 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 31s 377ms/step - loss: 1.9989 - multi_accuracy_1: 0.3336 - val_loss: 1.9621 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 31s 375ms/step - loss: 1.9905 - multi_accuracy_1: 0.3336 - val_loss: 1.9605 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 31s 384ms/step - loss: 1.9987 - multi_accuracy_1: 0.3336 - val_loss: 1.9579 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 29s 359ms/step - loss: 1.9998 - multi_accuracy_1: 0.3336 - val_loss: 1.9590 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 28s 347ms/step - loss: 1.9955 - multi_accuracy_1: 0.3336 - val_loss: 1.9603 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 31s 384ms/step - loss: 1.9979 - multi_accuracy_1: 0.3336 - val_loss: 1.9652 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 31s 378ms/step - loss: 2.0008 - multi_accuracy_1: 0.3336 - val_loss: 1.9552 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 32s 385ms/step - loss: 1.9981 - multi_accuracy_1: 0.3336 - val_loss: 1.9627 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 31s 373ms/step - loss: 1.9884 - multi_accuracy_1: 0.3336 - val_loss: 1.9584 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 30s 367ms/step - loss: 1.9921 - multi_accuracy_1: 0.3336 - val_loss: 1.9594 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 31s 380ms/step - loss: 1.9903 - multi_accuracy_1: 0.3336 - val_loss: 1.9607 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 32s 387ms/step - loss: 1.9843 - multi_accuracy_1: 0.3336 - val_loss: 1.9625 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 3s 106ms/step - loss: 1.9650 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 43s 395ms/step - loss: 5.9909 - multi_accuracy_1: 0.3336 - val_loss: 5.9706 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 29s 354ms/step - loss: 4.0297 - multi_accuracy_1: 0.3336 - val_loss: 4.1223 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 31s 384ms/step - loss: 3.3956 - multi_accuracy_1: 0.3336 - val_loss: 3.3307 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 30s 369ms/step - loss: 3.1991 - multi_accuracy_1: 0.3336 - val_loss: 3.3237 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 29s 359ms/step - loss: 3.1944 - multi_accuracy_1: 0.3336 - val_loss: 3.3195 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 29s 360ms/step - loss: 3.1927 - multi_accuracy_1: 0.3336 - val_loss: 3.3165 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 30s 371ms/step - loss: 3.1924 - multi_accuracy_1: 0.3336 - val_loss: 3.3187 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 29s 361ms/step - loss: 3.1923 - multi_accuracy_1: 0.3336 - val_loss: 3.3166 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 30s 367ms/step - loss: 3.1924 - multi_accuracy_1: 0.3336 - val_loss: 3.3175 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 30s 362ms/step - loss: 3.1922 - multi_accuracy_1: 0.3336 - val_loss: 3.3163 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 31s 381ms/step - loss: 3.1920 - multi_accuracy_1: 0.3337 - val_loss: 3.3175 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 30s 371ms/step - loss: 3.1921 - multi_accuracy_1: 0.3337 - val_loss: 3.3171 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 31s 375ms/step - loss: 3.1919 - multi_accuracy_1: 0.3337 - val_loss: 3.3189 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 31s 381ms/step - loss: 3.1922 - multi_accuracy_1: 0.3337 - val_loss: 3.3160 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 30s 371ms/step - loss: 3.1920 - multi_accuracy_1: 0.3337 - val_loss: 3.3170 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 31s 373ms/step - loss: 3.1920 - multi_accuracy_1: 0.3337 - val_loss: 3.3187 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 30s 371ms/step - loss: 3.1919 - multi_accuracy_1: 0.3337 - val_loss: 3.3153 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 31s 375ms/step - loss: 3.1919 - multi_accuracy_1: 0.3337 - val_loss: 3.3160 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 28s 338ms/step - loss: 3.1921 - multi_accuracy_1: 0.3337 - val_loss: 3.3156 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 23s 277ms/step - loss: 3.1919 - multi_accuracy_1: 0.3337 - val_loss: 3.3186 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 23s 285ms/step - loss: 3.1917 - multi_accuracy_1: 0.3337 - val_loss: 3.3170 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 30s 368ms/step - loss: 3.1919 - multi_accuracy_1: 0.3337 - val_loss: 3.3178 - val_multi_accuracy_1: 0.3337\n",
      "28/28 [==============================] - 3s 108ms/step - loss: 3.3326 - multi_accuracy_1: 0.3337\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 24s 193ms/step - loss: 2.8842 - multi_accuracy_1: 0.3337 - val_loss: 1.1274 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 1.1047 - multi_accuracy_1: 0.3337 - val_loss: 1.1108 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 183ms/step - loss: 1.0996 - multi_accuracy_1: 0.3337 - val_loss: 1.1083 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 1.0986 - multi_accuracy_1: 0.3337 - val_loss: 1.1066 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 15s 184ms/step - loss: 1.0979 - multi_accuracy_1: 0.3337 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 15s 184ms/step - loss: 1.0976 - multi_accuracy_1: 0.3337 - val_loss: 1.1063 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 1.0973 - multi_accuracy_1: 0.3337 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 15s 180ms/step - loss: 1.0968 - multi_accuracy_1: 0.3337 - val_loss: 1.1030 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 15s 180ms/step - loss: 1.0966 - multi_accuracy_1: 0.3337 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 14s 176ms/step - loss: 1.0960 - multi_accuracy_1: 0.3337 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 1.0962 - multi_accuracy_1: 0.3337 - val_loss: 1.1021 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 15s 184ms/step - loss: 1.0959 - multi_accuracy_1: 0.3337 - val_loss: 1.1033 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 15s 180ms/step - loss: 1.0954 - multi_accuracy_1: 0.3337 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 1.0948 - multi_accuracy_1: 0.3337 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 14s 175ms/step - loss: 1.0946 - multi_accuracy_1: 0.3338 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 1.0943 - multi_accuracy_1: 0.3338 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3338\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1033 - multi_accuracy_1: 0.3338\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 22s 195ms/step - loss: 3.3511 - multi_accuracy_1: 0.3338 - val_loss: 3.8246 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 3.0956 - multi_accuracy_1: 0.3338 - val_loss: 3.8144 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 183ms/step - loss: 3.0734 - multi_accuracy_1: 0.3338 - val_loss: 3.7947 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 14s 174ms/step - loss: 3.0681 - multi_accuracy_1: 0.3338 - val_loss: 3.7582 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 15s 182ms/step - loss: 3.0489 - multi_accuracy_1: 0.3337 - val_loss: 3.7502 - val_multi_accuracy_1: 0.3338\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 15s 188ms/step - loss: 3.0770 - multi_accuracy_1: 0.3337 - val_loss: 3.7889 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 15s 188ms/step - loss: 3.1136 - multi_accuracy_1: 0.3337 - val_loss: 3.8553 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 3.1355 - multi_accuracy_1: 0.3337 - val_loss: 3.8533 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 3.1883 - multi_accuracy_1: 0.3337 - val_loss: 3.9372 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 3.1962 - multi_accuracy_1: 0.3337 - val_loss: 3.9354 - val_multi_accuracy_1: 0.3337\n",
      "28/28 [==============================] - 2s 60ms/step - loss: 3.7100 - multi_accuracy_1: 0.3337\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 23s 200ms/step - loss: 1.6863 - multi_accuracy_1: 0.3337 - val_loss: 1.1129 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 15s 178ms/step - loss: 1.1025 - multi_accuracy_1: 0.3337 - val_loss: 1.1110 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 188ms/step - loss: 1.1000 - multi_accuracy_1: 0.3337 - val_loss: 1.1084 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 15s 187ms/step - loss: 1.0992 - multi_accuracy_1: 0.3337 - val_loss: 1.1087 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 15s 188ms/step - loss: 1.0985 - multi_accuracy_1: 0.3337 - val_loss: 1.1096 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0982 - multi_accuracy_1: 0.3337 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 14s 171ms/step - loss: 1.0978 - multi_accuracy_1: 0.3337 - val_loss: 1.1086 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 14s 174ms/step - loss: 1.0976 - multi_accuracy_1: 0.3337 - val_loss: 1.1094 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 14s 175ms/step - loss: 1.0975 - multi_accuracy_1: 0.3337 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 15s 178ms/step - loss: 1.0975 - multi_accuracy_1: 0.3337 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 14s 169ms/step - loss: 1.0974 - multi_accuracy_1: 0.3337 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 15s 178ms/step - loss: 1.0968 - multi_accuracy_1: 0.3337 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 15s 178ms/step - loss: 1.0968 - multi_accuracy_1: 0.3337 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 15s 179ms/step - loss: 1.0962 - multi_accuracy_1: 0.3337 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 14s 176ms/step - loss: 1.0960 - multi_accuracy_1: 0.3337 - val_loss: 1.1019 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 1.0957 - multi_accuracy_1: 0.3337 - val_loss: 1.1037 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 15s 178ms/step - loss: 1.0952 - multi_accuracy_1: 0.3337 - val_loss: 1.1033 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 15s 178ms/step - loss: 1.0951 - multi_accuracy_1: 0.3337 - val_loss: 1.1038 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 15s 183ms/step - loss: 1.0946 - multi_accuracy_1: 0.3337 - val_loss: 1.1022 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 15s 178ms/step - loss: 1.0942 - multi_accuracy_1: 0.3337 - val_loss: 1.1020 - val_multi_accuracy_1: 0.3337\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 1.1044 - multi_accuracy_1: 0.3337\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 12s 98ms/step - loss: 1.7770 - multi_accuracy_1: 0.3337 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.1017 - multi_accuracy_1: 0.3337 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0999 - multi_accuracy_1: 0.3337 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0991 - multi_accuracy_1: 0.3337 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0987 - multi_accuracy_1: 0.3337 - val_loss: 1.1059 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0980 - multi_accuracy_1: 0.3337 - val_loss: 1.1065 - val_multi_accuracy_1: 0.3337\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1026 - multi_accuracy_1: 0.3337\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 13s 102ms/step - loss: 1.4949 - multi_accuracy_1: 0.3337 - val_loss: 1.1082 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.0995 - multi_accuracy_1: 0.3337 - val_loss: 1.1075 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0981 - multi_accuracy_1: 0.3337 - val_loss: 1.1005 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.0975 - multi_accuracy_1: 0.3336 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0972 - multi_accuracy_1: 0.3336 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0965 - multi_accuracy_1: 0.3336 - val_loss: 1.1028 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.0961 - multi_accuracy_1: 0.3336 - val_loss: 1.1077 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0960 - multi_accuracy_1: 0.3336 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.1004 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 13s 101ms/step - loss: 4.1561 - multi_accuracy_1: 0.3336 - val_loss: 1.3658 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.1577 - multi_accuracy_1: 0.3336 - val_loss: 1.1073 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 93ms/step - loss: 1.1121 - multi_accuracy_1: 0.3336 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.1052 - multi_accuracy_1: 0.3336 - val_loss: 1.1065 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.1021 - multi_accuracy_1: 0.3336 - val_loss: 1.1084 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.1012 - multi_accuracy_1: 0.3336 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 8s 96ms/step - loss: 1.1005 - multi_accuracy_1: 0.3336 - val_loss: 1.1095 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.1003 - multi_accuracy_1: 0.3336 - val_loss: 1.1095 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 1.1028 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 33s 278ms/step - loss: 6.2531 - multi_accuracy_1: 0.3336 - val_loss: 5.0800 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 23s 277ms/step - loss: 5.7097 - multi_accuracy_1: 0.3336 - val_loss: 5.2034 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 23s 283ms/step - loss: 5.8020 - multi_accuracy_1: 0.3336 - val_loss: 5.3241 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 22s 271ms/step - loss: 5.8241 - multi_accuracy_1: 0.3336 - val_loss: 5.3108 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 22s 272ms/step - loss: 5.8069 - multi_accuracy_1: 0.3336 - val_loss: 5.3055 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 22s 272ms/step - loss: 5.8286 - multi_accuracy_1: 0.3336 - val_loss: 5.3851 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 4.8068 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 33s 276ms/step - loss: 1.3891 - multi_accuracy_1: 0.3336 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 23s 276ms/step - loss: 1.0977 - multi_accuracy_1: 0.3336 - val_loss: 1.1013 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 23s 279ms/step - loss: 1.0977 - multi_accuracy_1: 0.3336 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 22s 263ms/step - loss: 1.0976 - multi_accuracy_1: 0.3336 - val_loss: 1.1006 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 22s 271ms/step - loss: 1.0972 - multi_accuracy_1: 0.3336 - val_loss: 1.1092 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 22s 265ms/step - loss: 1.0968 - multi_accuracy_1: 0.3336 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 24s 290ms/step - loss: 1.0967 - multi_accuracy_1: 0.3336 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 25s 305ms/step - loss: 1.0961 - multi_accuracy_1: 0.3336 - val_loss: 1.0994 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 22s 269ms/step - loss: 1.0957 - multi_accuracy_1: 0.3336 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 24s 295ms/step - loss: 1.0952 - multi_accuracy_1: 0.3336 - val_loss: 1.0980 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 27s 336ms/step - loss: 1.0972 - multi_accuracy_1: 0.3336 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 29s 351ms/step - loss: 1.0956 - multi_accuracy_1: 0.3336 - val_loss: 1.1012 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 27s 328ms/step - loss: 1.0943 - multi_accuracy_1: 0.3336 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 27s 330ms/step - loss: 1.0934 - multi_accuracy_1: 0.3336 - val_loss: 1.0970 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 27s 331ms/step - loss: 1.0927 - multi_accuracy_1: 0.3337 - val_loss: 1.0977 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 27s 327ms/step - loss: 1.0927 - multi_accuracy_1: 0.3337 - val_loss: 1.0967 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 27s 327ms/step - loss: 1.0924 - multi_accuracy_1: 0.3337 - val_loss: 1.0930 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 28s 337ms/step - loss: 1.0922 - multi_accuracy_1: 0.3337 - val_loss: 1.0951 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 27s 329ms/step - loss: 1.0918 - multi_accuracy_1: 0.3337 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 27s 323ms/step - loss: 1.0922 - multi_accuracy_1: 0.3337 - val_loss: 1.0969 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 26s 321ms/step - loss: 1.0928 - multi_accuracy_1: 0.3337 - val_loss: 1.0988 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 25s 311ms/step - loss: 1.0921 - multi_accuracy_1: 0.3337 - val_loss: 1.1020 - val_multi_accuracy_1: 0.3337\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 1.0946 - multi_accuracy_1: 0.3337\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 37s 342ms/step - loss: 1.1732 - multi_accuracy_1: 0.3337 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 27s 331ms/step - loss: 1.0960 - multi_accuracy_1: 0.3337 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 28s 345ms/step - loss: 1.0958 - multi_accuracy_1: 0.3337 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 28s 340ms/step - loss: 1.0956 - multi_accuracy_1: 0.3337 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 30s 369ms/step - loss: 1.0949 - multi_accuracy_1: 0.3337 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 29s 360ms/step - loss: 1.0947 - multi_accuracy_1: 0.3337 - val_loss: 1.1019 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 29s 358ms/step - loss: 1.0936 - multi_accuracy_1: 0.3336 - val_loss: 1.1011 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 29s 355ms/step - loss: 1.1300 - multi_accuracy_1: 0.3336 - val_loss: 1.1135 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 28s 346ms/step - loss: 1.0976 - multi_accuracy_1: 0.3336 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 28s 342ms/step - loss: 1.0967 - multi_accuracy_1: 0.3336 - val_loss: 1.1062 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 29s 355ms/step - loss: 1.0963 - multi_accuracy_1: 0.3336 - val_loss: 1.1026 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 28s 336ms/step - loss: 1.0964 - multi_accuracy_1: 0.3336 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 1.1062 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 20s 164ms/step - loss: 1.7465 - multi_accuracy_1: 0.3336 - val_loss: 1.1081 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 1.0977 - multi_accuracy_1: 0.3336 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 1.0967 - multi_accuracy_1: 0.3336 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 15s 177ms/step - loss: 1.0972 - multi_accuracy_1: 0.3336 - val_loss: 1.1002 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 1.0966 - multi_accuracy_1: 0.3335 - val_loss: 1.0991 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 1.0964 - multi_accuracy_1: 0.3335 - val_loss: 1.1018 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0966 - multi_accuracy_1: 0.3335 - val_loss: 1.0992 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 1.0963 - multi_accuracy_1: 0.3335 - val_loss: 1.1023 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0963 - multi_accuracy_1: 0.3335 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0957 - multi_accuracy_1: 0.3335 - val_loss: 1.1033 - val_multi_accuracy_1: 0.3335\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.1010 - multi_accuracy_1: 0.3335\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 23s 208ms/step - loss: 1.4095 - multi_accuracy_1: 0.3335 - val_loss: 1.1019 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0985 - multi_accuracy_1: 0.3335 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 1.0974 - multi_accuracy_1: 0.3335 - val_loss: 1.1038 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0969 - multi_accuracy_1: 0.3335 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0966 - multi_accuracy_1: 0.3335 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 15s 187ms/step - loss: 1.0963 - multi_accuracy_1: 0.3335 - val_loss: 1.1052 - val_multi_accuracy_1: 0.3335\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 1.1025 - multi_accuracy_1: 0.3335\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 22s 196ms/step - loss: 3.2551 - multi_accuracy_1: 0.3335 - val_loss: 1.1137 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 15s 182ms/step - loss: 1.1024 - multi_accuracy_1: 0.3335 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 184ms/step - loss: 1.0988 - multi_accuracy_1: 0.3335 - val_loss: 1.1062 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0981 - multi_accuracy_1: 0.3335 - val_loss: 1.1052 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 15s 184ms/step - loss: 1.0981 - multi_accuracy_1: 0.3335 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 15s 187ms/step - loss: 1.0975 - multi_accuracy_1: 0.3335 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 15s 184ms/step - loss: 1.0967 - multi_accuracy_1: 0.3335 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 14s 174ms/step - loss: 1.0970 - multi_accuracy_1: 0.3335 - val_loss: 1.1041 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0969 - multi_accuracy_1: 0.3335 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 1.0967 - multi_accuracy_1: 0.3335 - val_loss: 1.1039 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 1.0965 - multi_accuracy_1: 0.3335 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 15s 182ms/step - loss: 1.0957 - multi_accuracy_1: 0.3335 - val_loss: 1.1028 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 1.0960 - multi_accuracy_1: 0.3335 - val_loss: 1.1026 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 15s 182ms/step - loss: 1.0954 - multi_accuracy_1: 0.3335 - val_loss: 1.1023 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 1.0956 - multi_accuracy_1: 0.3335 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 1.0953 - multi_accuracy_1: 0.3335 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0950 - multi_accuracy_1: 0.3335 - val_loss: 1.1002 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 15s 188ms/step - loss: 1.0946 - multi_accuracy_1: 0.3335 - val_loss: 1.1011 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 16s 191ms/step - loss: 1.0946 - multi_accuracy_1: 0.3335 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 1.0948 - multi_accuracy_1: 0.3335 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 1.0942 - multi_accuracy_1: 0.3335 - val_loss: 1.1015 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 15s 184ms/step - loss: 1.0942 - multi_accuracy_1: 0.3335 - val_loss: 1.0989 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 1.0939 - multi_accuracy_1: 0.3336 - val_loss: 1.0988 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 15s 186ms/step - loss: 1.0939 - multi_accuracy_1: 0.3336 - val_loss: 1.0989 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 15s 185ms/step - loss: 1.0934 - multi_accuracy_1: 0.3336 - val_loss: 1.1001 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1032 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 13s 111ms/step - loss: 4.3102 - multi_accuracy_1: 0.3336 - val_loss: 3.4029 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 8s 96ms/step - loss: 1.6344 - multi_accuracy_1: 0.3336 - val_loss: 1.1197 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.1076 - multi_accuracy_1: 0.3336 - val_loss: 1.1117 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.1024 - multi_accuracy_1: 0.3336 - val_loss: 1.1092 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.1006 - multi_accuracy_1: 0.3336 - val_loss: 1.1083 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 1.0998 - multi_accuracy_1: 0.3336 - val_loss: 1.1077 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.0995 - multi_accuracy_1: 0.3336 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 6s 77ms/step - loss: 1.0990 - multi_accuracy_1: 0.3336 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 1.0986 - multi_accuracy_1: 0.3336 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 1.0983 - multi_accuracy_1: 0.3336 - val_loss: 1.1059 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 1.0982 - multi_accuracy_1: 0.3336 - val_loss: 1.1072 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 6s 75ms/step - loss: 1.0981 - multi_accuracy_1: 0.3336 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 6s 77ms/step - loss: 1.0977 - multi_accuracy_1: 0.3336 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0976 - multi_accuracy_1: 0.3336 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 1.0976 - multi_accuracy_1: 0.3336 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0975 - multi_accuracy_1: 0.3336 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 1.0975 - multi_accuracy_1: 0.3336 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0974 - multi_accuracy_1: 0.3337 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.0974 - multi_accuracy_1: 0.3337 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0972 - multi_accuracy_1: 0.3337 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.0969 - multi_accuracy_1: 0.3337 - val_loss: 1.1077 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.0970 - multi_accuracy_1: 0.3337 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0968 - multi_accuracy_1: 0.3337 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0968 - multi_accuracy_1: 0.3337 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.0967 - multi_accuracy_1: 0.3337 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3337\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.1066 - multi_accuracy_1: 0.3337\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 13s 100ms/step - loss: 2.5710 - multi_accuracy_1: 0.3337 - val_loss: 1.1261 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.1060 - multi_accuracy_1: 0.3337 - val_loss: 1.1126 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 8s 94ms/step - loss: 1.1019 - multi_accuracy_1: 0.3337 - val_loss: 1.1071 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.1004 - multi_accuracy_1: 0.3337 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.0992 - multi_accuracy_1: 0.3337 - val_loss: 1.1076 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.0984 - multi_accuracy_1: 0.3337 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3337\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0976 - multi_accuracy_1: 0.3336 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 8s 92ms/step - loss: 1.0973 - multi_accuracy_1: 0.3336 - val_loss: 1.1051 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.0968 - multi_accuracy_1: 0.3336 - val_loss: 1.1041 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.0965 - multi_accuracy_1: 0.3336 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0957 - multi_accuracy_1: 0.3336 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0954 - multi_accuracy_1: 0.3336 - val_loss: 1.1038 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0953 - multi_accuracy_1: 0.3336 - val_loss: 1.1037 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 1.0952 - multi_accuracy_1: 0.3335 - val_loss: 1.1005 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 7s 82ms/step - loss: 1.0949 - multi_accuracy_1: 0.3335 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 7s 81ms/step - loss: 1.0943 - multi_accuracy_1: 0.3335 - val_loss: 1.1000 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0940 - multi_accuracy_1: 0.3335 - val_loss: 1.0980 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 1.0938 - multi_accuracy_1: 0.3335 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0931 - multi_accuracy_1: 0.3334 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.0933 - multi_accuracy_1: 0.3334 - val_loss: 1.0997 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 7s 91ms/step - loss: 1.0927 - multi_accuracy_1: 0.3334 - val_loss: 1.0980 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.0923 - multi_accuracy_1: 0.3334 - val_loss: 1.1013 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0921 - multi_accuracy_1: 0.3333 - val_loss: 1.1010 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 7s 84ms/step - loss: 1.0916 - multi_accuracy_1: 0.3333 - val_loss: 1.0990 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.0916 - multi_accuracy_1: 0.3333 - val_loss: 1.0986 - val_multi_accuracy_1: 0.3333\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 1.1020 - multi_accuracy_1: 0.3333\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 12s 95ms/step - loss: 2.9488 - multi_accuracy_1: 0.3333 - val_loss: 1.1539 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.1349 - multi_accuracy_1: 0.3333 - val_loss: 1.1076 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 7s 84ms/step - loss: 1.1097 - multi_accuracy_1: 0.3333 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.1040 - multi_accuracy_1: 0.3333 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.1026 - multi_accuracy_1: 0.3333 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 7s 84ms/step - loss: 1.1007 - multi_accuracy_1: 0.3333 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.1001 - multi_accuracy_1: 0.3333 - val_loss: 1.1023 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.0989 - multi_accuracy_1: 0.3333 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 7s 84ms/step - loss: 1.0986 - multi_accuracy_1: 0.3333 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.0978 - multi_accuracy_1: 0.3333 - val_loss: 1.1022 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 7s 84ms/step - loss: 1.0980 - multi_accuracy_1: 0.3333 - val_loss: 1.1006 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0974 - multi_accuracy_1: 0.3333 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 7s 84ms/step - loss: 1.0969 - multi_accuracy_1: 0.3333 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 1.0966 - multi_accuracy_1: 0.3333 - val_loss: 1.1015 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0964 - multi_accuracy_1: 0.3333 - val_loss: 1.1022 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0963 - multi_accuracy_1: 0.3333 - val_loss: 1.0997 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 1.0956 - multi_accuracy_1: 0.3333 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.0949 - multi_accuracy_1: 0.3333 - val_loss: 1.1000 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.0951 - multi_accuracy_1: 0.3333 - val_loss: 1.1016 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 7s 84ms/step - loss: 1.0948 - multi_accuracy_1: 0.3334 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0946 - multi_accuracy_1: 0.3334 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3334\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1031 - multi_accuracy_1: 0.3334\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 40s 343ms/step - loss: 1.4608 - multi_accuracy_1: 0.3334 - val_loss: 1.0987 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 30s 365ms/step - loss: 1.0959 - multi_accuracy_1: 0.3334 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 30s 367ms/step - loss: 1.0945 - multi_accuracy_1: 0.3334 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 30s 372ms/step - loss: 1.0942 - multi_accuracy_1: 0.3334 - val_loss: 1.1010 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 30s 370ms/step - loss: 1.0936 - multi_accuracy_1: 0.3334 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 31s 373ms/step - loss: 1.0933 - multi_accuracy_1: 0.3334 - val_loss: 1.0986 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 30s 369ms/step - loss: 1.0928 - multi_accuracy_1: 0.3335 - val_loss: 1.0990 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 30s 366ms/step - loss: 1.0929 - multi_accuracy_1: 0.3335 - val_loss: 1.0996 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 30s 361ms/step - loss: 1.0919 - multi_accuracy_1: 0.3335 - val_loss: 1.0967 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 30s 368ms/step - loss: 1.0918 - multi_accuracy_1: 0.3335 - val_loss: 1.0938 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 30s 369ms/step - loss: 1.0906 - multi_accuracy_1: 0.3336 - val_loss: 1.1044 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 29s 354ms/step - loss: 1.0900 - multi_accuracy_1: 0.3336 - val_loss: 1.1059 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 30s 370ms/step - loss: 1.0896 - multi_accuracy_1: 0.3336 - val_loss: 1.1141 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 30s 364ms/step - loss: 1.0890 - multi_accuracy_1: 0.3336 - val_loss: 1.1152 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 30s 366ms/step - loss: 1.0891 - multi_accuracy_1: 0.3336 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 3s 109ms/step - loss: 1.0965 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 38s 344ms/step - loss: 2.9267 - multi_accuracy_1: 0.3336 - val_loss: 2.2088 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 29s 360ms/step - loss: 2.3828 - multi_accuracy_1: 0.3336 - val_loss: 2.2141 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 31s 373ms/step - loss: 2.3815 - multi_accuracy_1: 0.3336 - val_loss: 2.2155 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 29s 359ms/step - loss: 2.3809 - multi_accuracy_1: 0.3336 - val_loss: 2.2141 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 30s 371ms/step - loss: 2.3810 - multi_accuracy_1: 0.3336 - val_loss: 2.2162 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 31s 373ms/step - loss: 2.3810 - multi_accuracy_1: 0.3336 - val_loss: 2.2159 - val_multi_accuracy_1: 0.3336\n",
      "28/28 [==============================] - 3s 108ms/step - loss: 2.1998 - multi_accuracy_1: 0.3336\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 44s 393ms/step - loss: 3.0340 - multi_accuracy_1: 0.3336 - val_loss: 2.8313 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 30s 367ms/step - loss: 3.0801 - multi_accuracy_1: 0.3336 - val_loss: 2.9632 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 31s 375ms/step - loss: 3.1665 - multi_accuracy_1: 0.3336 - val_loss: 2.9881 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 31s 378ms/step - loss: 2.2229 - multi_accuracy_1: 0.3336 - val_loss: 1.6860 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 29s 360ms/step - loss: 1.8130 - multi_accuracy_1: 0.3336 - val_loss: 1.6893 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 31s 378ms/step - loss: 1.8130 - multi_accuracy_1: 0.3336 - val_loss: 1.6872 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 31s 376ms/step - loss: 1.8126 - multi_accuracy_1: 0.3336 - val_loss: 1.6867 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 31s 377ms/step - loss: 1.8124 - multi_accuracy_1: 0.3336 - val_loss: 1.6859 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 30s 365ms/step - loss: 1.8119 - multi_accuracy_1: 0.3336 - val_loss: 1.6834 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 29s 357ms/step - loss: 1.8113 - multi_accuracy_1: 0.3336 - val_loss: 1.6874 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 24s 287ms/step - loss: 1.8112 - multi_accuracy_1: 0.3336 - val_loss: 1.6853 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 21s 256ms/step - loss: 1.8108 - multi_accuracy_1: 0.3336 - val_loss: 1.6819 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 21s 257ms/step - loss: 1.8107 - multi_accuracy_1: 0.3336 - val_loss: 1.6838 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 21s 257ms/step - loss: 1.8106 - multi_accuracy_1: 0.3336 - val_loss: 1.6841 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 21s 255ms/step - loss: 1.8108 - multi_accuracy_1: 0.3336 - val_loss: 1.6814 - val_multi_accuracy_1: 0.3336\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 21s 259ms/step - loss: 1.8102 - multi_accuracy_1: 0.3335 - val_loss: 1.6809 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 28s 338ms/step - loss: 1.8104 - multi_accuracy_1: 0.3335 - val_loss: 1.6857 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 29s 356ms/step - loss: 1.8104 - multi_accuracy_1: 0.3335 - val_loss: 1.6844 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 30s 363ms/step - loss: 1.8100 - multi_accuracy_1: 0.3335 - val_loss: 1.6836 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 30s 362ms/step - loss: 1.8102 - multi_accuracy_1: 0.3335 - val_loss: 1.6871 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 30s 360ms/step - loss: 1.8098 - multi_accuracy_1: 0.3335 - val_loss: 1.6787 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 29s 353ms/step - loss: 1.8100 - multi_accuracy_1: 0.3335 - val_loss: 1.6838 - val_multi_accuracy_1: 0.3335\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 26s 317ms/step - loss: 1.8101 - multi_accuracy_1: 0.3335 - val_loss: 1.6825 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 30s 363ms/step - loss: 1.8095 - multi_accuracy_1: 0.3334 - val_loss: 1.6838 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 29s 354ms/step - loss: 1.8094 - multi_accuracy_1: 0.3334 - val_loss: 1.6833 - val_multi_accuracy_1: 0.3334\n",
      "28/28 [==============================] - 3s 100ms/step - loss: 1.6815 - multi_accuracy_1: 0.3334\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 23s 186ms/step - loss: 2.1067 - multi_accuracy_1: 0.3334 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 15s 180ms/step - loss: 1.1024 - multi_accuracy_1: 0.3334 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 15s 179ms/step - loss: 1.1002 - multi_accuracy_1: 0.3334 - val_loss: 1.1089 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 1.0991 - multi_accuracy_1: 0.3334 - val_loss: 1.1073 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 14s 172ms/step - loss: 1.0978 - multi_accuracy_1: 0.3334 - val_loss: 1.1101 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 15s 181ms/step - loss: 1.0978 - multi_accuracy_1: 0.3334 - val_loss: 1.1087 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 14s 171ms/step - loss: 1.0969 - multi_accuracy_1: 0.3334 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 1.0962 - multi_accuracy_1: 0.3334 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 14s 177ms/step - loss: 1.0958 - multi_accuracy_1: 0.3333 - val_loss: 1.1104 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 14s 165ms/step - loss: 1.0954 - multi_accuracy_1: 0.3333 - val_loss: 1.0982 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 12s 150ms/step - loss: 1.0954 - multi_accuracy_1: 0.3333 - val_loss: 1.1031 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 14s 172ms/step - loss: 1.0952 - multi_accuracy_1: 0.3333 - val_loss: 1.1050 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 14s 175ms/step - loss: 1.0947 - multi_accuracy_1: 0.3333 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 1.0948 - multi_accuracy_1: 0.3333 - val_loss: 1.1016 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 14s 174ms/step - loss: 1.0940 - multi_accuracy_1: 0.3333 - val_loss: 1.0990 - val_multi_accuracy_1: 0.3333\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.0997 - multi_accuracy_1: 0.3333\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 22s 192ms/step - loss: 2.7436 - multi_accuracy_1: 0.3333 - val_loss: 1.1257 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 14s 172ms/step - loss: 1.1009 - multi_accuracy_1: 0.3333 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 14s 166ms/step - loss: 1.0979 - multi_accuracy_1: 0.3333 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 1.0976 - multi_accuracy_1: 0.3333 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 14s 175ms/step - loss: 1.0972 - multi_accuracy_1: 0.3333 - val_loss: 1.1062 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 1.0970 - multi_accuracy_1: 0.3333 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 1.0969 - multi_accuracy_1: 0.3333 - val_loss: 1.1059 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 14s 172ms/step - loss: 1.0964 - multi_accuracy_1: 0.3333 - val_loss: 1.1050 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 14s 172ms/step - loss: 1.0964 - multi_accuracy_1: 0.3333 - val_loss: 1.1052 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 1.0960 - multi_accuracy_1: 0.3333 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 1.0956 - multi_accuracy_1: 0.3333 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 14s 169ms/step - loss: 1.0950 - multi_accuracy_1: 0.3332 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 1.0949 - multi_accuracy_1: 0.3332 - val_loss: 1.1030 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 14s 171ms/step - loss: 1.0944 - multi_accuracy_1: 0.3332 - val_loss: 1.1039 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 12s 149ms/step - loss: 1.0943 - multi_accuracy_1: 0.3332 - val_loss: 1.1029 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 12s 146ms/step - loss: 1.0941 - multi_accuracy_1: 0.3332 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 1.0937 - multi_accuracy_1: 0.3332 - val_loss: 1.0997 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 14s 175ms/step - loss: 1.0937 - multi_accuracy_1: 0.3332 - val_loss: 1.0997 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 1.0936 - multi_accuracy_1: 0.3332 - val_loss: 1.1059 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 14s 166ms/step - loss: 1.0932 - multi_accuracy_1: 0.3332 - val_loss: 1.0999 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 14s 172ms/step - loss: 1.0931 - multi_accuracy_1: 0.3332 - val_loss: 1.1010 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 14s 172ms/step - loss: 1.0931 - multi_accuracy_1: 0.3332 - val_loss: 1.1003 - val_multi_accuracy_1: 0.3332\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.1015 - multi_accuracy_1: 0.3332\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 21s 176ms/step - loss: 3.5288 - multi_accuracy_1: 0.3332 - val_loss: 3.1089 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 14s 169ms/step - loss: 3.4174 - multi_accuracy_1: 0.3332 - val_loss: 3.1052 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 3.4307 - multi_accuracy_1: 0.3332 - val_loss: 3.1274 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 14s 166ms/step - loss: 3.4867 - multi_accuracy_1: 0.3332 - val_loss: 3.2145 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 13s 164ms/step - loss: 3.5086 - multi_accuracy_1: 0.3332 - val_loss: 3.2165 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 14s 166ms/step - loss: 3.5382 - multi_accuracy_1: 0.3332 - val_loss: 3.2343 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 14s 169ms/step - loss: 3.5410 - multi_accuracy_1: 0.3332 - val_loss: 3.2020 - val_multi_accuracy_1: 0.3332\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 3.1206 - multi_accuracy_1: 0.3332\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 13s 95ms/step - loss: 3.3471 - multi_accuracy_1: 0.3332 - val_loss: 1.1261 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 7s 84ms/step - loss: 1.1045 - multi_accuracy_1: 0.3332 - val_loss: 1.1105 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 7s 85ms/step - loss: 1.1016 - multi_accuracy_1: 0.3332 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.1008 - multi_accuracy_1: 0.3332 - val_loss: 1.1078 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0999 - multi_accuracy_1: 0.3332 - val_loss: 1.1079 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 1.0994 - multi_accuracy_1: 0.3332 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 7s 83ms/step - loss: 1.0992 - multi_accuracy_1: 0.3332 - val_loss: 1.1067 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 1.0988 - multi_accuracy_1: 0.3332 - val_loss: 1.1078 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 1.0984 - multi_accuracy_1: 0.3332 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 6s 75ms/step - loss: 1.0985 - multi_accuracy_1: 0.3332 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 1.0980 - multi_accuracy_1: 0.3332 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 1.0977 - multi_accuracy_1: 0.3332 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 6s 77ms/step - loss: 1.0976 - multi_accuracy_1: 0.3332 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.0974 - multi_accuracy_1: 0.3332 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0971 - multi_accuracy_1: 0.3332 - val_loss: 1.1033 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 1.0969 - multi_accuracy_1: 0.3332 - val_loss: 1.1045 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.0966 - multi_accuracy_1: 0.3332 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.0966 - multi_accuracy_1: 0.3332 - val_loss: 1.1042 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0964 - multi_accuracy_1: 0.3333 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0961 - multi_accuracy_1: 0.3333 - val_loss: 1.1010 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.0958 - multi_accuracy_1: 0.3333 - val_loss: 1.1003 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.0956 - multi_accuracy_1: 0.3333 - val_loss: 1.1011 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.0954 - multi_accuracy_1: 0.3333 - val_loss: 1.1033 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 5s 60ms/step - loss: 1.0954 - multi_accuracy_1: 0.3333 - val_loss: 1.1001 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0948 - multi_accuracy_1: 0.3333 - val_loss: 1.1031 - val_multi_accuracy_1: 0.3333\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.1078 - multi_accuracy_1: 0.3333\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 10s 69ms/step - loss: 2.0845 - multi_accuracy_1: 0.3333 - val_loss: 1.1078 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.1009 - multi_accuracy_1: 0.3333 - val_loss: 1.1070 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.0998 - multi_accuracy_1: 0.3333 - val_loss: 1.1076 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 5s 62ms/step - loss: 1.0986 - multi_accuracy_1: 0.3333 - val_loss: 1.1041 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.0979 - multi_accuracy_1: 0.3333 - val_loss: 1.1032 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.0969 - multi_accuracy_1: 0.3333 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.0964 - multi_accuracy_1: 0.3333 - val_loss: 1.1023 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.0958 - multi_accuracy_1: 0.3333 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.0961 - multi_accuracy_1: 0.3333 - val_loss: 1.1024 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.0951 - multi_accuracy_1: 0.3333 - val_loss: 1.1015 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 1.0946 - multi_accuracy_1: 0.3333 - val_loss: 1.1002 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 6s 78ms/step - loss: 1.0936 - multi_accuracy_1: 0.3333 - val_loss: 1.1030 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 1.0935 - multi_accuracy_1: 0.3333 - val_loss: 1.0989 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 1.0931 - multi_accuracy_1: 0.3332 - val_loss: 1.1000 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 6s 74ms/step - loss: 1.0930 - multi_accuracy_1: 0.3332 - val_loss: 1.1006 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 7s 81ms/step - loss: 1.0931 - multi_accuracy_1: 0.3332 - val_loss: 1.1032 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0929 - multi_accuracy_1: 0.3332 - val_loss: 1.1016 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0928 - multi_accuracy_1: 0.3332 - val_loss: 1.0998 - val_multi_accuracy_1: 0.3332\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.1043 - multi_accuracy_1: 0.3332\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 10s 71ms/step - loss: 1.2239 - multi_accuracy_1: 0.3332 - val_loss: 1.1075 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.0979 - multi_accuracy_1: 0.3332 - val_loss: 1.1084 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 5s 57ms/step - loss: 1.0973 - multi_accuracy_1: 0.3332 - val_loss: 1.1050 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0966 - multi_accuracy_1: 0.3332 - val_loss: 1.1062 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.0963 - multi_accuracy_1: 0.3332 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 6s 75ms/step - loss: 1.0961 - multi_accuracy_1: 0.3332 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0952 - multi_accuracy_1: 0.3332 - val_loss: 1.1044 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0948 - multi_accuracy_1: 0.3332 - val_loss: 1.1056 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 1.0944 - multi_accuracy_1: 0.3332 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 5s 63ms/step - loss: 1.0940 - multi_accuracy_1: 0.3333 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 5s 65ms/step - loss: 1.0933 - multi_accuracy_1: 0.3333 - val_loss: 1.0996 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.0930 - multi_accuracy_1: 0.3333 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 5s 58ms/step - loss: 1.0928 - multi_accuracy_1: 0.3333 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 5s 64ms/step - loss: 1.0921 - multi_accuracy_1: 0.3333 - val_loss: 1.0998 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 5s 59ms/step - loss: 1.0913 - multi_accuracy_1: 0.3333 - val_loss: 1.1030 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 5s 61ms/step - loss: 1.0908 - multi_accuracy_1: 0.3334 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3334\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.1011 - multi_accuracy_1: 0.3334\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 23s 162ms/step - loss: 2.7004 - multi_accuracy_1: 0.3334 - val_loss: 1.1166 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 12s 148ms/step - loss: 1.0987 - multi_accuracy_1: 0.3334 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 12s 145ms/step - loss: 1.0974 - multi_accuracy_1: 0.3334 - val_loss: 1.1084 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 12s 143ms/step - loss: 1.0968 - multi_accuracy_1: 0.3333 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3334\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 12s 144ms/step - loss: 1.0965 - multi_accuracy_1: 0.3333 - val_loss: 1.1052 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 13s 153ms/step - loss: 1.0960 - multi_accuracy_1: 0.3333 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 13s 156ms/step - loss: 1.0955 - multi_accuracy_1: 0.3333 - val_loss: 1.1023 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 13s 155ms/step - loss: 1.0952 - multi_accuracy_1: 0.3333 - val_loss: 1.1025 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 1.0948 - multi_accuracy_1: 0.3333 - val_loss: 1.1060 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 1.0941 - multi_accuracy_1: 0.3333 - val_loss: 1.1012 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 11s 139ms/step - loss: 1.0937 - multi_accuracy_1: 0.3333 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3333\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 12s 142ms/step - loss: 1.0934 - multi_accuracy_1: 0.3332 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 12s 146ms/step - loss: 1.0932 - multi_accuracy_1: 0.3332 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 12s 149ms/step - loss: 1.0923 - multi_accuracy_1: 0.3332 - val_loss: 1.0977 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 12s 142ms/step - loss: 1.0921 - multi_accuracy_1: 0.3332 - val_loss: 1.0975 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 13s 153ms/step - loss: 1.0925 - multi_accuracy_1: 0.3332 - val_loss: 1.0997 - val_multi_accuracy_1: 0.3332\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 1.0920 - multi_accuracy_1: 0.3331 - val_loss: 1.0989 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 11s 130ms/step - loss: 1.0920 - multi_accuracy_1: 0.3331 - val_loss: 1.0999 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 12s 144ms/step - loss: 1.0919 - multi_accuracy_1: 0.3331 - val_loss: 1.0976 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 1.0922 - multi_accuracy_1: 0.3331 - val_loss: 1.0980 - val_multi_accuracy_1: 0.3331\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 1.1019 - multi_accuracy_1: 0.3331\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 22s 154ms/step - loss: 1.8085 - multi_accuracy_1: 0.3331 - val_loss: 1.1039 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 12s 145ms/step - loss: 1.0960 - multi_accuracy_1: 0.3331 - val_loss: 1.1028 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 12s 148ms/step - loss: 1.0956 - multi_accuracy_1: 0.3331 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 12s 143ms/step - loss: 1.0951 - multi_accuracy_1: 0.3331 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 12s 148ms/step - loss: 1.0945 - multi_accuracy_1: 0.3331 - val_loss: 1.1020 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 12s 146ms/step - loss: 1.0946 - multi_accuracy_1: 0.3331 - val_loss: 1.0921 - val_multi_accuracy_1: 0.3331\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 1.0946 - multi_accuracy_1: 0.3330 - val_loss: 1.0984 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 12s 150ms/step - loss: 1.0932 - multi_accuracy_1: 0.3330 - val_loss: 1.0956 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 12s 148ms/step - loss: 1.0943 - multi_accuracy_1: 0.3330 - val_loss: 1.0945 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 12s 147ms/step - loss: 1.0933 - multi_accuracy_1: 0.3330 - val_loss: 1.1000 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 11s 140ms/step - loss: 1.0928 - multi_accuracy_1: 0.3330 - val_loss: 1.1033 - val_multi_accuracy_1: 0.3330\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 1.0941 - multi_accuracy_1: 0.3330\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 23s 155ms/step - loss: 2.7890 - multi_accuracy_1: 0.3330 - val_loss: 1.1396 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 12s 143ms/step - loss: 1.1270 - multi_accuracy_1: 0.3330 - val_loss: 1.1265 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 12s 143ms/step - loss: 1.1195 - multi_accuracy_1: 0.3330 - val_loss: 1.1260 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 1.1123 - multi_accuracy_1: 0.3330 - val_loss: 1.1185 - val_multi_accuracy_1: 0.3330\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 14s 172ms/step - loss: 1.0993 - multi_accuracy_1: 0.3329 - val_loss: 1.1064 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 14s 171ms/step - loss: 1.0951 - multi_accuracy_1: 0.3329 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 14s 176ms/step - loss: 1.0937 - multi_accuracy_1: 0.3329 - val_loss: 1.0933 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 12s 147ms/step - loss: 1.0941 - multi_accuracy_1: 0.3329 - val_loss: 1.1017 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 13s 158ms/step - loss: 1.0934 - multi_accuracy_1: 0.3329 - val_loss: 1.1010 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 12s 151ms/step - loss: 1.0938 - multi_accuracy_1: 0.3329 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 12s 144ms/step - loss: 1.0932 - multi_accuracy_1: 0.3328 - val_loss: 1.0982 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 12s 146ms/step - loss: 1.0929 - multi_accuracy_1: 0.3328 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3328\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.0963 - multi_accuracy_1: 0.3328\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 13s 75ms/step - loss: 2.1189 - multi_accuracy_1: 0.3328 - val_loss: 1.1139 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 6s 79ms/step - loss: 1.0987 - multi_accuracy_1: 0.3328 - val_loss: 1.1058 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 1.0976 - multi_accuracy_1: 0.3328 - val_loss: 1.1035 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0967 - multi_accuracy_1: 0.3328 - val_loss: 1.1072 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0961 - multi_accuracy_1: 0.3328 - val_loss: 1.1050 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 1.0959 - multi_accuracy_1: 0.3329 - val_loss: 1.1043 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.0956 - multi_accuracy_1: 0.3329 - val_loss: 1.1049 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0951 - multi_accuracy_1: 0.3329 - val_loss: 1.1036 - val_multi_accuracy_1: 0.3329\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 1.1040 - multi_accuracy_1: 0.3329\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 13s 77ms/step - loss: 3.0535 - multi_accuracy_1: 0.3329 - val_loss: 1.9743 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 2.0429 - multi_accuracy_1: 0.3329 - val_loss: 1.6248 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 6s 74ms/step - loss: 1.5334 - multi_accuracy_1: 0.3329 - val_loss: 1.3642 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.4598 - multi_accuracy_1: 0.3329 - val_loss: 1.3658 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 1.4486 - multi_accuracy_1: 0.3329 - val_loss: 1.3634 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.4416 - multi_accuracy_1: 0.3329 - val_loss: 1.3578 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.4404 - multi_accuracy_1: 0.3329 - val_loss: 1.3588 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 1.4357 - multi_accuracy_1: 0.3329 - val_loss: 1.3593 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 6s 70ms/step - loss: 1.4368 - multi_accuracy_1: 0.3329 - val_loss: 1.3557 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.4413 - multi_accuracy_1: 0.3329 - val_loss: 1.3577 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 1.4421 - multi_accuracy_1: 0.3329 - val_loss: 1.3576 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 1.4405 - multi_accuracy_1: 0.3328 - val_loss: 1.3621 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 1.4497 - multi_accuracy_1: 0.3328 - val_loss: 1.3630 - val_multi_accuracy_1: 0.3329\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 6s 77ms/step - loss: 1.4534 - multi_accuracy_1: 0.3328 - val_loss: 1.3607 - val_multi_accuracy_1: 0.3328\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 1.4117 - multi_accuracy_1: 0.3329\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 14s 88ms/step - loss: 1.6561 - multi_accuracy_1: 0.3328 - val_loss: 1.1291 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 6s 78ms/step - loss: 1.1103 - multi_accuracy_1: 0.3328 - val_loss: 1.1147 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 6s 78ms/step - loss: 1.1048 - multi_accuracy_1: 0.3328 - val_loss: 1.1103 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 6s 68ms/step - loss: 1.1023 - multi_accuracy_1: 0.3328 - val_loss: 1.1080 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.1013 - multi_accuracy_1: 0.3328 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 1.1006 - multi_accuracy_1: 0.3328 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0999 - multi_accuracy_1: 0.3328 - val_loss: 1.1065 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0993 - multi_accuracy_1: 0.3328 - val_loss: 1.1054 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 6s 78ms/step - loss: 1.0989 - multi_accuracy_1: 0.3328 - val_loss: 1.1055 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 1.0986 - multi_accuracy_1: 0.3328 - val_loss: 1.1061 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 1.0984 - multi_accuracy_1: 0.3328 - val_loss: 1.1057 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 6s 69ms/step - loss: 1.0978 - multi_accuracy_1: 0.3328 - val_loss: 1.1048 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 7s 80ms/step - loss: 1.0977 - multi_accuracy_1: 0.3328 - val_loss: 1.1053 - val_multi_accuracy_1: 0.3328\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 7s 80ms/step - loss: 1.0974 - multi_accuracy_1: 0.3327 - val_loss: 1.1046 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 7s 86ms/step - loss: 1.0973 - multi_accuracy_1: 0.3327 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 6s 74ms/step - loss: 1.0971 - multi_accuracy_1: 0.3327 - val_loss: 1.1041 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 6s 78ms/step - loss: 1.0969 - multi_accuracy_1: 0.3327 - val_loss: 1.1047 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 7s 81ms/step - loss: 1.0968 - multi_accuracy_1: 0.3327 - val_loss: 1.1034 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 6s 78ms/step - loss: 1.0965 - multi_accuracy_1: 0.3327 - val_loss: 1.1039 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 5s 67ms/step - loss: 1.0965 - multi_accuracy_1: 0.3327 - val_loss: 1.1041 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 21/25\n",
      "82/82 [==============================] - 5s 66ms/step - loss: 1.0966 - multi_accuracy_1: 0.3327 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 22/25\n",
      "82/82 [==============================] - 6s 74ms/step - loss: 1.0964 - multi_accuracy_1: 0.3327 - val_loss: 1.1033 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 23/25\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 1.0961 - multi_accuracy_1: 0.3327 - val_loss: 1.1039 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 24/25\n",
      "82/82 [==============================] - 6s 76ms/step - loss: 1.0960 - multi_accuracy_1: 0.3326 - val_loss: 1.1040 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 25/25\n",
      "82/82 [==============================] - 6s 74ms/step - loss: 1.0960 - multi_accuracy_1: 0.3326 - val_loss: 1.1027 - val_multi_accuracy_1: 0.3326\n",
      "28/28 [==============================] - 1s 23ms/step - loss: 1.1059 - multi_accuracy_1: 0.3326\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 9s 50ms/step - loss: 3.4273 - multi_accuracy_1: 0.3326 - val_loss: 1.7884 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.6520 - multi_accuracy_1: 0.3326 - val_loss: 1.4807 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 3s 39ms/step - loss: 1.4434 - multi_accuracy_1: 0.3326 - val_loss: 1.4620 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 1.4333 - multi_accuracy_1: 0.3326 - val_loss: 1.4529 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 3s 41ms/step - loss: 1.4304 - multi_accuracy_1: 0.3326 - val_loss: 1.4526 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 3s 39ms/step - loss: 1.4292 - multi_accuracy_1: 0.3326 - val_loss: 1.4516 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.4286 - multi_accuracy_1: 0.3326 - val_loss: 1.4541 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.4285 - multi_accuracy_1: 0.3326 - val_loss: 1.4498 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.4276 - multi_accuracy_1: 0.3326 - val_loss: 1.4495 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.4276 - multi_accuracy_1: 0.3326 - val_loss: 1.4515 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.4276 - multi_accuracy_1: 0.3326 - val_loss: 1.4494 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.4271 - multi_accuracy_1: 0.3326 - val_loss: 1.4520 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.4269 - multi_accuracy_1: 0.3326 - val_loss: 1.4503 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.4269 - multi_accuracy_1: 0.3326 - val_loss: 1.4518 - val_multi_accuracy_1: 0.3327\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.4268 - multi_accuracy_1: 0.3326 - val_loss: 1.4488 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.4263 - multi_accuracy_1: 0.3326 - val_loss: 1.4529 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.4262 - multi_accuracy_1: 0.3326 - val_loss: 1.4493 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 18/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.4263 - multi_accuracy_1: 0.3326 - val_loss: 1.4500 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 19/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.4260 - multi_accuracy_1: 0.3326 - val_loss: 1.4501 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 20/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.4259 - multi_accuracy_1: 0.3326 - val_loss: 1.4516 - val_multi_accuracy_1: 0.3326\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.4596 - multi_accuracy_1: 0.3326\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 7s 41ms/step - loss: 2.3308 - multi_accuracy_1: 0.3326 - val_loss: 1.1066 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.1016 - multi_accuracy_1: 0.3326 - val_loss: 1.1086 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.1004 - multi_accuracy_1: 0.3326 - val_loss: 1.1090 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.0994 - multi_accuracy_1: 0.3326 - val_loss: 1.1081 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 3s 37ms/step - loss: 1.0993 - multi_accuracy_1: 0.3326 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 3s 34ms/step - loss: 1.0986 - multi_accuracy_1: 0.3326 - val_loss: 1.1088 - val_multi_accuracy_1: 0.3326\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 1.1065 - multi_accuracy_1: 0.3326\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 8s 40ms/step - loss: 2.0700 - multi_accuracy_1: 0.3326 - val_loss: 1.1745 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 1.1195 - multi_accuracy_1: 0.3326 - val_loss: 1.1230 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 3s 31ms/step - loss: 1.1068 - multi_accuracy_1: 0.3326 - val_loss: 1.1153 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 4/25\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.1043 - multi_accuracy_1: 0.3326 - val_loss: 1.1129 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 5/25\n",
      "82/82 [==============================] - 3s 35ms/step - loss: 1.1025 - multi_accuracy_1: 0.3326 - val_loss: 1.1116 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 6/25\n",
      "82/82 [==============================] - 3s 33ms/step - loss: 1.1010 - multi_accuracy_1: 0.3326 - val_loss: 1.1098 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 7/25\n",
      "82/82 [==============================] - 3s 39ms/step - loss: 1.1002 - multi_accuracy_1: 0.3326 - val_loss: 1.1096 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 8/25\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 1.0995 - multi_accuracy_1: 0.3326 - val_loss: 1.1101 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 9/25\n",
      "82/82 [==============================] - 4s 44ms/step - loss: 1.0991 - multi_accuracy_1: 0.3326 - val_loss: 1.1085 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 10/25\n",
      "82/82 [==============================] - 3s 42ms/step - loss: 1.0987 - multi_accuracy_1: 0.3326 - val_loss: 1.1079 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 11/25\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.0981 - multi_accuracy_1: 0.3326 - val_loss: 1.1083 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 12/25\n",
      "82/82 [==============================] - 3s 43ms/step - loss: 1.0980 - multi_accuracy_1: 0.3326 - val_loss: 1.1068 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 13/25\n",
      "82/82 [==============================] - 3s 37ms/step - loss: 1.0979 - multi_accuracy_1: 0.3326 - val_loss: 1.1077 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 14/25\n",
      "82/82 [==============================] - 3s 39ms/step - loss: 1.0975 - multi_accuracy_1: 0.3326 - val_loss: 1.1076 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 15/25\n",
      "82/82 [==============================] - 3s 38ms/step - loss: 1.0974 - multi_accuracy_1: 0.3326 - val_loss: 1.1075 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 16/25\n",
      "82/82 [==============================] - 3s 36ms/step - loss: 1.0971 - multi_accuracy_1: 0.3326 - val_loss: 1.1074 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 17/25\n",
      "82/82 [==============================] - 3s 37ms/step - loss: 1.0971 - multi_accuracy_1: 0.3326 - val_loss: 1.1069 - val_multi_accuracy_1: 0.3326\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 1.1065 - multi_accuracy_1: 0.3326\n",
      "Epoch 1/25\n",
      "82/82 [==============================] - 25s 184ms/step - loss: 3.5307 - multi_accuracy_1: 0.3326 - val_loss: 2.0983 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 13s 162ms/step - loss: 2.4118 - multi_accuracy_1: 0.3326 - val_loss: 2.0985 - val_multi_accuracy_1: 0.3326\n",
      "Epoch 3/25\n",
      "42/82 [==============>...............] - ETA: 5s - loss: 2.4216 - multi_accuracy_1: 0.3326"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m model \u001b[39m=\u001b[39m create_transformer_model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m         m\u001b[39m=\u001b[39mmemory_length\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         n\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(SELECTED_TICKERS),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m         class_first\u001b[39m=\u001b[39mCLASS_FIRST\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m             loss\u001b[39m=\u001b[39mMultiSoftmaxLoss(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m             metrics\u001b[39m=\u001b[39mMETRICS)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x \u001b[39m=\u001b[39;49m (x_train,x_ts_train,x_train,x_ts_train),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         y \u001b[39m=\u001b[39;49m y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m         validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m         callbacks\u001b[39m=\u001b[39;49mCALLBACKS)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39m./models/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mserial\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.keras\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m model_dict\u001b[39m.\u001b[39mupdate(model\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m             x \u001b[39m=\u001b[39m (x_test,x_ts_test,x_test,x_ts_test),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m             y \u001b[39m=\u001b[39m y_test,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m         )\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./models/\"):\n",
    "    os.makedirs(\"./models/\")\n",
    "\n",
    "METRICS = [MultiAccuracy()]\n",
    "CALLBACKS = [keras.callbacks.EarlyStopping(patience=5,\n",
    "                                           restore_best_weights=True)]\n",
    "CLASS_FIRST = True\n",
    "\n",
    "if MODEL_SERIAL is None:\n",
    "    counter = 0\n",
    "    RESUME = 9\n",
    "\n",
    "    for memory_length in [50,20,10]:\n",
    "        if PREDICT_PRICES:\n",
    "            OUTPUT_SCALE = (0,1)\n",
    "            x, y = create_batch_xy(\n",
    "                        memory_length,\n",
    "                        transformed_np_arr,\n",
    "                        overlap=True,\n",
    "                        y_updown=False,\n",
    "                        diff_data=True,\n",
    "                        output_scale=OUTPUT_SCALE)\n",
    "        else:\n",
    "            x, x_ts, y = create_transformer_onehot_xy(\n",
    "                                memory_length,\n",
    "                                transformed_np_arr,\n",
    "                                DATAFRAME.to_numpy(),\n",
    "                                DATAFRAME.index.to_numpy(),\n",
    "                                0.002)\n",
    "\n",
    "        split_idx = int(x.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "        x_train = x[:split_idx,:,:]\n",
    "        x_ts_train = x_ts[:split_idx,:,:]\n",
    "        y_train = y[:split_idx,:,:]\n",
    "\n",
    "        x_test = x[split_idx:,:,:]\n",
    "        x_ts_test = x_ts[split_idx:,:,:]\n",
    "        y_test = y[split_idx:,:,:]\n",
    "\n",
    "        if CLASS_FIRST:\n",
    "            y_train = tf.transpose(y_train, (0,2,1))\n",
    "            y_test = tf.transpose(y_test, (0,2,1))\n",
    "\n",
    "        for head_size in [32,16,64]:\n",
    "            for num_heads in [32,16,8]:\n",
    "                for ff_dim in [64,32,16]:\n",
    "                    for num_transformer_blocks in [4,2,1]:\n",
    "                        for mlp_units in [64,32,16]:\n",
    "                            if counter < RESUME:\n",
    "                                counter = counter + 1\n",
    "                                continue\n",
    "                            \n",
    "                            serial = \"transformer_model_\" \\\n",
    "                                + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                            model_dict = {\n",
    "                                \"serial\": serial,\n",
    "                                \"memory_length\": memory_length,\n",
    "                                \"head_size\": head_size,\n",
    "                                \"num_heads\": num_heads,\n",
    "                                \"ff_dim\": ff_dim,\n",
    "                                \"num_transformer_blocks\": num_transformer_blocks,\n",
    "                                \"mlp_units\": mlp_units\n",
    "                            }\n",
    "\n",
    "                            model = create_transformer_model(\n",
    "                                    m=memory_length+1,\n",
    "                                    n=len(SELECTED_TICKERS),\n",
    "                                    output_dim=3,\n",
    "                                    head_size=head_size,\n",
    "                                    num_heads=num_heads,\n",
    "                                    ff_dim=ff_dim,\n",
    "                                    num_transformer_blocks=num_transformer_blocks,\n",
    "                                    mlp_units=(mlp_units,),\n",
    "                                    class_first=CLASS_FIRST\n",
    "                                )\n",
    "                            \n",
    "\n",
    "                            model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                                        loss=MultiSoftmaxLoss(),\n",
    "                                        metrics=METRICS)\n",
    "\n",
    "                            model.fit(x = (x_train,x_ts_train,x_train,x_ts_train),\n",
    "                                    y = y_train,\n",
    "                                    batch_size=32,\n",
    "                                    epochs=25,\n",
    "                                    validation_split=0.25,\n",
    "                                    callbacks=CALLBACKS)\n",
    "                            \n",
    "                            model.save(\"./models/\"+serial+\".keras\")\n",
    "\n",
    "                            model_dict.update(model.evaluate(\n",
    "                                        x = (x_test,x_ts_test,x_test,x_ts_test),\n",
    "                                        y = y_test,\n",
    "                                        batch_size=32,\n",
    "                                        workers=4,\n",
    "                                        use_multiprocessing=True,\n",
    "                                        return_dict=True\n",
    "                                    )\n",
    "                                )\n",
    "                            \n",
    "                            if os.path.exists(\"./transformer_results.json\"):\n",
    "                                with open(\"./transformer_results.json\", \"r\",\n",
    "                                        encoding=ENCODING) as json_file:\n",
    "                                    model_list = json.load(json_file)\n",
    "                                model_list.append(model_dict)\n",
    "                            else:\n",
    "                                model_list = [model_dict]\n",
    "\n",
    "                            with open(\"./transformer_results.json\", \"w\",\n",
    "                                    encoding=ENCODING) as json_file:\n",
    "                                json.dump(model_list, json_file)\n",
    "\n",
    "    if os.path.exists(\"./transformer_results.json\"):\n",
    "        with open(\"./transformer_results.json\", \"r\",\n",
    "                  encoding=ENCODING) as json_file:\n",
    "            model_list = json.load(json_file)\n",
    "    else:\n",
    "        model_list = [{}]\n",
    "    \n",
    "    model_df = pd.DataFrame.from_dict(model_list)\n",
    "    model_df.to_excel(\"./transformer_results.xlsx\")\n",
    "else:\n",
    "    with open(\"./transformer_results.json\", \"r\",\n",
    "              encoding=ENCODING) as json_file:\n",
    "        model_list = json.load(json_file)\n",
    "    model_dict = next(item for item in model_list\n",
    "                      if item[\"serial\"] == MODEL_SERIAL)\n",
    "\n",
    "    memory_length = int(model_dict[\"memory_length\"])\n",
    "\n",
    "    if PREDICT_PRICES:\n",
    "        OUTPUT_SCALE = (0,1)\n",
    "        x, y = create_batch_xy(\n",
    "                    memory_length,\n",
    "                    transformed_np_arr,\n",
    "                    overlap=True,\n",
    "                    y_updown=False,\n",
    "                    diff_data=True,\n",
    "                    output_scale=OUTPUT_SCALE)\n",
    "    else:\n",
    "        x, x_ts, y = create_transformer_onehot_xy(\n",
    "                            memory_length,\n",
    "                            transformed_np_arr,\n",
    "                            DATAFRAME.to_numpy(),\n",
    "                            DATAFRAME.index.to_numpy(),\n",
    "                            0.002)\n",
    "\n",
    "    split_idx = int(x.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "    x_train = x[:split_idx,:,:]\n",
    "    x_ts_train = x_ts[:split_idx,:,:]\n",
    "    y_train = y[:split_idx,:,:]\n",
    "\n",
    "    x_test = x[split_idx:,:,:]\n",
    "    x_ts_test = x_ts[split_idx:,:,:]\n",
    "    y_test = y[split_idx:,:,:]\n",
    "\n",
    "    if CLASS_FIRST:\n",
    "        y_train = tf.transpose(y_train, (0,2,1))\n",
    "        y_test = tf.transpose(y_test, (0,2,1))\n",
    "\n",
    "    model = keras.models.load_model(\"./models/\" + MODEL_SERIAL + \".keras\")\n",
    "\n",
    "plot_model(\n",
    "        model,\n",
    "        to_file=\"./figures/transformer_model_plot.png\",\n",
    "        show_shapes=True,\n",
    "        show_layer_names = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model([x_test, x_ts_test, x_test, x_ts_test], training=False)\n",
    "print(\"Y_pred: \\n\", y_pred)\n",
    "print(\"Y_test: \\n\", y_test)\n",
    "\n",
    "for stock_idx in range(y_pred.shape[2] if CLASS_FIRST else y_pred.shape[1]):\n",
    "    if CLASS_FIRST:\n",
    "        direction_preds = y_pred[:,:,stock_idx]\n",
    "        direction_true = y_test[:,:,stock_idx]\n",
    "    else:\n",
    "        direction_preds = y_pred[:,stock_idx,:]\n",
    "        direction_true = y_test[:,stock_idx,:]\n",
    "\n",
    "    accuracy = \\\n",
    "        np.sum(direction_preds == direction_true) / direction_preds.shape[0]\n",
    "    print(f\"\"\"\n",
    "            Up/Down/Flat accuracy for stock {IND_CONVERSION[stock_idx]}:\n",
    "            {accuracy}\n",
    "            \"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate profit by optimal strategy (theoretical) vs using model to predict\n",
    "test_sz = int(DATAFRAME.shape[0] * TEST_FRAC)\n",
    "df_test = DATAFRAME.iloc[-test_sz:,:].copy()\n",
    "if HAS_TIMEDELTA:\n",
    "    df_test.drop(\"Time Delta\", axis=1, inplace=True)\n",
    "np_arr_test = df_test.to_numpy()\n",
    "print(\"np_arr_test data shape: \", np_arr_test.shape)\n",
    "\n",
    "optimal_trading_mask = calculate_optimal_invest_strategy(np_arr_test)\n",
    "print(f\"Optimal mask 3rd stock: \\n {optimal_trading_mask[:,2]}\")\n",
    "profit_optimal = calculate_profit_on_invest_strategy(np_arr_test,\n",
    "                                                     optimal_trading_mask)\n",
    "print(f\"Optimal strategy matrix shape: {optimal_trading_mask.shape}\")\n",
    "print(f\"Profit by optimal strategy on test data: {profit_optimal}\")\n",
    "\n",
    "# To calculate the mask for the model, we need to give the data in the same format as it was trained in\n",
    "transformed_df_test = transformed_df.iloc[-test_sz:,:]\n",
    "transformed_np_arr_test = transformed_df_test.to_numpy()\n",
    "print(\"transformed_np_arr_test data shape: \", transformed_np_arr_test.shape)\n",
    "print(transformed_np_arr_test[0:2,:])\n",
    "prediction_trading_mask = \\\n",
    "    strategy_mask_from_direction_model(transformed_np_arr_test,\n",
    "                                       memory_length, model,\n",
    "                                       True, df.to_numpy()[-test_sz:,:],\n",
    "                                       df.index.to_numpy()[-test_sz:]\n",
    "                                       )\n",
    "\n",
    "if HAS_TIMEDELTA:\n",
    "    prediction_trading_mask = prediction_trading_mask[:,1:]\n",
    "\n",
    "print(f\"Prediction mask 3rd stock: \\n {prediction_trading_mask[:,2]}\")\n",
    "if HAS_TIMEDELTA:\n",
    "    profit_pred_model = \\\n",
    "        calculate_profit_on_invest_strategy(np_arr_test[:,1:],\n",
    "                                            prediction_trading_mask)\n",
    "else:\n",
    "    profit_pred_model = \\\n",
    "        calculate_profit_on_invest_strategy(np_arr_test,\n",
    "                                            prediction_trading_mask)\n",
    "\n",
    "print(f\"Prediction strategy matrix shape: {prediction_trading_mask.shape}\")\n",
    "print(\n",
    "    f\"Profit by predicting the next hour using the model: {profit_pred_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_indices = np.random.choice(np.arange(len(IND_CONVERSION)), 4,\n",
    "                                 replace=False)\n",
    "part_mask = prediction_trading_mask[:,stock_indices]\n",
    "\n",
    "if HAS_TIMEDELTA:\n",
    "    part_price = np_arr_test[:,1:][:,stock_indices]\n",
    "else:\n",
    "    part_price = np_arr_test[:,stock_indices]\n",
    "\n",
    "ind_conversion = {si : IND_CONVERSION[i] for si, i in enumerate(stock_indices)}\n",
    "plot_mask_and_data(part_mask, part_price, ind_conversion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stonks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
