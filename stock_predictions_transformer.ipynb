{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import locale\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from stock_modules.stock_transform import (create_batch_xy,\n",
    "                                           create_transformer_onehot_xy)\n",
    "\n",
    "from stock_modules.stock_ml import (create_transformer_model,\n",
    "                                    MultiSoftmaxLoss, MultiAccuracy)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = locale.getpreferredencoding()\n",
    "DF_PATH = \"HEL_12-10-21to08-11-23.csv\"\n",
    "HISTORY_ARRAY_PATH = \"./histories_arr.npy\"\n",
    "MODEL_PATH = \"./model.h5\"\n",
    "SELECTED_TICKERS_PATH = \"./TICKERS_TO_FOLLOW.json\"\n",
    "\n",
    "TEST_FRAC = 0.2\n",
    "PREDICT_PRICES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_TICKERS = json.load(open(SELECTED_TICKERS_PATH,\n",
    "                                  \"r\", encoding=ENCODING))\n",
    "DATAFRAME = pd.read_csv(DF_PATH, encoding=ENCODING)\n",
    "\n",
    "DATAFRAME.set_index(\"date\", inplace=True)\n",
    "HAS_TIMEDELTA = \"Time Delta\" in DATAFRAME.columns\n",
    "\n",
    "# ind transformation tells the label of each index in the np_arr_test\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(DATAFRAME.columns) if ticker in SELECTED_TICKERS}\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(IND_CONVERSION.values())}\n",
    "\n",
    "print(\"Selected tickers: \\n\", SELECTED_TICKERS)\n",
    "print(\"Dataframe columns: \\n\", DATAFRAME.columns)\n",
    "print(\"Dataframe shape: \", DATAFRAME.shape)\n",
    "print(\"Dataframe head: \\n\", DATAFRAME.head(2))\n",
    "print(f\"Index conversion: \\n {IND_CONVERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_begin_idx = int(DATAFRAME.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "if PREDICT_PRICES:\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaler.fit(DATAFRAME.iloc[:test_begin_idx, :])\n",
    "    transformed_df = pd.DataFrame(scaler.transform(DATAFRAME), columns=DATAFRAME.columns, index=DATAFRAME.index)\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            return pd.DataFrame(scaler.inverse_transform(df), columns=df.columns, index=df.index)\n",
    "        elif isinstance(df, np.ndarray):\n",
    "            return scaler.inverse_transform(df)\n",
    "\n",
    "# If we are predicting the up/down, we create a dataframe where we subtract the previous value from the current value\n",
    "else:\n",
    "    # Do not diff the Time Delta column\n",
    "    df = DATAFRAME.copy()\n",
    "    if HAS_TIMEDELTA:\n",
    "        td_col = df[\"Time Delta\"]\n",
    "        df.drop(\"Time Delta\", axis=1, inplace=True)\n",
    "    transformed_df = df.diff()\n",
    "    # The first row is NaN, so lets copy the second row there\n",
    "    transformed_df.iloc[0, :] = transformed_df.iloc[1, :]\n",
    "    # Add back the Time Delta column\n",
    "    if HAS_TIMEDELTA:\n",
    "        transformed_df[\"Time Delta\"] = td_col\n",
    "        # Make Time Delta the first column\n",
    "        cols = transformed_df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        transformed_df = transformed_df[cols]\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        return df\n",
    "\n",
    "print(\"Transformed df: \\n\", transformed_df.head(2))\n",
    "print(\"Transformed df shape: \", transformed_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./models/\"):\n",
    "    os.makedirs(\"./models/\")\n",
    "\n",
    "METRICS = [MultiAccuracy()]\n",
    "CALLBACKS = [keras.callbacks.EarlyStopping(patience=10,\n",
    "                                           restore_best_weights=True)]\n",
    "CLASS_FIRST = True\n",
    "\n",
    "counter = 0\n",
    "RESUME = 0\n",
    "\n",
    "for memory_length in [10,50,200]:\n",
    "    if PREDICT_PRICES:\n",
    "        OUTPUT_SCALE = (0,1)\n",
    "        x, y = create_batch_xy(\n",
    "                    memory_length,\n",
    "                    transformed_np_arr,\n",
    "                    overlap=True,\n",
    "                    y_updown=False,\n",
    "                    diff_data=True,\n",
    "                    output_scale=OUTPUT_SCALE)\n",
    "    else:\n",
    "        x, x_ts, y = create_transformer_onehot_xy(\n",
    "                            memory_length,\n",
    "                            transformed_np_arr,\n",
    "                            DATAFRAME.to_numpy(),\n",
    "                            DATAFRAME.index.to_numpy(),\n",
    "                            0.01)\n",
    "\n",
    "    split_idx = int(x.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "    x_train = x[:split_idx,:,:]\n",
    "    x_ts_train = x_ts[:split_idx,:,:]\n",
    "    y_train = y[:split_idx,:,:]\n",
    "\n",
    "    x_test = x[split_idx:,:,:]\n",
    "    x_ts_test = x_ts[split_idx:,:,:]\n",
    "    y_test = y[split_idx:,:,:]\n",
    "\n",
    "    if CLASS_FIRST:\n",
    "        y_train = tf.transpose(y_train, (0,2,1))\n",
    "        y_test = tf.transpose(y_test, (0,2,1))\n",
    "\n",
    "    for head_size in [32,16,8]:\n",
    "        for num_heads in [32,16,8]:\n",
    "            for ff_dim in [64,32,16]:\n",
    "                for num_transformer_blocks in [4,2,1]:\n",
    "                    for mlp_units in [64,32,16]:\n",
    "                        if counter < RESUME:\n",
    "                            counter = counter + 1\n",
    "                            continue\n",
    "                        \n",
    "                        serial = \"transformer_model_\" \\\n",
    "                            + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                        model_dict = {\n",
    "                            \"serial\": serial,\n",
    "                            \"memory_length\": memory_length,\n",
    "                            \"head_size\": head_size,\n",
    "                            \"num_heads\": num_heads,\n",
    "                            \"ff_dim\": ff_dim,\n",
    "                            \"num_transformer_blocks\": num_transformer_blocks,\n",
    "                            \"mlp_units\": mlp_units\n",
    "                        }\n",
    "\n",
    "                        model = create_transformer_model(\n",
    "                                m=memory_length+1,\n",
    "                                n=len(SELECTED_TICKERS),\n",
    "                                output_dim=3,\n",
    "                                head_size=head_size,\n",
    "                                num_heads=num_heads,\n",
    "                                ff_dim=ff_dim,\n",
    "                                num_transformer_blocks=num_transformer_blocks,\n",
    "                                mlp_units=(mlp_units,),\n",
    "                                class_first=CLASS_FIRST\n",
    "                            )\n",
    "                        \n",
    "\n",
    "                        model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                                    loss=MultiSoftmaxLoss(),\n",
    "                                    metrics=METRICS)\n",
    "\n",
    "                        model.fit(x = (x_train,x_ts_train,x_train,x_ts_train),\n",
    "                                y = y_train,\n",
    "                                batch_size=32,\n",
    "                                epochs=100,\n",
    "                                validation_split=0.25,\n",
    "                                callbacks=CALLBACKS)\n",
    "                        \n",
    "                        model.save(\"./models/\"+serial+\".keras\")\n",
    "\n",
    "                        model_dict.update(model.evaluate(\n",
    "                                    x = (x_test,x_ts_test,x_test,x_ts_test),\n",
    "                                    y = y_test,\n",
    "                                    batch_size=32,\n",
    "                                    workers=4,\n",
    "                                    use_multiprocessing=True,\n",
    "                                    return_dict=True\n",
    "                                )\n",
    "                            )\n",
    "                        \n",
    "                        if os.path.exists(\"./transformer_results.json\"):\n",
    "                            with open(\"./transformer_results.json\", \"r\",\n",
    "                                      encoding=ENCODING) as json_file:\n",
    "                                model_list = json.load(json_file)\n",
    "                        else:\n",
    "                            model_list = [model_dict]\n",
    "                        \n",
    "                        with open(\"./transformer_results.json\", \"w\",\n",
    "                                  encoding=ENCODING) as json_file:\n",
    "                            json.dump(model_list, json_file)\n",
    "\n",
    "plot_model(\n",
    "        model,\n",
    "        to_file=\"./figures/transformer_model_plot.png\",\n",
    "        show_shapes=True,\n",
    "        show_layer_names = True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stonks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
