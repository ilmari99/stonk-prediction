{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 17:34:31.408509: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-10 17:34:31.433923: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-10 17:34:31.433948: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-10 17:34:31.433952: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-10 17:34:31.440103: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/sergiovaneg/miniforge3/envs/stonks/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import locale\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from stock_modules.stock_transform import (create_batch_xy,\n",
    "                                           create_transformer_onehot_xy)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from stock_modules.stock_ml import (create_transformer_model,\n",
    "                                    MultiSoftmaxLoss, MultiAccuracy)\n",
    "\n",
    "from invest_strategies import (calculate_optimal_invest_strategy,\n",
    "                               calculate_profit_on_invest_strategy,\n",
    "                               strategy_mask_from_direction_model)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "from stock_modules.stock_plot import plot_mask_and_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = locale.getpreferredencoding()\n",
    "DF_PATH = \"HEL_12-10-21to08-11-23.csv\"\n",
    "MODEL_SERIAL = None\n",
    "SELECTED_TICKERS_PATH = \"./TICKERS_TO_FOLLOW.json\"\n",
    "\n",
    "TEST_FRAC = 0.2\n",
    "PREDICT_PRICES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected tickers: \n",
      " ['ALBBV.HE', 'CGCBV.HE', 'EQV1V.HE', 'KNEBV.HE', 'ORNBV.HE', 'OLVAS.HE', 'DETEC.HE', 'PON1V.HE', 'ORNAV.HE', 'VALMT.HE', 'NESTE.HE', 'HUH1V.HE', 'REG1V.HE', 'VAIAS.HE']\n",
      "Dataframe columns: \n",
      " Index(['REG1V.HE', 'NESTE.HE', 'ORNBV.HE', 'KNEBV.HE', 'OLVAS.HE', 'HUH1V.HE',\n",
      "       'DETEC.HE', 'ORNAV.HE', 'CGCBV.HE', 'VAIAS.HE', 'ALBBV.HE', 'VALMT.HE',\n",
      "       'EQV1V.HE', 'PON1V.HE'],\n",
      "      dtype='object')\n",
      "Dataframe shape:  (4389, 14)\n",
      "Dataframe head: \n",
      "                       REG1V.HE   NESTE.HE   ORNBV.HE   KNEBV.HE   OLVAS.HE  \\\n",
      "date                                                                         \n",
      "2021-10-12 07:00:00  55.950001  41.820000  35.689999  60.220001  53.099998   \n",
      "2021-10-12 08:00:00  55.799999  41.720001  35.630001  60.419998  53.299999   \n",
      "\n",
      "                      HUH1V.HE  DETEC.HE   ORNAV.HE   CGCBV.HE   VAIAS.HE  \\\n",
      "date                                                                        \n",
      "2021-10-12 07:00:00  38.529999      23.0  38.049999  43.139999  46.150002   \n",
      "2021-10-12 08:00:00  38.560001      23.0  38.049999  43.500000  45.950001   \n",
      "\n",
      "                      ALBBV.HE   VALMT.HE   EQV1V.HE   PON1V.HE  \n",
      "date                                                             \n",
      "2021-10-12 07:00:00  28.700001  36.459999  24.850000  39.150002  \n",
      "2021-10-12 08:00:00  28.799999  36.599998  24.950001  39.200001  \n",
      "Index conversion: \n",
      " {0: 'REG1V.HE', 1: 'NESTE.HE', 2: 'ORNBV.HE', 3: 'KNEBV.HE', 4: 'OLVAS.HE', 5: 'HUH1V.HE', 6: 'DETEC.HE', 7: 'ORNAV.HE', 8: 'CGCBV.HE', 9: 'VAIAS.HE', 10: 'ALBBV.HE', 11: 'VALMT.HE', 12: 'EQV1V.HE', 13: 'PON1V.HE'}\n"
     ]
    }
   ],
   "source": [
    "SELECTED_TICKERS = json.load(open(SELECTED_TICKERS_PATH,\n",
    "                                  \"r\", encoding=ENCODING))\n",
    "DATAFRAME = pd.read_csv(DF_PATH, encoding=ENCODING)\n",
    "\n",
    "DATAFRAME.set_index(\"date\", inplace=True)\n",
    "HAS_TIMEDELTA = \"Time Delta\" in DATAFRAME.columns\n",
    "\n",
    "# ind transformation tells the label of each index in the np_arr_test\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(DATAFRAME.columns) if ticker in SELECTED_TICKERS}\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(IND_CONVERSION.values())}\n",
    "\n",
    "print(\"Selected tickers: \\n\", SELECTED_TICKERS)\n",
    "print(\"Dataframe columns: \\n\", DATAFRAME.columns)\n",
    "print(\"Dataframe shape: \", DATAFRAME.shape)\n",
    "print(\"Dataframe head: \\n\", DATAFRAME.head(2))\n",
    "print(f\"Index conversion: \\n {IND_CONVERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed df: \n",
      "                      REG1V.HE  NESTE.HE  ORNBV.HE  KNEBV.HE  OLVAS.HE  \\\n",
      "date                                                                    \n",
      "2021-10-12 07:00:00 -0.150002 -0.099998 -0.059998  0.199997  0.200001   \n",
      "2021-10-12 08:00:00 -0.150002 -0.099998 -0.059998  0.199997  0.200001   \n",
      "\n",
      "                     HUH1V.HE  DETEC.HE  ORNAV.HE  CGCBV.HE  VAIAS.HE  \\\n",
      "date                                                                    \n",
      "2021-10-12 07:00:00  0.030003       0.0       0.0  0.360001 -0.200001   \n",
      "2021-10-12 08:00:00  0.030003       0.0       0.0  0.360001 -0.200001   \n",
      "\n",
      "                     ALBBV.HE  VALMT.HE  EQV1V.HE  PON1V.HE  \n",
      "date                                                         \n",
      "2021-10-12 07:00:00  0.099998  0.139999       0.1  0.049999  \n",
      "2021-10-12 08:00:00  0.099998  0.139999       0.1  0.049999  \n",
      "Transformed df shape:  (4389, 14)\n"
     ]
    }
   ],
   "source": [
    "test_begin_idx = int(DATAFRAME.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "if PREDICT_PRICES:\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaler.fit(DATAFRAME.iloc[:test_begin_idx, :])\n",
    "    transformed_df = pd.DataFrame(scaler.transform(DATAFRAME), columns=DATAFRAME.columns, index=DATAFRAME.index)\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            return pd.DataFrame(scaler.inverse_transform(df), columns=df.columns, index=df.index)\n",
    "        elif isinstance(df, np.ndarray):\n",
    "            return scaler.inverse_transform(df)\n",
    "\n",
    "# If we are predicting the up/down, we create a dataframe where we subtract the previous value from the current value\n",
    "else:\n",
    "    # Do not diff the Time Delta column\n",
    "    df = DATAFRAME.copy()\n",
    "    if HAS_TIMEDELTA:\n",
    "        td_col = df[\"Time Delta\"]\n",
    "        df.drop(\"Time Delta\", axis=1, inplace=True)\n",
    "    transformed_df = df.diff()\n",
    "    # The first row is NaN, so lets copy the second row there\n",
    "    transformed_df.iloc[0, :] = transformed_df.iloc[1, :]\n",
    "    # Add back the Time Delta column\n",
    "    if HAS_TIMEDELTA:\n",
    "        transformed_df[\"Time Delta\"] = td_col\n",
    "        # Make Time Delta the first column\n",
    "        cols = transformed_df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        transformed_df = transformed_df[cols]\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        return df\n",
    "\n",
    "print(\"Transformed df: \\n\", transformed_df.head(2))\n",
    "print(\"Transformed df shape: \", transformed_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 17:34:34.793398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 17:34:34.971471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 17:34:34.971531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 17:34:34.973966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 17:34:34.974347: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 17:34:34.974451: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 17:34:35.436196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 17:34:35.436291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 17:34:35.436298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-10 17:34:35.436337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 17:34:35.436354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4071 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 17:34:50.180912: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-10 17:34:50.213850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8800\n",
      "2023-12-10 17:34:50.662242: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-10 17:34:52.724427: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff414157250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-10 17:34:52.724465: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2023-12-10 17:34:52.727881: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-10 17:34:52.777047: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 31s 117ms/step - loss: 1.5728 - multi_accuracy: 0.3433 - val_loss: 1.1063 - val_multi_accuracy: 0.3460\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 7s 89ms/step - loss: 1.0976 - multi_accuracy: 0.3380 - val_loss: 1.1067 - val_multi_accuracy: 0.3385\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0963 - multi_accuracy: 0.3345 - val_loss: 1.1030 - val_multi_accuracy: 0.3373\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 1.0953 - multi_accuracy: 0.3346 - val_loss: 1.1033 - val_multi_accuracy: 0.3367\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 6s 77ms/step - loss: 1.0944 - multi_accuracy: 0.3348 - val_loss: 1.1037 - val_multi_accuracy: 0.3368\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.0936 - multi_accuracy: 0.3354 - val_loss: 1.1014 - val_multi_accuracy: 0.3366\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 7s 81ms/step - loss: 1.0933 - multi_accuracy: 0.3354 - val_loss: 1.0965 - val_multi_accuracy: 0.3362\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 7s 85ms/step - loss: 1.0926 - multi_accuracy: 0.3351 - val_loss: 1.0996 - val_multi_accuracy: 0.3357\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 7s 81ms/step - loss: 1.0923 - multi_accuracy: 0.3347 - val_loss: 1.0991 - val_multi_accuracy: 0.3349\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 1.0920 - multi_accuracy: 0.3341 - val_loss: 1.0971 - val_multi_accuracy: 0.3341\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 7s 81ms/step - loss: 1.0920 - multi_accuracy: 0.3334 - val_loss: 1.1006 - val_multi_accuracy: 0.3332\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0915 - multi_accuracy: 0.3325 - val_loss: 1.0949 - val_multi_accuracy: 0.3330\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 7s 87ms/step - loss: 1.0914 - multi_accuracy: 0.3324 - val_loss: 1.0944 - val_multi_accuracy: 0.3326\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 7s 81ms/step - loss: 1.0912 - multi_accuracy: 0.3321 - val_loss: 1.0983 - val_multi_accuracy: 0.3324\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0909 - multi_accuracy: 0.3319 - val_loss: 1.0969 - val_multi_accuracy: 0.3321\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.0911 - multi_accuracy: 0.3316 - val_loss: 1.0951 - val_multi_accuracy: 0.3320\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 6s 78ms/step - loss: 1.0911 - multi_accuracy: 0.3315 - val_loss: 1.1005 - val_multi_accuracy: 0.3317\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 1.0905 - multi_accuracy: 0.3314 - val_loss: 1.0988 - val_multi_accuracy: 0.3315\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 1.0993 - multi_accuracy: 0.3317\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 29s 123ms/step - loss: 2.4295 - multi_accuracy: 0.3344 - val_loss: 1.6149 - val_multi_accuracy: 0.3430\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 7s 84ms/step - loss: 1.4845 - multi_accuracy: 0.3359 - val_loss: 1.6082 - val_multi_accuracy: 0.3385\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 7s 84ms/step - loss: 1.5308 - multi_accuracy: 0.3362 - val_loss: 1.5775 - val_multi_accuracy: 0.3384\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 7s 84ms/step - loss: 1.5610 - multi_accuracy: 0.3361 - val_loss: 1.5962 - val_multi_accuracy: 0.3372\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.5793 - multi_accuracy: 0.3356 - val_loss: 1.5975 - val_multi_accuracy: 0.3365\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.6402 - multi_accuracy: 0.3355 - val_loss: 1.5993 - val_multi_accuracy: 0.3361\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.6681 - multi_accuracy: 0.3352 - val_loss: 1.6014 - val_multi_accuracy: 0.3357\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.7108 - multi_accuracy: 0.3347 - val_loss: 1.6048 - val_multi_accuracy: 0.3352\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.5706 - multi_accuracy: 0.3362\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 28s 121ms/step - loss: 1.8234 - multi_accuracy: 0.3291 - val_loss: 1.1077 - val_multi_accuracy: 0.3210\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 8s 94ms/step - loss: 1.1058 - multi_accuracy: 0.3249 - val_loss: 1.1035 - val_multi_accuracy: 0.3246\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 7s 88ms/step - loss: 1.0989 - multi_accuracy: 0.3244 - val_loss: 1.0983 - val_multi_accuracy: 0.3230\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.0957 - multi_accuracy: 0.3229 - val_loss: 1.0965 - val_multi_accuracy: 0.3236\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 7s 87ms/step - loss: 1.0944 - multi_accuracy: 0.3229 - val_loss: 1.0958 - val_multi_accuracy: 0.3225\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 7s 89ms/step - loss: 1.0947 - multi_accuracy: 0.3225 - val_loss: 1.0990 - val_multi_accuracy: 0.3222\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 7s 85ms/step - loss: 1.0934 - multi_accuracy: 0.3221 - val_loss: 1.1005 - val_multi_accuracy: 0.3216\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 7s 84ms/step - loss: 1.0933 - multi_accuracy: 0.3216 - val_loss: 1.1000 - val_multi_accuracy: 0.3215\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 7s 81ms/step - loss: 1.0930 - multi_accuracy: 0.3213 - val_loss: 1.0992 - val_multi_accuracy: 0.3212\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0930 - multi_accuracy: 0.3211 - val_loss: 1.0986 - val_multi_accuracy: 0.3208\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0996 - multi_accuracy: 0.3207\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 19s 92ms/step - loss: 2.2653 - multi_accuracy: 0.3228 - val_loss: 1.1033 - val_multi_accuracy: 0.3219\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.1018 - multi_accuracy: 0.3295 - val_loss: 1.1061 - val_multi_accuracy: 0.3273\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 1.0997 - multi_accuracy: 0.3326 - val_loss: 1.1055 - val_multi_accuracy: 0.3316\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0983 - multi_accuracy: 0.3353 - val_loss: 1.1037 - val_multi_accuracy: 0.3344\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0976 - multi_accuracy: 0.3369 - val_loss: 1.1022 - val_multi_accuracy: 0.3360\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.0970 - multi_accuracy: 0.3377 - val_loss: 1.1036 - val_multi_accuracy: 0.3372\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.0964 - multi_accuracy: 0.3388 - val_loss: 1.1020 - val_multi_accuracy: 0.3384\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 5s 60ms/step - loss: 1.0961 - multi_accuracy: 0.3398 - val_loss: 1.1008 - val_multi_accuracy: 0.3395\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.0953 - multi_accuracy: 0.3406 - val_loss: 1.0983 - val_multi_accuracy: 0.3405\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 1.0946 - multi_accuracy: 0.3414 - val_loss: 1.0988 - val_multi_accuracy: 0.3414\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.0941 - multi_accuracy: 0.3425 - val_loss: 1.0955 - val_multi_accuracy: 0.3428\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0936 - multi_accuracy: 0.3437 - val_loss: 1.1021 - val_multi_accuracy: 0.3436\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.0935 - multi_accuracy: 0.3445 - val_loss: 1.1000 - val_multi_accuracy: 0.3447\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.0928 - multi_accuracy: 0.3456 - val_loss: 1.0987 - val_multi_accuracy: 0.3459\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 8s 102ms/step - loss: 1.0925 - multi_accuracy: 0.3467 - val_loss: 1.0968 - val_multi_accuracy: 0.3471\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 7s 85ms/step - loss: 1.0922 - multi_accuracy: 0.3478 - val_loss: 1.1013 - val_multi_accuracy: 0.3479\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 1.0992 - multi_accuracy: 0.3478\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 19s 96ms/step - loss: 4.0636 - multi_accuracy: 0.3436 - val_loss: 4.3247 - val_multi_accuracy: 0.3375\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 1.9861 - multi_accuracy: 0.3374 - val_loss: 1.1035 - val_multi_accuracy: 0.3365\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 1.0968 - multi_accuracy: 0.3336 - val_loss: 1.1003 - val_multi_accuracy: 0.3336\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 1.0952 - multi_accuracy: 0.3326 - val_loss: 1.0995 - val_multi_accuracy: 0.3332\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 5s 64ms/step - loss: 1.0944 - multi_accuracy: 0.3326 - val_loss: 1.0996 - val_multi_accuracy: 0.3339\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0934 - multi_accuracy: 0.3339 - val_loss: 1.0985 - val_multi_accuracy: 0.3350\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 1.0930 - multi_accuracy: 0.3347 - val_loss: 1.0960 - val_multi_accuracy: 0.3360\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 1.0932 - multi_accuracy: 0.3361 - val_loss: 1.1003 - val_multi_accuracy: 0.3369\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0927 - multi_accuracy: 0.3367 - val_loss: 1.1000 - val_multi_accuracy: 0.3373\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.0929 - multi_accuracy: 0.3371 - val_loss: 1.0995 - val_multi_accuracy: 0.3379\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.0925 - multi_accuracy: 0.3379 - val_loss: 1.0988 - val_multi_accuracy: 0.3386\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.0923 - multi_accuracy: 0.3387 - val_loss: 1.1017 - val_multi_accuracy: 0.3393\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 1.1015 - multi_accuracy: 0.3397\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 19s 94ms/step - loss: 4.3305 - multi_accuracy: 0.3203 - val_loss: 1.7088 - val_multi_accuracy: 0.3324\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.5962 - multi_accuracy: 0.3276 - val_loss: 1.4559 - val_multi_accuracy: 0.3306\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.2393 - multi_accuracy: 0.3305 - val_loss: 1.1151 - val_multi_accuracy: 0.3317\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 5s 64ms/step - loss: 1.1080 - multi_accuracy: 0.3320 - val_loss: 1.1100 - val_multi_accuracy: 0.3327\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.1033 - multi_accuracy: 0.3327 - val_loss: 1.1069 - val_multi_accuracy: 0.3334\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.1005 - multi_accuracy: 0.3336 - val_loss: 1.1061 - val_multi_accuracy: 0.3341\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 1.0993 - multi_accuracy: 0.3337 - val_loss: 1.1040 - val_multi_accuracy: 0.3342\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 5s 60ms/step - loss: 1.0982 - multi_accuracy: 0.3337 - val_loss: 1.1034 - val_multi_accuracy: 0.3339\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 5s 58ms/step - loss: 1.0970 - multi_accuracy: 0.3336 - val_loss: 1.1026 - val_multi_accuracy: 0.3339\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.0968 - multi_accuracy: 0.3335 - val_loss: 1.1019 - val_multi_accuracy: 0.3337\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 6s 66ms/step - loss: 1.0965 - multi_accuracy: 0.3333 - val_loss: 1.1008 - val_multi_accuracy: 0.3335\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 5s 60ms/step - loss: 1.0957 - multi_accuracy: 0.3330 - val_loss: 1.1015 - val_multi_accuracy: 0.3331\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 6s 70ms/step - loss: 1.0953 - multi_accuracy: 0.3329 - val_loss: 1.1021 - val_multi_accuracy: 0.3330\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.0954 - multi_accuracy: 0.3325 - val_loss: 1.1014 - val_multi_accuracy: 0.3326\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.0951 - multi_accuracy: 0.3323 - val_loss: 1.1015 - val_multi_accuracy: 0.3323\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.0948 - multi_accuracy: 0.3320 - val_loss: 1.1009 - val_multi_accuracy: 0.3320\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 1.1032 - multi_accuracy: 0.3322\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 16s 88ms/step - loss: 1.9542 - multi_accuracy: 0.3330 - val_loss: 1.1466 - val_multi_accuracy: 0.3311\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 1.1081 - multi_accuracy: 0.3272 - val_loss: 1.1110 - val_multi_accuracy: 0.3326\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.0996 - multi_accuracy: 0.3279 - val_loss: 1.1074 - val_multi_accuracy: 0.3307\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.0981 - multi_accuracy: 0.3268 - val_loss: 1.1031 - val_multi_accuracy: 0.3284\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0973 - multi_accuracy: 0.3252 - val_loss: 1.1005 - val_multi_accuracy: 0.3262\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0967 - multi_accuracy: 0.3238 - val_loss: 1.1047 - val_multi_accuracy: 0.3256\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0965 - multi_accuracy: 0.3233 - val_loss: 1.1026 - val_multi_accuracy: 0.3247\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0959 - multi_accuracy: 0.3229 - val_loss: 1.1014 - val_multi_accuracy: 0.3241\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0954 - multi_accuracy: 0.3225 - val_loss: 1.1025 - val_multi_accuracy: 0.3237\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0945 - multi_accuracy: 0.3221 - val_loss: 1.0996 - val_multi_accuracy: 0.3231\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0939 - multi_accuracy: 0.3217 - val_loss: 1.0988 - val_multi_accuracy: 0.3224\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0932 - multi_accuracy: 0.3211 - val_loss: 1.0977 - val_multi_accuracy: 0.3217\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 1.0928 - multi_accuracy: 0.3206 - val_loss: 1.0972 - val_multi_accuracy: 0.3212\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0915 - multi_accuracy: 0.3200 - val_loss: 1.0956 - val_multi_accuracy: 0.3201\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 1.0905 - multi_accuracy: 0.3191 - val_loss: 1.0955 - val_multi_accuracy: 0.3194\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0897 - multi_accuracy: 0.3183 - val_loss: 1.0928 - val_multi_accuracy: 0.3180\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0882 - multi_accuracy: 0.3169 - val_loss: 1.0947 - val_multi_accuracy: 0.3166\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0880 - multi_accuracy: 0.3154 - val_loss: 1.1000 - val_multi_accuracy: 0.3158\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.0848 - multi_accuracy: 0.3145 - val_loss: 1.0916 - val_multi_accuracy: 0.3143\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 1.0823 - multi_accuracy: 0.3130 - val_loss: 1.0951 - val_multi_accuracy: 0.3130\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.0799 - multi_accuracy: 0.3115 - val_loss: 1.0873 - val_multi_accuracy: 0.3112\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0770 - multi_accuracy: 0.3097 - val_loss: 1.0834 - val_multi_accuracy: 0.3092\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.0735 - multi_accuracy: 0.3077 - val_loss: 1.0807 - val_multi_accuracy: 0.3073\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.0735 - multi_accuracy: 0.3059 - val_loss: 1.0856 - val_multi_accuracy: 0.3057\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 1.0754 - multi_accuracy: 0.3045 - val_loss: 1.0864 - val_multi_accuracy: 0.3042\n",
      "28/28 [==============================] - 1s 17ms/step - loss: 1.0848 - multi_accuracy: 0.3040\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 15s 83ms/step - loss: 3.2732 - multi_accuracy: 0.3220 - val_loss: 1.9247 - val_multi_accuracy: 0.3221\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.5573 - multi_accuracy: 0.3286 - val_loss: 1.5449 - val_multi_accuracy: 0.3266\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.5092 - multi_accuracy: 0.3323 - val_loss: 1.3671 - val_multi_accuracy: 0.3304\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.4596 - multi_accuracy: 0.3336 - val_loss: 1.4952 - val_multi_accuracy: 0.3325\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.5611 - multi_accuracy: 0.3351 - val_loss: 1.5841 - val_multi_accuracy: 0.3338\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.4644 - multi_accuracy: 0.3357 - val_loss: 1.3402 - val_multi_accuracy: 0.3345\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.1085 - multi_accuracy: 0.3359 - val_loss: 1.1091 - val_multi_accuracy: 0.3347\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0984 - multi_accuracy: 0.3357 - val_loss: 1.1086 - val_multi_accuracy: 0.3348\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0980 - multi_accuracy: 0.3357 - val_loss: 1.1083 - val_multi_accuracy: 0.3350\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0969 - multi_accuracy: 0.3362 - val_loss: 1.1076 - val_multi_accuracy: 0.3356\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0967 - multi_accuracy: 0.3368 - val_loss: 1.1071 - val_multi_accuracy: 0.3363\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0964 - multi_accuracy: 0.3373 - val_loss: 1.1072 - val_multi_accuracy: 0.3368\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0962 - multi_accuracy: 0.3378 - val_loss: 1.1065 - val_multi_accuracy: 0.3374\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0960 - multi_accuracy: 0.3383 - val_loss: 1.1056 - val_multi_accuracy: 0.3379\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0955 - multi_accuracy: 0.3388 - val_loss: 1.1048 - val_multi_accuracy: 0.3385\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0951 - multi_accuracy: 0.3395 - val_loss: 1.1047 - val_multi_accuracy: 0.3393\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0948 - multi_accuracy: 0.3402 - val_loss: 1.1044 - val_multi_accuracy: 0.3401\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0945 - multi_accuracy: 0.3409 - val_loss: 1.1041 - val_multi_accuracy: 0.3408\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0939 - multi_accuracy: 0.3417 - val_loss: 1.1033 - val_multi_accuracy: 0.3417\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0934 - multi_accuracy: 0.3425 - val_loss: 1.1029 - val_multi_accuracy: 0.3426\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0930 - multi_accuracy: 0.3433 - val_loss: 1.1020 - val_multi_accuracy: 0.3434\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0925 - multi_accuracy: 0.3442 - val_loss: 1.1021 - val_multi_accuracy: 0.3443\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0919 - multi_accuracy: 0.3450 - val_loss: 1.1015 - val_multi_accuracy: 0.3451\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0919 - multi_accuracy: 0.3458 - val_loss: 1.1001 - val_multi_accuracy: 0.3459\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0912 - multi_accuracy: 0.3466 - val_loss: 1.1011 - val_multi_accuracy: 0.3467\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.1042 - multi_accuracy: 0.3470\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 14s 80ms/step - loss: 2.4401 - multi_accuracy: 0.3492 - val_loss: 1.3342 - val_multi_accuracy: 0.3433\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.1741 - multi_accuracy: 0.3462 - val_loss: 1.1305 - val_multi_accuracy: 0.3438\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.1166 - multi_accuracy: 0.3461 - val_loss: 1.1172 - val_multi_accuracy: 0.3447\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 5s 54ms/step - loss: 1.1081 - multi_accuracy: 0.3460 - val_loss: 1.1121 - val_multi_accuracy: 0.3450\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.1025 - multi_accuracy: 0.3464 - val_loss: 1.1107 - val_multi_accuracy: 0.3454\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.1020 - multi_accuracy: 0.3466 - val_loss: 1.1080 - val_multi_accuracy: 0.3459\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0990 - multi_accuracy: 0.3471 - val_loss: 1.1053 - val_multi_accuracy: 0.3465\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0972 - multi_accuracy: 0.3478 - val_loss: 1.1035 - val_multi_accuracy: 0.3475\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0959 - multi_accuracy: 0.3487 - val_loss: 1.1034 - val_multi_accuracy: 0.3483\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0953 - multi_accuracy: 0.3495 - val_loss: 1.1036 - val_multi_accuracy: 0.3490\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0946 - multi_accuracy: 0.3499 - val_loss: 1.1013 - val_multi_accuracy: 0.3496\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0940 - multi_accuracy: 0.3505 - val_loss: 1.1016 - val_multi_accuracy: 0.3502\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0935 - multi_accuracy: 0.3508 - val_loss: 1.1000 - val_multi_accuracy: 0.3506\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 1.0926 - multi_accuracy: 0.3514 - val_loss: 1.0993 - val_multi_accuracy: 0.3512\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.0918 - multi_accuracy: 0.3521 - val_loss: 1.0984 - val_multi_accuracy: 0.3520\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0920 - multi_accuracy: 0.3528 - val_loss: 1.0980 - val_multi_accuracy: 0.3527\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0913 - multi_accuracy: 0.3536 - val_loss: 1.0997 - val_multi_accuracy: 0.3535\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 5s 58ms/step - loss: 1.0903 - multi_accuracy: 0.3544 - val_loss: 1.0971 - val_multi_accuracy: 0.3544\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 1.0895 - multi_accuracy: 0.3553 - val_loss: 1.0960 - val_multi_accuracy: 0.3554\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.0889 - multi_accuracy: 0.3562 - val_loss: 1.0957 - val_multi_accuracy: 0.3564\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 5s 54ms/step - loss: 1.0885 - multi_accuracy: 0.3571 - val_loss: 1.0943 - val_multi_accuracy: 0.3574\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.0880 - multi_accuracy: 0.3582 - val_loss: 1.0952 - val_multi_accuracy: 0.3584\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 1.0882 - multi_accuracy: 0.3591 - val_loss: 1.0924 - val_multi_accuracy: 0.3594\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0870 - multi_accuracy: 0.3603 - val_loss: 1.0931 - val_multi_accuracy: 0.3605\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0858 - multi_accuracy: 0.3614 - val_loss: 1.0933 - val_multi_accuracy: 0.3616\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0998 - multi_accuracy: 0.3619\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 30s 123ms/step - loss: 5.4758 - multi_accuracy: 0.3472 - val_loss: 5.1000 - val_multi_accuracy: 0.3474\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 8s 99ms/step - loss: 3.5320 - multi_accuracy: 0.3400 - val_loss: 3.3255 - val_multi_accuracy: 0.3402\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 8s 97ms/step - loss: 3.0229 - multi_accuracy: 0.3331 - val_loss: 3.3158 - val_multi_accuracy: 0.3337\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 7s 87ms/step - loss: 3.0123 - multi_accuracy: 0.3293 - val_loss: 2.6500 - val_multi_accuracy: 0.3312\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 7s 90ms/step - loss: 2.3252 - multi_accuracy: 0.3287 - val_loss: 2.6093 - val_multi_accuracy: 0.3296\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 8s 95ms/step - loss: 2.3666 - multi_accuracy: 0.3286 - val_loss: 1.1253 - val_multi_accuracy: 0.3295\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 7s 90ms/step - loss: 1.1036 - multi_accuracy: 0.3284 - val_loss: 1.1128 - val_multi_accuracy: 0.3290\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 7s 90ms/step - loss: 1.1000 - multi_accuracy: 0.3283 - val_loss: 1.1091 - val_multi_accuracy: 0.3288\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 8s 98ms/step - loss: 1.0987 - multi_accuracy: 0.3285 - val_loss: 1.1070 - val_multi_accuracy: 0.3289\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.0985 - multi_accuracy: 0.3285 - val_loss: 1.1080 - val_multi_accuracy: 0.3289\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 7s 87ms/step - loss: 1.0978 - multi_accuracy: 0.3282 - val_loss: 1.1066 - val_multi_accuracy: 0.3284\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 1.0975 - multi_accuracy: 0.3278 - val_loss: 1.1063 - val_multi_accuracy: 0.3280\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 1.0966 - multi_accuracy: 0.3273 - val_loss: 1.1041 - val_multi_accuracy: 0.3271\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 7s 89ms/step - loss: 1.0964 - multi_accuracy: 0.3265 - val_loss: 1.1058 - val_multi_accuracy: 0.3267\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 8s 93ms/step - loss: 1.0965 - multi_accuracy: 0.3263 - val_loss: 1.1057 - val_multi_accuracy: 0.3265\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 8s 92ms/step - loss: 1.0962 - multi_accuracy: 0.3261 - val_loss: 1.1023 - val_multi_accuracy: 0.3260\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 1.0964 - multi_accuracy: 0.3255 - val_loss: 1.1040 - val_multi_accuracy: 0.3254\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 7s 85ms/step - loss: 1.0962 - multi_accuracy: 0.3249 - val_loss: 1.1041 - val_multi_accuracy: 0.3250\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 7s 88ms/step - loss: 1.0955 - multi_accuracy: 0.3247 - val_loss: 1.1042 - val_multi_accuracy: 0.3249\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 7s 90ms/step - loss: 1.0951 - multi_accuracy: 0.3246 - val_loss: 1.1044 - val_multi_accuracy: 0.3246\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 8s 92ms/step - loss: 1.0949 - multi_accuracy: 0.3243 - val_loss: 1.1027 - val_multi_accuracy: 0.3243\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 1.1043 - multi_accuracy: 0.3242\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 31s 127ms/step - loss: 1.4872 - multi_accuracy: 0.3457 - val_loss: 1.1049 - val_multi_accuracy: 0.3405\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 8s 94ms/step - loss: 1.0984 - multi_accuracy: 0.3437 - val_loss: 1.1036 - val_multi_accuracy: 0.3417\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 7s 88ms/step - loss: 1.0967 - multi_accuracy: 0.3435 - val_loss: 1.1019 - val_multi_accuracy: 0.3428\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 7s 85ms/step - loss: 1.0953 - multi_accuracy: 0.3445 - val_loss: 1.0998 - val_multi_accuracy: 0.3449\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 8s 92ms/step - loss: 1.0939 - multi_accuracy: 0.3460 - val_loss: 1.0990 - val_multi_accuracy: 0.3463\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 8s 97ms/step - loss: 1.0932 - multi_accuracy: 0.3475 - val_loss: 1.0965 - val_multi_accuracy: 0.3489\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 1.0927 - multi_accuracy: 0.3497 - val_loss: 1.0968 - val_multi_accuracy: 0.3510\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 7s 85ms/step - loss: 1.0920 - multi_accuracy: 0.3520 - val_loss: 1.0988 - val_multi_accuracy: 0.3529\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 7s 90ms/step - loss: 1.0919 - multi_accuracy: 0.3539 - val_loss: 1.0977 - val_multi_accuracy: 0.3546\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 8s 92ms/step - loss: 1.0916 - multi_accuracy: 0.3557 - val_loss: 1.0938 - val_multi_accuracy: 0.3564\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 7s 89ms/step - loss: 1.0917 - multi_accuracy: 0.3570 - val_loss: 1.0966 - val_multi_accuracy: 0.3576\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 8s 92ms/step - loss: 1.0914 - multi_accuracy: 0.3581 - val_loss: 1.0966 - val_multi_accuracy: 0.3586\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 7s 89ms/step - loss: 1.0913 - multi_accuracy: 0.3590 - val_loss: 1.0943 - val_multi_accuracy: 0.3594\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 7s 88ms/step - loss: 1.0913 - multi_accuracy: 0.3598 - val_loss: 1.1051 - val_multi_accuracy: 0.3598\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 7s 87ms/step - loss: 1.0917 - multi_accuracy: 0.3601 - val_loss: 1.0931 - val_multi_accuracy: 0.3604\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.0913 - multi_accuracy: 0.3606 - val_loss: 1.0958 - val_multi_accuracy: 0.3609\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.0913 - multi_accuracy: 0.3612 - val_loss: 1.0986 - val_multi_accuracy: 0.3615\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0909 - multi_accuracy: 0.3617 - val_loss: 1.0967 - val_multi_accuracy: 0.3620\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 7s 84ms/step - loss: 1.0910 - multi_accuracy: 0.3623 - val_loss: 1.0928 - val_multi_accuracy: 0.3625\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0906 - multi_accuracy: 0.3628 - val_loss: 1.1113 - val_multi_accuracy: 0.3629\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0901 - multi_accuracy: 0.3631 - val_loss: 1.0985 - val_multi_accuracy: 0.3632\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0902 - multi_accuracy: 0.3636 - val_loss: 1.0953 - val_multi_accuracy: 0.3638\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 1.0886 - multi_accuracy: 0.3640 - val_loss: 1.0969 - val_multi_accuracy: 0.3642\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 1.0894 - multi_accuracy: 0.3646 - val_loss: 1.0973 - val_multi_accuracy: 0.3649\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.0986 - multi_accuracy: 0.3651\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 29s 120ms/step - loss: 3.5340 - multi_accuracy: 0.3423 - val_loss: 2.5836 - val_multi_accuracy: 0.3358\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 7s 88ms/step - loss: 2.7250 - multi_accuracy: 0.3389 - val_loss: 2.5718 - val_multi_accuracy: 0.3393\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 7s 84ms/step - loss: 2.7060 - multi_accuracy: 0.3389 - val_loss: 2.5646 - val_multi_accuracy: 0.3413\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 2.7004 - multi_accuracy: 0.3393 - val_loss: 2.5626 - val_multi_accuracy: 0.3410\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 2.6941 - multi_accuracy: 0.3397 - val_loss: 2.5620 - val_multi_accuracy: 0.3406\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 7s 81ms/step - loss: 2.6928 - multi_accuracy: 0.3386 - val_loss: 2.5631 - val_multi_accuracy: 0.3392\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 7s 81ms/step - loss: 2.6901 - multi_accuracy: 0.3382 - val_loss: 2.5628 - val_multi_accuracy: 0.3387\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 7s 81ms/step - loss: 2.6902 - multi_accuracy: 0.3377 - val_loss: 2.5635 - val_multi_accuracy: 0.3382\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 2.6944 - multi_accuracy: 0.3372 - val_loss: 2.5634 - val_multi_accuracy: 0.3375\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 2.6932 - multi_accuracy: 0.3364 - val_loss: 2.5627 - val_multi_accuracy: 0.3367\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 2.4742 - multi_accuracy: 0.3373\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 19s 92ms/step - loss: 2.5588 - multi_accuracy: 0.3222 - val_loss: 1.1942 - val_multi_accuracy: 0.3243\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.1322 - multi_accuracy: 0.3258 - val_loss: 1.1159 - val_multi_accuracy: 0.3248\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.1068 - multi_accuracy: 0.3269 - val_loss: 1.1116 - val_multi_accuracy: 0.3263\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.1029 - multi_accuracy: 0.3283 - val_loss: 1.1103 - val_multi_accuracy: 0.3273\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 5s 60ms/step - loss: 1.1007 - multi_accuracy: 0.3291 - val_loss: 1.1075 - val_multi_accuracy: 0.3285\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.0993 - multi_accuracy: 0.3300 - val_loss: 1.1031 - val_multi_accuracy: 0.3300\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 6s 66ms/step - loss: 1.0981 - multi_accuracy: 0.3313 - val_loss: 1.1046 - val_multi_accuracy: 0.3311\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 1.0971 - multi_accuracy: 0.3324 - val_loss: 1.1032 - val_multi_accuracy: 0.3323\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.0964 - multi_accuracy: 0.3336 - val_loss: 1.1073 - val_multi_accuracy: 0.3332\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 1.0958 - multi_accuracy: 0.3344 - val_loss: 1.1049 - val_multi_accuracy: 0.3341\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.0948 - multi_accuracy: 0.3354 - val_loss: 1.1017 - val_multi_accuracy: 0.3354\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.0944 - multi_accuracy: 0.3366 - val_loss: 1.1012 - val_multi_accuracy: 0.3367\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 5s 60ms/step - loss: 1.0938 - multi_accuracy: 0.3378 - val_loss: 1.1019 - val_multi_accuracy: 0.3378\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.0932 - multi_accuracy: 0.3389 - val_loss: 1.1017 - val_multi_accuracy: 0.3390\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.0925 - multi_accuracy: 0.3398 - val_loss: 1.0982 - val_multi_accuracy: 0.3400\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 1.0920 - multi_accuracy: 0.3410 - val_loss: 1.0980 - val_multi_accuracy: 0.3412\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.0912 - multi_accuracy: 0.3422 - val_loss: 1.0966 - val_multi_accuracy: 0.3423\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0908 - multi_accuracy: 0.3431 - val_loss: 1.0964 - val_multi_accuracy: 0.3432\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 1.0895 - multi_accuracy: 0.3442 - val_loss: 1.0984 - val_multi_accuracy: 0.3442\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.0898 - multi_accuracy: 0.3452 - val_loss: 1.0965 - val_multi_accuracy: 0.3453\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.0877 - multi_accuracy: 0.3462 - val_loss: 1.1018 - val_multi_accuracy: 0.3462\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.0872 - multi_accuracy: 0.3473 - val_loss: 1.0961 - val_multi_accuracy: 0.3473\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0859 - multi_accuracy: 0.3483 - val_loss: 1.0991 - val_multi_accuracy: 0.3483\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.0854 - multi_accuracy: 0.3493 - val_loss: 1.0917 - val_multi_accuracy: 0.3494\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 1.0896 - multi_accuracy: 0.3500 - val_loss: 1.1035 - val_multi_accuracy: 0.3499\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.1061 - multi_accuracy: 0.3498\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 20s 97ms/step - loss: 5.4086 - multi_accuracy: 0.3445 - val_loss: 6.4716 - val_multi_accuracy: 0.3376\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 5.2007 - multi_accuracy: 0.3404 - val_loss: 5.5946 - val_multi_accuracy: 0.3400\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 5.2383 - multi_accuracy: 0.3406 - val_loss: 5.9808 - val_multi_accuracy: 0.3397\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 5s 64ms/step - loss: 5.3067 - multi_accuracy: 0.3405 - val_loss: 6.0071 - val_multi_accuracy: 0.3395\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 5.3822 - multi_accuracy: 0.3411 - val_loss: 6.1999 - val_multi_accuracy: 0.3403\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 5.5239 - multi_accuracy: 0.3416 - val_loss: 6.4048 - val_multi_accuracy: 0.3409\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 5.6388 - multi_accuracy: 0.3418 - val_loss: 6.5746 - val_multi_accuracy: 0.3411\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 5.7604 - multi_accuracy: 0.3408\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 18s 97ms/step - loss: 2.1541 - multi_accuracy: 0.3259 - val_loss: 1.1956 - val_multi_accuracy: 0.3320\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.1047 - multi_accuracy: 0.3276 - val_loss: 1.1043 - val_multi_accuracy: 0.3306\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0998 - multi_accuracy: 0.3266 - val_loss: 1.1025 - val_multi_accuracy: 0.3284\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.0987 - multi_accuracy: 0.3263 - val_loss: 1.1030 - val_multi_accuracy: 0.3283\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.0979 - multi_accuracy: 0.3265 - val_loss: 1.1038 - val_multi_accuracy: 0.3281\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0969 - multi_accuracy: 0.3264 - val_loss: 1.1035 - val_multi_accuracy: 0.3278\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.0965 - multi_accuracy: 0.3260 - val_loss: 1.1023 - val_multi_accuracy: 0.3271\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0958 - multi_accuracy: 0.3256 - val_loss: 1.1036 - val_multi_accuracy: 0.3267\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 1.0953 - multi_accuracy: 0.3252 - val_loss: 1.1021 - val_multi_accuracy: 0.3262\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.0950 - multi_accuracy: 0.3247 - val_loss: 1.1015 - val_multi_accuracy: 0.3255\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 1.0944 - multi_accuracy: 0.3240 - val_loss: 1.0973 - val_multi_accuracy: 0.3242\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.0944 - multi_accuracy: 0.3231 - val_loss: 1.0998 - val_multi_accuracy: 0.3236\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.0939 - multi_accuracy: 0.3223 - val_loss: 1.0992 - val_multi_accuracy: 0.3227\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 1.0939 - multi_accuracy: 0.3216 - val_loss: 1.0988 - val_multi_accuracy: 0.3220\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.0933 - multi_accuracy: 0.3209 - val_loss: 1.1008 - val_multi_accuracy: 0.3213\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.0930 - multi_accuracy: 0.3202 - val_loss: 1.0986 - val_multi_accuracy: 0.3206\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 1.1002 - multi_accuracy: 0.3208\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 14s 81ms/step - loss: 2.7635 - multi_accuracy: 0.3275 - val_loss: 1.1184 - val_multi_accuracy: 0.3241\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.1057 - multi_accuracy: 0.3289 - val_loss: 1.1129 - val_multi_accuracy: 0.3263\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.1017 - multi_accuracy: 0.3293 - val_loss: 1.1102 - val_multi_accuracy: 0.3277\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0997 - multi_accuracy: 0.3299 - val_loss: 1.1073 - val_multi_accuracy: 0.3287\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 5s 54ms/step - loss: 1.0988 - multi_accuracy: 0.3306 - val_loss: 1.1073 - val_multi_accuracy: 0.3296\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0981 - multi_accuracy: 0.3312 - val_loss: 1.1067 - val_multi_accuracy: 0.3304\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0976 - multi_accuracy: 0.3317 - val_loss: 1.1052 - val_multi_accuracy: 0.3311\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0969 - multi_accuracy: 0.3325 - val_loss: 1.1083 - val_multi_accuracy: 0.3319\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0967 - multi_accuracy: 0.3329 - val_loss: 1.1057 - val_multi_accuracy: 0.3324\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0966 - multi_accuracy: 0.3336 - val_loss: 1.1041 - val_multi_accuracy: 0.3333\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0961 - multi_accuracy: 0.3342 - val_loss: 1.1088 - val_multi_accuracy: 0.3338\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0956 - multi_accuracy: 0.3351 - val_loss: 1.1035 - val_multi_accuracy: 0.3348\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0953 - multi_accuracy: 0.3359 - val_loss: 1.1015 - val_multi_accuracy: 0.3358\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0948 - multi_accuracy: 0.3368 - val_loss: 1.1043 - val_multi_accuracy: 0.3366\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0943 - multi_accuracy: 0.3376 - val_loss: 1.1033 - val_multi_accuracy: 0.3374\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0939 - multi_accuracy: 0.3385 - val_loss: 1.1036 - val_multi_accuracy: 0.3384\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.0932 - multi_accuracy: 0.3394 - val_loss: 1.1015 - val_multi_accuracy: 0.3393\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.0923 - multi_accuracy: 0.3402 - val_loss: 1.1012 - val_multi_accuracy: 0.3402\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0917 - multi_accuracy: 0.3412 - val_loss: 1.0971 - val_multi_accuracy: 0.3412\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0898 - multi_accuracy: 0.3423 - val_loss: 1.1009 - val_multi_accuracy: 0.3423\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 1.0881 - multi_accuracy: 0.3436 - val_loss: 1.0969 - val_multi_accuracy: 0.3437\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.0866 - multi_accuracy: 0.3451 - val_loss: 1.0939 - val_multi_accuracy: 0.3452\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0844 - multi_accuracy: 0.3466 - val_loss: 1.0940 - val_multi_accuracy: 0.3468\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 1.0881 - multi_accuracy: 0.3480 - val_loss: 1.0963 - val_multi_accuracy: 0.3481\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0855 - multi_accuracy: 0.3495 - val_loss: 1.0895 - val_multi_accuracy: 0.3497\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.0920 - multi_accuracy: 0.3499\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 15s 84ms/step - loss: 1.9096 - multi_accuracy: 0.3297 - val_loss: 1.1083 - val_multi_accuracy: 0.3303\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.1005 - multi_accuracy: 0.3308 - val_loss: 1.1079 - val_multi_accuracy: 0.3316\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0982 - multi_accuracy: 0.3302 - val_loss: 1.1061 - val_multi_accuracy: 0.3307\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0971 - multi_accuracy: 0.3297 - val_loss: 1.1055 - val_multi_accuracy: 0.3298\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 5s 54ms/step - loss: 1.0967 - multi_accuracy: 0.3287 - val_loss: 1.1046 - val_multi_accuracy: 0.3289\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0955 - multi_accuracy: 0.3285 - val_loss: 1.1036 - val_multi_accuracy: 0.3287\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0951 - multi_accuracy: 0.3283 - val_loss: 1.1037 - val_multi_accuracy: 0.3283\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0946 - multi_accuracy: 0.3282 - val_loss: 1.1029 - val_multi_accuracy: 0.3282\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0942 - multi_accuracy: 0.3284 - val_loss: 1.1007 - val_multi_accuracy: 0.3287\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0941 - multi_accuracy: 0.3288 - val_loss: 1.1017 - val_multi_accuracy: 0.3290\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0939 - multi_accuracy: 0.3289 - val_loss: 1.1007 - val_multi_accuracy: 0.3288\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0934 - multi_accuracy: 0.3287 - val_loss: 1.0999 - val_multi_accuracy: 0.3286\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0931 - multi_accuracy: 0.3286 - val_loss: 1.1011 - val_multi_accuracy: 0.3289\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0928 - multi_accuracy: 0.3290 - val_loss: 1.1014 - val_multi_accuracy: 0.3290\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0926 - multi_accuracy: 0.3292 - val_loss: 1.0992 - val_multi_accuracy: 0.3294\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0923 - multi_accuracy: 0.3297 - val_loss: 1.1016 - val_multi_accuracy: 0.3299\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 1.0921 - multi_accuracy: 0.3302 - val_loss: 1.0957 - val_multi_accuracy: 0.3306\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 1.0916 - multi_accuracy: 0.3307 - val_loss: 1.0963 - val_multi_accuracy: 0.3310\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0910 - multi_accuracy: 0.3314 - val_loss: 1.0965 - val_multi_accuracy: 0.3317\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0907 - multi_accuracy: 0.3320 - val_loss: 1.0952 - val_multi_accuracy: 0.3324\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0906 - multi_accuracy: 0.3327 - val_loss: 1.0949 - val_multi_accuracy: 0.3330\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.0903 - multi_accuracy: 0.3333 - val_loss: 1.0978 - val_multi_accuracy: 0.3336\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0900 - multi_accuracy: 0.3338 - val_loss: 1.0961 - val_multi_accuracy: 0.3341\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0897 - multi_accuracy: 0.3344 - val_loss: 1.0980 - val_multi_accuracy: 0.3347\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0899 - multi_accuracy: 0.3350 - val_loss: 1.0959 - val_multi_accuracy: 0.3352\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.1019 - multi_accuracy: 0.3354\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 15s 89ms/step - loss: 5.1495 - multi_accuracy: 0.3467 - val_loss: 3.4949 - val_multi_accuracy: 0.3379\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 54ms/step - loss: 3.7570 - multi_accuracy: 0.3422 - val_loss: 3.4023 - val_multi_accuracy: 0.3380\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 3.7280 - multi_accuracy: 0.3402 - val_loss: 3.4084 - val_multi_accuracy: 0.3378\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 3.5271 - multi_accuracy: 0.3391 - val_loss: 3.0504 - val_multi_accuracy: 0.3373\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 3.3563 - multi_accuracy: 0.3385 - val_loss: 3.0490 - val_multi_accuracy: 0.3372\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 3.3636 - multi_accuracy: 0.3384 - val_loss: 3.0422 - val_multi_accuracy: 0.3372\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 3.3513 - multi_accuracy: 0.3384 - val_loss: 3.0391 - val_multi_accuracy: 0.3374\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 3.3482 - multi_accuracy: 0.3382 - val_loss: 3.0378 - val_multi_accuracy: 0.3373\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 3.3593 - multi_accuracy: 0.3381 - val_loss: 3.0339 - val_multi_accuracy: 0.3373\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 3.3509 - multi_accuracy: 0.3381 - val_loss: 3.0285 - val_multi_accuracy: 0.3375\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 3.3271 - multi_accuracy: 0.3382 - val_loss: 3.0294 - val_multi_accuracy: 0.3376\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 3.3362 - multi_accuracy: 0.3381 - val_loss: 3.0241 - val_multi_accuracy: 0.3376\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 3.3416 - multi_accuracy: 0.3381 - val_loss: 3.0225 - val_multi_accuracy: 0.3376\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 3.3419 - multi_accuracy: 0.3381 - val_loss: 3.0274 - val_multi_accuracy: 0.3377\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 3.3265 - multi_accuracy: 0.3382 - val_loss: 3.0307 - val_multi_accuracy: 0.3378\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 3.3367 - multi_accuracy: 0.3383 - val_loss: 3.0288 - val_multi_accuracy: 0.3379\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 3.3408 - multi_accuracy: 0.3385 - val_loss: 3.0323 - val_multi_accuracy: 0.3381\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 3.3403 - multi_accuracy: 0.3386 - val_loss: 3.0350 - val_multi_accuracy: 0.3382\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 3.1297 - multi_accuracy: 0.3379\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 31s 128ms/step - loss: 2.3969 - multi_accuracy: 0.3161 - val_loss: 1.1084 - val_multi_accuracy: 0.3228\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 7s 88ms/step - loss: 1.0994 - multi_accuracy: 0.3192 - val_loss: 1.1046 - val_multi_accuracy: 0.3220\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 8s 92ms/step - loss: 1.0982 - multi_accuracy: 0.3196 - val_loss: 1.1040 - val_multi_accuracy: 0.3218\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 7s 87ms/step - loss: 1.0978 - multi_accuracy: 0.3204 - val_loss: 1.1030 - val_multi_accuracy: 0.3221\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.0970 - multi_accuracy: 0.3195 - val_loss: 1.1008 - val_multi_accuracy: 0.3208\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0965 - multi_accuracy: 0.3188 - val_loss: 1.1027 - val_multi_accuracy: 0.3201\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 1.0959 - multi_accuracy: 0.3179 - val_loss: 1.1011 - val_multi_accuracy: 0.3188\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.0951 - multi_accuracy: 0.3167 - val_loss: 1.1002 - val_multi_accuracy: 0.3173\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0947 - multi_accuracy: 0.3153 - val_loss: 1.0999 - val_multi_accuracy: 0.3158\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 7s 85ms/step - loss: 1.0943 - multi_accuracy: 0.3139 - val_loss: 1.0990 - val_multi_accuracy: 0.3143\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 1.0941 - multi_accuracy: 0.3128 - val_loss: 1.0988 - val_multi_accuracy: 0.3131\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 7s 84ms/step - loss: 1.0936 - multi_accuracy: 0.3116 - val_loss: 1.0983 - val_multi_accuracy: 0.3120\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 1.0935 - multi_accuracy: 0.3106 - val_loss: 1.0997 - val_multi_accuracy: 0.3109\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 1.0929 - multi_accuracy: 0.3096 - val_loss: 1.1007 - val_multi_accuracy: 0.3098\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 7s 89ms/step - loss: 1.0928 - multi_accuracy: 0.3089 - val_loss: 1.0992 - val_multi_accuracy: 0.3091\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 1.0925 - multi_accuracy: 0.3081 - val_loss: 1.0977 - val_multi_accuracy: 0.3084\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 7s 84ms/step - loss: 1.0923 - multi_accuracy: 0.3075 - val_loss: 1.0978 - val_multi_accuracy: 0.3076\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0918 - multi_accuracy: 0.3068 - val_loss: 1.1107 - val_multi_accuracy: 0.3069\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 7s 88ms/step - loss: 1.0966 - multi_accuracy: 0.3066 - val_loss: 1.1030 - val_multi_accuracy: 0.3071\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 7s 81ms/step - loss: 1.0943 - multi_accuracy: 0.3067 - val_loss: 1.1013 - val_multi_accuracy: 0.3072\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0934 - multi_accuracy: 0.3069 - val_loss: 1.0971 - val_multi_accuracy: 0.3072\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 1.0929 - multi_accuracy: 0.3068 - val_loss: 1.0985 - val_multi_accuracy: 0.3070\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 7s 85ms/step - loss: 1.0927 - multi_accuracy: 0.3066 - val_loss: 1.0986 - val_multi_accuracy: 0.3068\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 7s 87ms/step - loss: 1.0923 - multi_accuracy: 0.3064 - val_loss: 1.0986 - val_multi_accuracy: 0.3066\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 1.0923 - multi_accuracy: 0.3062 - val_loss: 1.0965 - val_multi_accuracy: 0.3064\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.0989 - multi_accuracy: 0.3066\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 31s 126ms/step - loss: 4.6536 - multi_accuracy: 0.3190 - val_loss: 3.7648 - val_multi_accuracy: 0.3227\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 7s 90ms/step - loss: 4.2204 - multi_accuracy: 0.3184 - val_loss: 3.7767 - val_multi_accuracy: 0.3174\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 4.2840 - multi_accuracy: 0.3172 - val_loss: 3.7858 - val_multi_accuracy: 0.3160\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 4.2761 - multi_accuracy: 0.3162 - val_loss: 3.8136 - val_multi_accuracy: 0.3155\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 7s 87ms/step - loss: 4.2772 - multi_accuracy: 0.3156 - val_loss: 3.8469 - val_multi_accuracy: 0.3151\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 7s 85ms/step - loss: 4.3270 - multi_accuracy: 0.3153 - val_loss: 3.8696 - val_multi_accuracy: 0.3149\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.8239 - multi_accuracy: 0.3160\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 32s 129ms/step - loss: 5.1118 - multi_accuracy: 0.3254 - val_loss: 4.7178 - val_multi_accuracy: 0.3278\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 8s 93ms/step - loss: 4.3904 - multi_accuracy: 0.3268 - val_loss: 4.7062 - val_multi_accuracy: 0.3272\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 7s 89ms/step - loss: 4.3891 - multi_accuracy: 0.3262 - val_loss: 4.6967 - val_multi_accuracy: 0.3267\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 7s 89ms/step - loss: 4.3952 - multi_accuracy: 0.3262 - val_loss: 4.6916 - val_multi_accuracy: 0.3267\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 7s 90ms/step - loss: 4.3537 - multi_accuracy: 0.3262 - val_loss: 4.6875 - val_multi_accuracy: 0.3266\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 4.3630 - multi_accuracy: 0.3263 - val_loss: 4.6862 - val_multi_accuracy: 0.3266\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 4.3641 - multi_accuracy: 0.3265 - val_loss: 4.6841 - val_multi_accuracy: 0.3268\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 7s 86ms/step - loss: 4.3758 - multi_accuracy: 0.3267 - val_loss: 4.6810 - val_multi_accuracy: 0.3270\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 7s 83ms/step - loss: 4.3627 - multi_accuracy: 0.3273 - val_loss: 4.6822 - val_multi_accuracy: 0.3275\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 7s 82ms/step - loss: 4.3886 - multi_accuracy: 0.3276 - val_loss: 4.6894 - val_multi_accuracy: 0.3278\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 7s 85ms/step - loss: 4.3987 - multi_accuracy: 0.3281 - val_loss: 4.6894 - val_multi_accuracy: 0.3282\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 7s 87ms/step - loss: 4.4001 - multi_accuracy: 0.3284 - val_loss: 4.6898 - val_multi_accuracy: 0.3285\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 7s 87ms/step - loss: 4.4165 - multi_accuracy: 0.3287 - val_loss: 4.6896 - val_multi_accuracy: 0.3288\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 4.8409 - multi_accuracy: 0.3289\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 21s 114ms/step - loss: 1.6726 - multi_accuracy: 0.3385 - val_loss: 1.1128 - val_multi_accuracy: 0.3335\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.1055 - multi_accuracy: 0.3358 - val_loss: 1.1113 - val_multi_accuracy: 0.3320\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 1.1019 - multi_accuracy: 0.3349 - val_loss: 1.1080 - val_multi_accuracy: 0.3327\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.1000 - multi_accuracy: 0.3349 - val_loss: 1.1103 - val_multi_accuracy: 0.3332\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 1.0994 - multi_accuracy: 0.3351 - val_loss: 1.1096 - val_multi_accuracy: 0.3338\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 1.0986 - multi_accuracy: 0.3359 - val_loss: 1.1078 - val_multi_accuracy: 0.3347\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 1.0983 - multi_accuracy: 0.3360 - val_loss: 1.1036 - val_multi_accuracy: 0.3351\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 5s 64ms/step - loss: 1.0982 - multi_accuracy: 0.3361 - val_loss: 1.1045 - val_multi_accuracy: 0.3352\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 5s 60ms/step - loss: 1.0980 - multi_accuracy: 0.3362 - val_loss: 1.1055 - val_multi_accuracy: 0.3354\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 1.0976 - multi_accuracy: 0.3365 - val_loss: 1.1058 - val_multi_accuracy: 0.3358\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.0975 - multi_accuracy: 0.3367 - val_loss: 1.1065 - val_multi_accuracy: 0.3361\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.0973 - multi_accuracy: 0.3372 - val_loss: 1.1042 - val_multi_accuracy: 0.3365\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 1.1044 - multi_accuracy: 0.3359\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 20s 103ms/step - loss: 4.6899 - multi_accuracy: 0.3355 - val_loss: 2.3331 - val_multi_accuracy: 0.3327\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 2.0847 - multi_accuracy: 0.3372 - val_loss: 1.9868 - val_multi_accuracy: 0.3352\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 2.0537 - multi_accuracy: 0.3384 - val_loss: 2.0043 - val_multi_accuracy: 0.3371\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 2.0510 - multi_accuracy: 0.3396 - val_loss: 2.0074 - val_multi_accuracy: 0.3387\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 2.0851 - multi_accuracy: 0.3403 - val_loss: 2.0151 - val_multi_accuracy: 0.3395\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 2.0924 - multi_accuracy: 0.3405 - val_loss: 2.0232 - val_multi_accuracy: 0.3399\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 5s 59ms/step - loss: 2.1013 - multi_accuracy: 0.3407 - val_loss: 2.0222 - val_multi_accuracy: 0.3401\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 1.8901 - multi_accuracy: 0.3396\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 20s 94ms/step - loss: 3.3871 - multi_accuracy: 0.3282 - val_loss: 1.8275 - val_multi_accuracy: 0.3283\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.5187 - multi_accuracy: 0.3253 - val_loss: 1.4481 - val_multi_accuracy: 0.3266\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 5s 65ms/step - loss: 1.5452 - multi_accuracy: 0.3246 - val_loss: 1.5133 - val_multi_accuracy: 0.3254\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.5518 - multi_accuracy: 0.3232 - val_loss: 1.5168 - val_multi_accuracy: 0.3241\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 5s 63ms/step - loss: 1.5630 - multi_accuracy: 0.3224 - val_loss: 1.5427 - val_multi_accuracy: 0.3233\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 5s 60ms/step - loss: 1.5591 - multi_accuracy: 0.3216 - val_loss: 1.5412 - val_multi_accuracy: 0.3226\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 5s 62ms/step - loss: 1.5869 - multi_accuracy: 0.3211 - val_loss: 1.6100 - val_multi_accuracy: 0.3220\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 1.4322 - multi_accuracy: 0.3229\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 15s 76ms/step - loss: 2.0338 - multi_accuracy: 0.3278 - val_loss: 1.1125 - val_multi_accuracy: 0.3269\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 1.1017 - multi_accuracy: 0.3365 - val_loss: 1.1077 - val_multi_accuracy: 0.3336\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0987 - multi_accuracy: 0.3391 - val_loss: 1.1063 - val_multi_accuracy: 0.3370\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0976 - multi_accuracy: 0.3402 - val_loss: 1.1064 - val_multi_accuracy: 0.3390\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0970 - multi_accuracy: 0.3416 - val_loss: 1.1047 - val_multi_accuracy: 0.3404\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0959 - multi_accuracy: 0.3427 - val_loss: 1.1049 - val_multi_accuracy: 0.3419\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0954 - multi_accuracy: 0.3437 - val_loss: 1.1099 - val_multi_accuracy: 0.3429\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0948 - multi_accuracy: 0.3445 - val_loss: 1.1004 - val_multi_accuracy: 0.3443\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0941 - multi_accuracy: 0.3459 - val_loss: 1.1016 - val_multi_accuracy: 0.3455\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.0933 - multi_accuracy: 0.3471 - val_loss: 1.1027 - val_multi_accuracy: 0.3467\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0927 - multi_accuracy: 0.3480 - val_loss: 1.1074 - val_multi_accuracy: 0.3476\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0924 - multi_accuracy: 0.3489 - val_loss: 1.1048 - val_multi_accuracy: 0.3488\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0918 - multi_accuracy: 0.3500 - val_loss: 1.0981 - val_multi_accuracy: 0.3502\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0910 - multi_accuracy: 0.3513 - val_loss: 1.1020 - val_multi_accuracy: 0.3514\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0905 - multi_accuracy: 0.3523 - val_loss: 1.0964 - val_multi_accuracy: 0.3527\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0901 - multi_accuracy: 0.3538 - val_loss: 1.0958 - val_multi_accuracy: 0.3541\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0893 - multi_accuracy: 0.3552 - val_loss: 1.0960 - val_multi_accuracy: 0.3555\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0882 - multi_accuracy: 0.3566 - val_loss: 1.0934 - val_multi_accuracy: 0.3569\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0866 - multi_accuracy: 0.3582 - val_loss: 1.0924 - val_multi_accuracy: 0.3586\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 5s 54ms/step - loss: 1.0842 - multi_accuracy: 0.3601 - val_loss: 1.1013 - val_multi_accuracy: 0.3602\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0806 - multi_accuracy: 0.3620 - val_loss: 1.0877 - val_multi_accuracy: 0.3624\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.0731 - multi_accuracy: 0.3644 - val_loss: 1.0715 - val_multi_accuracy: 0.3650\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 1.0647 - multi_accuracy: 0.3673 - val_loss: 1.0666 - val_multi_accuracy: 0.3678\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 1.0517 - multi_accuracy: 0.3704 - val_loss: 1.0623 - val_multi_accuracy: 0.3710\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0454 - multi_accuracy: 0.3738 - val_loss: 1.0591 - val_multi_accuracy: 0.3744\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.0656 - multi_accuracy: 0.3750\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 16s 86ms/step - loss: 4.9508 - multi_accuracy: 0.3333 - val_loss: 3.8892 - val_multi_accuracy: 0.3336\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 2.6605 - multi_accuracy: 0.3336 - val_loss: 1.2846 - val_multi_accuracy: 0.3349\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.1910 - multi_accuracy: 0.3385 - val_loss: 1.1208 - val_multi_accuracy: 0.3389\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.1273 - multi_accuracy: 0.3408 - val_loss: 1.1153 - val_multi_accuracy: 0.3408\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.1171 - multi_accuracy: 0.3422 - val_loss: 1.1137 - val_multi_accuracy: 0.3419\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.1110 - multi_accuracy: 0.3430 - val_loss: 1.1085 - val_multi_accuracy: 0.3429\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.1064 - multi_accuracy: 0.3441 - val_loss: 1.1089 - val_multi_accuracy: 0.3437\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.1043 - multi_accuracy: 0.3448 - val_loss: 1.1083 - val_multi_accuracy: 0.3445\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.1029 - multi_accuracy: 0.3453 - val_loss: 1.1076 - val_multi_accuracy: 0.3450\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.1014 - multi_accuracy: 0.3457 - val_loss: 1.1071 - val_multi_accuracy: 0.3454\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.1003 - multi_accuracy: 0.3461 - val_loss: 1.1063 - val_multi_accuracy: 0.3458\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0997 - multi_accuracy: 0.3464 - val_loss: 1.1058 - val_multi_accuracy: 0.3461\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0987 - multi_accuracy: 0.3466 - val_loss: 1.1053 - val_multi_accuracy: 0.3463\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0982 - multi_accuracy: 0.3469 - val_loss: 1.1043 - val_multi_accuracy: 0.3466\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 1.0975 - multi_accuracy: 0.3473 - val_loss: 1.1038 - val_multi_accuracy: 0.3471\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0968 - multi_accuracy: 0.3477 - val_loss: 1.1033 - val_multi_accuracy: 0.3475\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0964 - multi_accuracy: 0.3479 - val_loss: 1.1028 - val_multi_accuracy: 0.3478\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0963 - multi_accuracy: 0.3482 - val_loss: 1.1028 - val_multi_accuracy: 0.3480\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0958 - multi_accuracy: 0.3484 - val_loss: 1.1026 - val_multi_accuracy: 0.3483\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0957 - multi_accuracy: 0.3485 - val_loss: 1.1024 - val_multi_accuracy: 0.3484\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0954 - multi_accuracy: 0.3488 - val_loss: 1.1019 - val_multi_accuracy: 0.3487\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0950 - multi_accuracy: 0.3491 - val_loss: 1.1015 - val_multi_accuracy: 0.3490\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0948 - multi_accuracy: 0.3493 - val_loss: 1.1018 - val_multi_accuracy: 0.3492\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.0945 - multi_accuracy: 0.3496 - val_loss: 1.1017 - val_multi_accuracy: 0.3495\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0943 - multi_accuracy: 0.3498 - val_loss: 1.1016 - val_multi_accuracy: 0.3497\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 1.1038 - multi_accuracy: 0.3496\n",
      "Epoch 1/25\n",
      "83/83 [==============================] - 15s 89ms/step - loss: 1.5316 - multi_accuracy: 0.3302 - val_loss: 1.1199 - val_multi_accuracy: 0.3268\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.1081 - multi_accuracy: 0.3310 - val_loss: 1.1070 - val_multi_accuracy: 0.3288\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 1.1005 - multi_accuracy: 0.3331 - val_loss: 1.1063 - val_multi_accuracy: 0.3315\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0984 - multi_accuracy: 0.3350 - val_loss: 1.1056 - val_multi_accuracy: 0.3337\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0976 - multi_accuracy: 0.3360 - val_loss: 1.1046 - val_multi_accuracy: 0.3350\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0974 - multi_accuracy: 0.3369 - val_loss: 1.1043 - val_multi_accuracy: 0.3360\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 5s 56ms/step - loss: 1.0967 - multi_accuracy: 0.3376 - val_loss: 1.1039 - val_multi_accuracy: 0.3368\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0965 - multi_accuracy: 0.3384 - val_loss: 1.1037 - val_multi_accuracy: 0.3378\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0960 - multi_accuracy: 0.3388 - val_loss: 1.1029 - val_multi_accuracy: 0.3382\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0951 - multi_accuracy: 0.3396 - val_loss: 1.1034 - val_multi_accuracy: 0.3390\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0947 - multi_accuracy: 0.3402 - val_loss: 1.1028 - val_multi_accuracy: 0.3397\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0942 - multi_accuracy: 0.3409 - val_loss: 1.1022 - val_multi_accuracy: 0.3406\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0936 - multi_accuracy: 0.3418 - val_loss: 1.1030 - val_multi_accuracy: 0.3415\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 5s 54ms/step - loss: 1.0931 - multi_accuracy: 0.3426 - val_loss: 1.1020 - val_multi_accuracy: 0.3424\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0930 - multi_accuracy: 0.3434 - val_loss: 1.1024 - val_multi_accuracy: 0.3432\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0926 - multi_accuracy: 0.3440 - val_loss: 1.1014 - val_multi_accuracy: 0.3438\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.0924 - multi_accuracy: 0.3447 - val_loss: 1.1017 - val_multi_accuracy: 0.3445\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0919 - multi_accuracy: 0.3454 - val_loss: 1.1013 - val_multi_accuracy: 0.3452\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0916 - multi_accuracy: 0.3460 - val_loss: 1.0984 - val_multi_accuracy: 0.3460\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0912 - multi_accuracy: 0.3469 - val_loss: 1.0988 - val_multi_accuracy: 0.3469\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 1.0904 - multi_accuracy: 0.3478 - val_loss: 1.0998 - val_multi_accuracy: 0.3477\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 1.0899 - multi_accuracy: 0.3486 - val_loss: 1.0992 - val_multi_accuracy: 0.3486\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.0892 - multi_accuracy: 0.3494 - val_loss: 1.0960 - val_multi_accuracy: 0.3496\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 1.0888 - multi_accuracy: 0.3505 - val_loss: 1.0980 - val_multi_accuracy: 0.3505\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 5s 54ms/step - loss: 1.0884 - multi_accuracy: 0.3514 - val_loss: 1.0977 - val_multi_accuracy: 0.3515\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.1026 - multi_accuracy: 0.3516\n",
      "Epoch 1/25\n",
      "12/83 [===>..........................] - ETA: 11s - loss: 5.7564 - multi_accuracy: 0.3550"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m model \u001b[39m=\u001b[39m create_transformer_model(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m         m\u001b[39m=\u001b[39mmemory_length\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m         n\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(SELECTED_TICKERS),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m         class_first\u001b[39m=\u001b[39mCLASS_FIRST\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m             loss\u001b[39m=\u001b[39mMultiSoftmaxLoss(),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m             metrics\u001b[39m=\u001b[39m[MultiAccuracy()])\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x \u001b[39m=\u001b[39;49m (x_train,x_ts_train,x_train,x_ts_train),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m         y \u001b[39m=\u001b[39;49m y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m         validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m             keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m                 patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m                 restore_best_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m             )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m         ])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39m./models/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mserial\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.keras\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m model_dict\u001b[39m.\u001b[39mupdate(model\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m             x \u001b[39m=\u001b[39m (x_test,x_ts_test,x_test,x_ts_test),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m             y \u001b[39m=\u001b[39m y_test,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m         )\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bdebian/home/sergiovaneg/stonk-prediction/stock_predictions_transformer.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=101'>102</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/stonks/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./models/\"):\n",
    "    os.makedirs(\"./models/\")\n",
    "\n",
    "CLASS_FIRST = True\n",
    "\n",
    "if MODEL_SERIAL is None:\n",
    "    counter = 0\n",
    "    RESUME = 612\n",
    "\n",
    "    for memory_length in [50,20,10]:\n",
    "        if PREDICT_PRICES:\n",
    "            OUTPUT_SCALE = (0,1)\n",
    "            x, y = create_batch_xy(\n",
    "                        memory_length,\n",
    "                        transformed_np_arr,\n",
    "                        overlap=True,\n",
    "                        y_updown=False,\n",
    "                        diff_data=True,\n",
    "                        output_scale=OUTPUT_SCALE)\n",
    "        else:\n",
    "            x, x_ts, y = create_transformer_onehot_xy(\n",
    "                                memory_length,\n",
    "                                transformed_np_arr,\n",
    "                                DATAFRAME.to_numpy(),\n",
    "                                DATAFRAME.index.to_numpy(),\n",
    "                                0.002)\n",
    "\n",
    "        split_idx = int(x.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "        x_train = x[:split_idx,:,:]\n",
    "        x_ts_train = x_ts[:split_idx,:,:]\n",
    "        y_train = y[:split_idx,:,:]\n",
    "\n",
    "        x_test = x[split_idx:,:,:]\n",
    "        x_ts_test = x_ts[split_idx:,:,:]\n",
    "        y_test = y[split_idx:,:,:]\n",
    "\n",
    "        if CLASS_FIRST:\n",
    "            y_train = tf.transpose(y_train, (0,2,1))\n",
    "            y_test = tf.transpose(y_test, (0,2,1))\n",
    "\n",
    "        for head_size in [32,16,64]:\n",
    "            for num_heads in [32,16,8]:\n",
    "                for ff_dim in [64,32,16]:\n",
    "                    for num_transformer_blocks in [4,2,1]:\n",
    "                        for mlp_units in [64,32,16]:\n",
    "                            if counter < RESUME:\n",
    "                                counter = counter + 1\n",
    "                                continue\n",
    "                            \n",
    "                            serial = \"transformer_model_\" \\\n",
    "                                + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                            model_dict = {\n",
    "                                \"serial\": serial,\n",
    "                                \"memory_length\": memory_length,\n",
    "                                \"head_size\": head_size,\n",
    "                                \"num_heads\": num_heads,\n",
    "                                \"ff_dim\": ff_dim,\n",
    "                                \"num_transformer_blocks\": num_transformer_blocks,\n",
    "                                \"mlp_units\": mlp_units\n",
    "                            }\n",
    "\n",
    "                            model = create_transformer_model(\n",
    "                                    m=memory_length+1,\n",
    "                                    n=len(SELECTED_TICKERS),\n",
    "                                    output_dim=3,\n",
    "                                    head_size=head_size,\n",
    "                                    num_heads=num_heads,\n",
    "                                    ff_dim=ff_dim,\n",
    "                                    num_transformer_blocks=num_transformer_blocks,\n",
    "                                    mlp_units=(mlp_units,),\n",
    "                                    class_first=CLASS_FIRST\n",
    "                                )\n",
    "                            \n",
    "\n",
    "                            model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                                        loss=MultiSoftmaxLoss(),\n",
    "                                        metrics=[MultiAccuracy()])\n",
    "\n",
    "                            model.fit(x = (x_train,x_ts_train,x_train,x_ts_train),\n",
    "                                    y = y_train,\n",
    "                                    batch_size=32,\n",
    "                                    epochs=25,\n",
    "                                    validation_split=0.25,\n",
    "                                    callbacks=[\n",
    "                                        keras.callbacks.EarlyStopping(\n",
    "                                            patience=5,\n",
    "                                            restore_best_weights=True\n",
    "                                        )\n",
    "                                    ])\n",
    "                            \n",
    "                            model.save(\"./models/\"+serial+\".keras\")\n",
    "\n",
    "                            model_dict.update(model.evaluate(\n",
    "                                        x = (x_test,x_ts_test,x_test,x_ts_test),\n",
    "                                        y = y_test,\n",
    "                                        batch_size=32,\n",
    "                                        workers=4,\n",
    "                                        use_multiprocessing=True,\n",
    "                                        return_dict=True\n",
    "                                    )\n",
    "                                )\n",
    "                            \n",
    "                            if os.path.exists(\"./transformer_results.json\"):\n",
    "                                with open(\"./transformer_results.json\", \"r\",\n",
    "                                        encoding=ENCODING) as json_file:\n",
    "                                    model_list = json.load(json_file)\n",
    "                                model_list.append(model_dict)\n",
    "                            else:\n",
    "                                model_list = [model_dict]\n",
    "\n",
    "                            with open(\"./transformer_results.json\", \"w\",\n",
    "                                    encoding=ENCODING) as json_file:\n",
    "                                json.dump(model_list, json_file)\n",
    "\n",
    "                            keras.backend.clear_session()\n",
    "\n",
    "    if os.path.exists(\"./transformer_results.json\"):\n",
    "        with open(\"./transformer_results.json\", \"r\",\n",
    "                  encoding=ENCODING) as json_file:\n",
    "            model_list = json.load(json_file)\n",
    "    else:\n",
    "        model_list = [{}]\n",
    "    \n",
    "    model_df = pd.DataFrame.from_dict(model_list)\n",
    "    model_df.to_excel(\"./transformer_results.xlsx\")\n",
    "else:\n",
    "    with open(\"./transformer_results.json\", \"r\",\n",
    "              encoding=ENCODING) as json_file:\n",
    "        model_list = json.load(json_file)\n",
    "    model_dict = next(item for item in model_list\n",
    "                      if item[\"serial\"] == MODEL_SERIAL)\n",
    "\n",
    "    memory_length = int(model_dict[\"memory_length\"])\n",
    "\n",
    "    if PREDICT_PRICES:\n",
    "        OUTPUT_SCALE = (0,1)\n",
    "        x, y = create_batch_xy(\n",
    "                    memory_length,\n",
    "                    transformed_np_arr,\n",
    "                    overlap=True,\n",
    "                    y_updown=False,\n",
    "                    diff_data=True,\n",
    "                    output_scale=OUTPUT_SCALE)\n",
    "    else:\n",
    "        x, x_ts, y = create_transformer_onehot_xy(\n",
    "                            memory_length,\n",
    "                            transformed_np_arr,\n",
    "                            DATAFRAME.to_numpy(),\n",
    "                            DATAFRAME.index.to_numpy(),\n",
    "                            0.002)\n",
    "\n",
    "    split_idx = int(x.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "    x_train = x[:split_idx,:,:]\n",
    "    x_ts_train = x_ts[:split_idx,:,:]\n",
    "    y_train = y[:split_idx,:,:]\n",
    "\n",
    "    x_test = x[split_idx:,:,:]\n",
    "    x_ts_test = x_ts[split_idx:,:,:]\n",
    "    y_test = y[split_idx:,:,:]\n",
    "\n",
    "    if CLASS_FIRST:\n",
    "        y_train = tf.transpose(y_train, (0,2,1))\n",
    "        y_test = tf.transpose(y_test, (0,2,1))\n",
    "\n",
    "    model = keras.models.load_model(\"./models/\" + MODEL_SERIAL + \".keras\")\n",
    "\n",
    "plot_model(\n",
    "        model,\n",
    "        to_file=\"./figures/transformer_model_plot.png\",\n",
    "        show_shapes=True,\n",
    "        show_layer_names = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model([x_test, x_ts_test, x_test, x_ts_test], training=False)\n",
    "print(\"Y_pred: \\n\", y_pred)\n",
    "print(\"Y_test: \\n\", y_test)\n",
    "\n",
    "for stock_idx in range(y_pred.shape[2] if CLASS_FIRST else y_pred.shape[1]):\n",
    "    if CLASS_FIRST:\n",
    "        direction_preds = y_pred[:,:,stock_idx]\n",
    "        direction_true = y_test[:,:,stock_idx]\n",
    "    else:\n",
    "        direction_preds = y_pred[:,stock_idx,:]\n",
    "        direction_true = y_test[:,stock_idx,:]\n",
    "\n",
    "    accuracy = \\\n",
    "        np.sum(direction_preds == direction_true) / direction_preds.shape[0]\n",
    "    print(f\"\"\"\n",
    "            Up/Down/Flat accuracy for stock {IND_CONVERSION[stock_idx]}:\n",
    "            {accuracy}\n",
    "            \"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate profit by optimal strategy (theoretical) vs using model to predict\n",
    "test_sz = int(DATAFRAME.shape[0] * TEST_FRAC)\n",
    "df_test = DATAFRAME.iloc[-test_sz:,:].copy()\n",
    "if HAS_TIMEDELTA:\n",
    "    df_test.drop(\"Time Delta\", axis=1, inplace=True)\n",
    "np_arr_test = df_test.to_numpy()\n",
    "print(\"np_arr_test data shape: \", np_arr_test.shape)\n",
    "\n",
    "optimal_trading_mask = calculate_optimal_invest_strategy(np_arr_test)\n",
    "print(f\"Optimal mask 3rd stock: \\n {optimal_trading_mask[:,2]}\")\n",
    "profit_optimal = calculate_profit_on_invest_strategy(np_arr_test,\n",
    "                                                     optimal_trading_mask)\n",
    "print(f\"Optimal strategy matrix shape: {optimal_trading_mask.shape}\")\n",
    "print(f\"Profit by optimal strategy on test data: {profit_optimal}\")\n",
    "\n",
    "# To calculate the mask for the model, we need to give the data in the same format as it was trained in\n",
    "transformed_df_test = transformed_df.iloc[-test_sz:,:]\n",
    "transformed_np_arr_test = transformed_df_test.to_numpy()\n",
    "print(\"transformed_np_arr_test data shape: \", transformed_np_arr_test.shape)\n",
    "print(transformed_np_arr_test[0:2,:])\n",
    "prediction_trading_mask = \\\n",
    "    strategy_mask_from_direction_model(transformed_np_arr_test,\n",
    "                                       memory_length, model,\n",
    "                                       True, df.to_numpy()[-test_sz:,:],\n",
    "                                       df.index.to_numpy()[-test_sz:]\n",
    "                                       )\n",
    "\n",
    "if HAS_TIMEDELTA:\n",
    "    prediction_trading_mask = prediction_trading_mask[:,1:]\n",
    "\n",
    "print(f\"Prediction mask 3rd stock: \\n {prediction_trading_mask[:,2]}\")\n",
    "if HAS_TIMEDELTA:\n",
    "    profit_pred_model = \\\n",
    "        calculate_profit_on_invest_strategy(np_arr_test[:,1:],\n",
    "                                            prediction_trading_mask)\n",
    "else:\n",
    "    profit_pred_model = \\\n",
    "        calculate_profit_on_invest_strategy(np_arr_test,\n",
    "                                            prediction_trading_mask)\n",
    "\n",
    "print(f\"Prediction strategy matrix shape: {prediction_trading_mask.shape}\")\n",
    "print(\n",
    "    f\"Profit by predicting the next hour using the model: {profit_pred_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_indices = np.random.choice(np.arange(len(IND_CONVERSION)), 4,\n",
    "                                 replace=False)\n",
    "part_mask = prediction_trading_mask[:,stock_indices]\n",
    "\n",
    "if HAS_TIMEDELTA:\n",
    "    part_price = np_arr_test[:,1:][:,stock_indices]\n",
    "else:\n",
    "    part_price = np_arr_test[:,stock_indices]\n",
    "\n",
    "ind_conversion = {si : IND_CONVERSION[i] for si, i in enumerate(stock_indices)}\n",
    "plot_mask_and_data(part_mask, part_price, ind_conversion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stonks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
