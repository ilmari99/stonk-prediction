{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 10:16:24.297332: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-08 10:16:24.320158: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-08 10:16:24.320178: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-08 10:16:24.320182: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-08 10:16:24.324226: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import locale\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from stock_modules.stock_transform import (create_batch_xy,\n",
    "                                           create_transformer_onehot_xy)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from stock_modules.stock_ml import (create_transformer_model,\n",
    "                                    MultiSoftmaxLoss, MultiAccuracy)\n",
    "\n",
    "from invest_strategies import (calculate_optimal_invest_strategy,\n",
    "                               calculate_profit_on_invest_strategy,\n",
    "                               strategy_mask_from_direction_model)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "from stock_modules.stock_plot import plot_mask_and_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = locale.getpreferredencoding()\n",
    "DF_PATH = \"HEL_12-10-21to08-11-23.csv\"\n",
    "MODEL_SERIAL = None\n",
    "SELECTED_TICKERS_PATH = \"./TICKERS_TO_FOLLOW.json\"\n",
    "\n",
    "TEST_FRAC = 0.2\n",
    "PREDICT_PRICES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected tickers: \n",
      " ['ALBBV.HE', 'CGCBV.HE', 'EQV1V.HE', 'KNEBV.HE', 'ORNBV.HE', 'OLVAS.HE', 'DETEC.HE', 'PON1V.HE', 'ORNAV.HE', 'VALMT.HE', 'NESTE.HE', 'HUH1V.HE', 'REG1V.HE', 'VAIAS.HE']\n",
      "Dataframe columns: \n",
      " Index(['REG1V.HE', 'NESTE.HE', 'ORNBV.HE', 'KNEBV.HE', 'OLVAS.HE', 'HUH1V.HE',\n",
      "       'DETEC.HE', 'ORNAV.HE', 'CGCBV.HE', 'VAIAS.HE', 'ALBBV.HE', 'VALMT.HE',\n",
      "       'EQV1V.HE', 'PON1V.HE'],\n",
      "      dtype='object')\n",
      "Dataframe shape:  (4389, 14)\n",
      "Dataframe head: \n",
      "                       REG1V.HE   NESTE.HE   ORNBV.HE   KNEBV.HE   OLVAS.HE  \\\n",
      "date                                                                         \n",
      "2021-10-12 07:00:00  55.950001  41.820000  35.689999  60.220001  53.099998   \n",
      "2021-10-12 08:00:00  55.799999  41.720001  35.630001  60.419998  53.299999   \n",
      "\n",
      "                      HUH1V.HE  DETEC.HE   ORNAV.HE   CGCBV.HE   VAIAS.HE  \\\n",
      "date                                                                        \n",
      "2021-10-12 07:00:00  38.529999      23.0  38.049999  43.139999  46.150002   \n",
      "2021-10-12 08:00:00  38.560001      23.0  38.049999  43.500000  45.950001   \n",
      "\n",
      "                      ALBBV.HE   VALMT.HE   EQV1V.HE   PON1V.HE  \n",
      "date                                                             \n",
      "2021-10-12 07:00:00  28.700001  36.459999  24.850000  39.150002  \n",
      "2021-10-12 08:00:00  28.799999  36.599998  24.950001  39.200001  \n",
      "Index conversion: \n",
      " {0: 'REG1V.HE', 1: 'NESTE.HE', 2: 'ORNBV.HE', 3: 'KNEBV.HE', 4: 'OLVAS.HE', 5: 'HUH1V.HE', 6: 'DETEC.HE', 7: 'ORNAV.HE', 8: 'CGCBV.HE', 9: 'VAIAS.HE', 10: 'ALBBV.HE', 11: 'VALMT.HE', 12: 'EQV1V.HE', 13: 'PON1V.HE'}\n"
     ]
    }
   ],
   "source": [
    "SELECTED_TICKERS = json.load(open(SELECTED_TICKERS_PATH,\n",
    "                                  \"r\", encoding=ENCODING))\n",
    "DATAFRAME = pd.read_csv(DF_PATH, encoding=ENCODING)\n",
    "\n",
    "DATAFRAME.set_index(\"date\", inplace=True)\n",
    "HAS_TIMEDELTA = \"Time Delta\" in DATAFRAME.columns\n",
    "\n",
    "# ind transformation tells the label of each index in the np_arr_test\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(DATAFRAME.columns) if ticker in SELECTED_TICKERS}\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(IND_CONVERSION.values())}\n",
    "\n",
    "print(\"Selected tickers: \\n\", SELECTED_TICKERS)\n",
    "print(\"Dataframe columns: \\n\", DATAFRAME.columns)\n",
    "print(\"Dataframe shape: \", DATAFRAME.shape)\n",
    "print(\"Dataframe head: \\n\", DATAFRAME.head(2))\n",
    "print(f\"Index conversion: \\n {IND_CONVERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed df: \n",
      "                      REG1V.HE  NESTE.HE  ORNBV.HE  KNEBV.HE  OLVAS.HE  \\\n",
      "date                                                                    \n",
      "2021-10-12 07:00:00 -0.150002 -0.099998 -0.059998  0.199997  0.200001   \n",
      "2021-10-12 08:00:00 -0.150002 -0.099998 -0.059998  0.199997  0.200001   \n",
      "\n",
      "                     HUH1V.HE  DETEC.HE  ORNAV.HE  CGCBV.HE  VAIAS.HE  \\\n",
      "date                                                                    \n",
      "2021-10-12 07:00:00  0.030003       0.0       0.0  0.360001 -0.200001   \n",
      "2021-10-12 08:00:00  0.030003       0.0       0.0  0.360001 -0.200001   \n",
      "\n",
      "                     ALBBV.HE  VALMT.HE  EQV1V.HE  PON1V.HE  \n",
      "date                                                         \n",
      "2021-10-12 07:00:00  0.099998  0.139999       0.1  0.049999  \n",
      "2021-10-12 08:00:00  0.099998  0.139999       0.1  0.049999  \n",
      "Transformed df shape:  (4389, 14)\n"
     ]
    }
   ],
   "source": [
    "test_begin_idx = int(DATAFRAME.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "if PREDICT_PRICES:\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaler.fit(DATAFRAME.iloc[:test_begin_idx, :])\n",
    "    transformed_df = pd.DataFrame(scaler.transform(DATAFRAME), columns=DATAFRAME.columns, index=DATAFRAME.index)\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            return pd.DataFrame(scaler.inverse_transform(df), columns=df.columns, index=df.index)\n",
    "        elif isinstance(df, np.ndarray):\n",
    "            return scaler.inverse_transform(df)\n",
    "\n",
    "# If we are predicting the up/down, we create a dataframe where we subtract the previous value from the current value\n",
    "else:\n",
    "    # Do not diff the Time Delta column\n",
    "    df = DATAFRAME.copy()\n",
    "    if HAS_TIMEDELTA:\n",
    "        td_col = df[\"Time Delta\"]\n",
    "        df.drop(\"Time Delta\", axis=1, inplace=True)\n",
    "    transformed_df = df.diff()\n",
    "    # The first row is NaN, so lets copy the second row there\n",
    "    transformed_df.iloc[0, :] = transformed_df.iloc[1, :]\n",
    "    # Add back the Time Delta column\n",
    "    if HAS_TIMEDELTA:\n",
    "        transformed_df[\"Time Delta\"] = td_col\n",
    "        # Make Time Delta the first column\n",
    "        cols = transformed_df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        transformed_df = transformed_df[cols]\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        return df\n",
    "\n",
    "print(\"Transformed df: \\n\", transformed_df.head(2))\n",
    "print(\"Transformed df shape: \", transformed_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 10:16:26.965838: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-12-08 10:16:26.965861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: Jorogumo\n",
      "2023-12-08 10:16:26.965863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: Jorogumo\n",
      "2023-12-08 10:16:26.966017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.129.3\n",
      "2023-12-08 10:16:26.966027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.129.3\n",
      "2023-12-08 10:16:26.966029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.129.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "82/82 [==============================] - 25s 188ms/step - loss: 1.1868 - multi_accuracy: 0.4201 - val_loss: 0.7797 - val_multi_accuracy: 0.4226\n",
      "Epoch 2/25\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 1.0046 - multi_accuracy: 0.4186 - val_loss: 0.7799 - val_multi_accuracy: 0.4200\n",
      "Epoch 3/25\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 1.0033 - multi_accuracy: 0.4181 - val_loss: 0.7859 - val_multi_accuracy: 0.4191\n",
      "Epoch 4/25\n",
      "35/82 [===========>..................] - ETA: 9s - loss: 0.9946 - multi_accuracy: 0.4188"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./models/\"):\n",
    "    os.makedirs(\"./models/\")\n",
    "\n",
    "METRICS = [MultiAccuracy()]\n",
    "CALLBACKS = [keras.callbacks.EarlyStopping(patience=5,\n",
    "                                           restore_best_weights=True)]\n",
    "CLASS_FIRST = True\n",
    "\n",
    "if MODEL_SERIAL is None:\n",
    "    counter = 0\n",
    "    RESUME = 0\n",
    "\n",
    "    for memory_length in [20]:\n",
    "        if PREDICT_PRICES:\n",
    "            OUTPUT_SCALE = (0,1)\n",
    "            x, y = create_batch_xy(\n",
    "                        memory_length,\n",
    "                        transformed_np_arr,\n",
    "                        overlap=True,\n",
    "                        y_updown=False,\n",
    "                        diff_data=True,\n",
    "                        output_scale=OUTPUT_SCALE)\n",
    "        else:\n",
    "            x, x_ts, y = create_transformer_onehot_xy(\n",
    "                                memory_length,\n",
    "                                transformed_np_arr,\n",
    "                                DATAFRAME.to_numpy(),\n",
    "                                DATAFRAME.index.to_numpy(),\n",
    "                                0.01)\n",
    "\n",
    "        split_idx = int(x.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "        x_train = x[:split_idx,:,:]\n",
    "        x_ts_train = x_ts[:split_idx,:,:]\n",
    "        y_train = y[:split_idx,:,:]\n",
    "\n",
    "        x_test = x[split_idx:,:,:]\n",
    "        x_ts_test = x_ts[split_idx:,:,:]\n",
    "        y_test = y[split_idx:,:,:]\n",
    "\n",
    "        if CLASS_FIRST:\n",
    "            y_train = tf.transpose(y_train, (0,2,1))\n",
    "            y_test = tf.transpose(y_test, (0,2,1))\n",
    "\n",
    "        for head_size in [32,16,8]:\n",
    "            for num_heads in [32,16,8]:\n",
    "                for ff_dim in [64,32,16]:\n",
    "                    for num_transformer_blocks in [4,2,1]:\n",
    "                        for mlp_units in [64,32,16]:\n",
    "                            if counter < RESUME:\n",
    "                                counter = counter + 1\n",
    "                                continue\n",
    "                            \n",
    "                            serial = \"transformer_model_\" \\\n",
    "                                + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                            model_dict = {\n",
    "                                \"serial\": serial,\n",
    "                                \"memory_length\": memory_length,\n",
    "                                \"head_size\": head_size,\n",
    "                                \"num_heads\": num_heads,\n",
    "                                \"ff_dim\": ff_dim,\n",
    "                                \"num_transformer_blocks\": num_transformer_blocks,\n",
    "                                \"mlp_units\": mlp_units\n",
    "                            }\n",
    "\n",
    "                            model = create_transformer_model(\n",
    "                                    m=memory_length+1,\n",
    "                                    n=len(SELECTED_TICKERS),\n",
    "                                    output_dim=3,\n",
    "                                    head_size=head_size,\n",
    "                                    num_heads=num_heads,\n",
    "                                    ff_dim=ff_dim,\n",
    "                                    num_transformer_blocks=num_transformer_blocks,\n",
    "                                    mlp_units=(mlp_units,),\n",
    "                                    class_first=CLASS_FIRST\n",
    "                                )\n",
    "                            \n",
    "\n",
    "                            model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                                        loss=MultiSoftmaxLoss(),\n",
    "                                        metrics=METRICS)\n",
    "\n",
    "                            model.fit(x = (x_train,x_ts_train,x_train,x_ts_train),\n",
    "                                    y = y_train,\n",
    "                                    batch_size=32,\n",
    "                                    epochs=25,\n",
    "                                    validation_split=0.25,\n",
    "                                    callbacks=CALLBACKS)\n",
    "                            \n",
    "                            model.save(\"./models/\"+serial+\".keras\")\n",
    "\n",
    "                            model_dict.update(model.evaluate(\n",
    "                                        x = (x_test,x_ts_test,x_test,x_ts_test),\n",
    "                                        y = y_test,\n",
    "                                        batch_size=32,\n",
    "                                        workers=4,\n",
    "                                        use_multiprocessing=True,\n",
    "                                        return_dict=True\n",
    "                                    )\n",
    "                                )\n",
    "                            \n",
    "                            if os.path.exists(\"./transformer_results.json\"):\n",
    "                                with open(\"./transformer_results.json\", \"r\",\n",
    "                                        encoding=ENCODING) as json_file:\n",
    "                                    model_list = json.load(json_file)\n",
    "                                model_list.append(model_dict)\n",
    "                            else:\n",
    "                                model_list = [model_dict]\n",
    "\n",
    "                            with open(\"./transformer_results.json\", \"w\",\n",
    "                                    encoding=ENCODING) as json_file:\n",
    "                                json.dump(model_list, json_file)\n",
    "\n",
    "    if os.path.exists(\"./transformer_results.json\"):\n",
    "        with open(\"./transformer_results.json\", \"r\",\n",
    "                  encoding=ENCODING) as json_file:\n",
    "            model_list = json.load(json_file)\n",
    "    else:\n",
    "        model_list = [{}]\n",
    "    \n",
    "    model_df = pd.DataFrame.from_dict(model_list)\n",
    "    model_df.to_excel(\"./transformer_results.xlsx\")\n",
    "else:\n",
    "    with open(\"./transformer_results.json\", \"r\",\n",
    "              encoding=ENCODING) as json_file:\n",
    "        model_list = json.load(json_file)\n",
    "    model_dict = next(item for item in model_list\n",
    "                      if item[\"serial\"] == MODEL_SERIAL)\n",
    "\n",
    "    memory_length = int(model_dict[\"memory_length\"])\n",
    "\n",
    "    if PREDICT_PRICES:\n",
    "        OUTPUT_SCALE = (0,1)\n",
    "        x, y = create_batch_xy(\n",
    "                    memory_length,\n",
    "                    transformed_np_arr,\n",
    "                    overlap=True,\n",
    "                    y_updown=False,\n",
    "                    diff_data=True,\n",
    "                    output_scale=OUTPUT_SCALE)\n",
    "    else:\n",
    "        x, x_ts, y = create_transformer_onehot_xy(\n",
    "                            memory_length,\n",
    "                            transformed_np_arr,\n",
    "                            DATAFRAME.to_numpy(),\n",
    "                            DATAFRAME.index.to_numpy(),\n",
    "                            0.01)\n",
    "\n",
    "    split_idx = int(x.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "    x_train = x[:split_idx,:,:]\n",
    "    x_ts_train = x_ts[:split_idx,:,:]\n",
    "    y_train = y[:split_idx,:,:]\n",
    "\n",
    "    x_test = x[split_idx:,:,:]\n",
    "    x_ts_test = x_ts[split_idx:,:,:]\n",
    "    y_test = y[split_idx:,:,:]\n",
    "\n",
    "    if CLASS_FIRST:\n",
    "        y_train = tf.transpose(y_train, (0,2,1))\n",
    "        y_test = tf.transpose(y_test, (0,2,1))\n",
    "\n",
    "    model = keras.models.load_model(\"./models/\" + MODEL_SERIAL + \".keras\")\n",
    "\n",
    "plot_model(\n",
    "        model,\n",
    "        to_file=\"./figures/transformer_model_plot.png\",\n",
    "        show_shapes=True,\n",
    "        show_layer_names = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model([x_test, x_ts_test, x_test, x_ts_test], training=False)\n",
    "print(\"Y_pred: \\n\", y_pred)\n",
    "print(\"Y_test: \\n\", y_test)\n",
    "\n",
    "for stock_idx in range(y_pred.shape[2] if CLASS_FIRST else y_pred.shape[1]):\n",
    "    if CLASS_FIRST:\n",
    "        direction_preds = y_pred[:,:,stock_idx]\n",
    "        direction_true = y_test[:,:,stock_idx]\n",
    "    else:\n",
    "        direction_preds = y_pred[:,stock_idx,:]\n",
    "        direction_true = y_test[:,stock_idx,:]\n",
    "\n",
    "    accuracy = \\\n",
    "        np.sum(direction_preds == direction_true) / direction_preds.shape[0]\n",
    "    print(f\"\"\"\n",
    "            Up/Down/Flat accuracy for stock {IND_CONVERSION[stock_idx]}:\n",
    "            {accuracy}\n",
    "            \"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate profit by optimal strategy (theoretical) vs using model to predict\n",
    "test_sz = int(DATAFRAME.shape[0] * TEST_FRAC)\n",
    "df_test = DATAFRAME.iloc[-test_sz:,:].copy()\n",
    "if HAS_TIMEDELTA:\n",
    "    df_test.drop(\"Time Delta\", axis=1, inplace=True)\n",
    "np_arr_test = df_test.to_numpy()\n",
    "print(\"np_arr_test data shape: \", np_arr_test.shape)\n",
    "\n",
    "optimal_trading_mask = calculate_optimal_invest_strategy(np_arr_test)\n",
    "print(f\"Optimal mask 3rd stock: \\n {optimal_trading_mask[:,2]}\")\n",
    "profit_optimal = calculate_profit_on_invest_strategy(np_arr_test,\n",
    "                                                     optimal_trading_mask)\n",
    "print(f\"Optimal strategy matrix shape: {optimal_trading_mask.shape}\")\n",
    "print(f\"Profit by optimal strategy on test data: {profit_optimal}\")\n",
    "\n",
    "# To calculate the mask for the model, we need to give the data in the same format as it was trained in\n",
    "transformed_df_test = transformed_df.iloc[-test_sz:,:]\n",
    "transformed_np_arr_test = transformed_df_test.to_numpy()\n",
    "print(\"transformed_np_arr_test data shape: \", transformed_np_arr_test.shape)\n",
    "print(transformed_np_arr_test[0:2,:])\n",
    "prediction_trading_mask = \\\n",
    "    strategy_mask_from_direction_model(transformed_np_arr_test,\n",
    "                                       memory_length, model,\n",
    "                                       True, df.to_numpy()[-test_sz:,:],\n",
    "                                       df.index.to_numpy()[-test_sz:]\n",
    "                                       )\n",
    "\n",
    "if HAS_TIMEDELTA:\n",
    "    prediction_trading_mask = prediction_trading_mask[:,1:]\n",
    "\n",
    "print(f\"Prediction mask 3rd stock: \\n {prediction_trading_mask[:,2]}\")\n",
    "if HAS_TIMEDELTA:\n",
    "    profit_pred_model = \\\n",
    "        calculate_profit_on_invest_strategy(np_arr_test[:,1:],\n",
    "                                            prediction_trading_mask)\n",
    "else:\n",
    "    profit_pred_model = \\\n",
    "        calculate_profit_on_invest_strategy(np_arr_test,\n",
    "                                            prediction_trading_mask)\n",
    "\n",
    "print(f\"Prediction strategy matrix shape: {prediction_trading_mask.shape}\")\n",
    "print(\n",
    "    f\"Profit by predicting the next hour using the model: {profit_pred_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_indices = np.random.choice(np.arange(len(IND_CONVERSION)), 4,\n",
    "                                 replace=False)\n",
    "part_mask = prediction_trading_mask[:,stock_indices]\n",
    "\n",
    "if HAS_TIMEDELTA:\n",
    "    part_price = np_arr_test[:,1:][:,stock_indices]\n",
    "else:\n",
    "    part_price = np_arr_test[:,stock_indices]\n",
    "\n",
    "ind_conversion = {si : IND_CONVERSION[i] for si, i in enumerate(stock_indices)}\n",
    "plot_mask_and_data(part_mask, part_price, ind_conversion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stonks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
