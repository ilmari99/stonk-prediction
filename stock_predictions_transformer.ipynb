{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import locale\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from stock_modules.stock_transform import (create_batch_xy,\n",
    "                                           create_transformer_onehot_xy)\n",
    "\n",
    "from stock_modules.stock_ml import (create_transformer_model,\n",
    "                                    MultiSoftmaxLoss, MultiAccuracy)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from invest_strategies import (calculate_optimal_invest_strategy,\n",
    "                               calculate_profit_on_invest_strategy,\n",
    "                               strategy_mask_from_direction_model)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "from stock_modules.stock_plot import plot_mask_and_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = locale.getpreferredencoding()\n",
    "DF_PATH = \"HEL_12-10-21to08-11-23.csv\"\n",
    "MODEL_SERIAL = None\n",
    "SELECTED_TICKERS_PATH = \"./TICKERS_TO_FOLLOW.json\"\n",
    "\n",
    "TEST_FRAC = 0.2\n",
    "PREDICT_PRICES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_TICKERS = json.load(open(SELECTED_TICKERS_PATH,\n",
    "                                  \"r\", encoding=ENCODING))\n",
    "DATAFRAME = pd.read_csv(DF_PATH, encoding=ENCODING)\n",
    "\n",
    "DATAFRAME.set_index(\"date\", inplace=True)\n",
    "HAS_TIMEDELTA = \"Time Delta\" in DATAFRAME.columns\n",
    "\n",
    "# ind transformation tells the label of each index in the np_arr_test\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(DATAFRAME.columns) if ticker in SELECTED_TICKERS}\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(IND_CONVERSION.values())}\n",
    "\n",
    "print(\"Selected tickers: \\n\", SELECTED_TICKERS)\n",
    "print(\"Dataframe columns: \\n\", DATAFRAME.columns)\n",
    "print(\"Dataframe shape: \", DATAFRAME.shape)\n",
    "print(\"Dataframe head: \\n\", DATAFRAME.head(2))\n",
    "print(f\"Index conversion: \\n {IND_CONVERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_begin_idx = int(DATAFRAME.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "if PREDICT_PRICES:\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaler.fit(DATAFRAME.iloc[:test_begin_idx, :])\n",
    "    transformed_df = pd.DataFrame(scaler.transform(DATAFRAME), columns=DATAFRAME.columns, index=DATAFRAME.index)\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            return pd.DataFrame(scaler.inverse_transform(df), columns=df.columns, index=df.index)\n",
    "        elif isinstance(df, np.ndarray):\n",
    "            return scaler.inverse_transform(df)\n",
    "\n",
    "# If we are predicting the up/down, we create a dataframe where we subtract the previous value from the current value\n",
    "else:\n",
    "    # Do not diff the Time Delta column\n",
    "    df = DATAFRAME.copy()\n",
    "    if HAS_TIMEDELTA:\n",
    "        td_col = df[\"Time Delta\"]\n",
    "        df.drop(\"Time Delta\", axis=1, inplace=True)\n",
    "    transformed_df = df.diff()\n",
    "    # The first row is NaN, so lets copy the second row there\n",
    "    transformed_df.iloc[0, :] = transformed_df.iloc[1, :]\n",
    "    # Add back the Time Delta column\n",
    "    if HAS_TIMEDELTA:\n",
    "        transformed_df[\"Time Delta\"] = td_col\n",
    "        # Make Time Delta the first column\n",
    "        cols = transformed_df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        transformed_df = transformed_df[cols]\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        return df\n",
    "\n",
    "print(\"Transformed df: \\n\", transformed_df.head(2))\n",
    "print(\"Transformed df shape: \", transformed_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./models/\"):\n",
    "    os.makedirs(\"./models/\")\n",
    "\n",
    "METRICS = [MultiAccuracy()]\n",
    "CALLBACKS = [keras.callbacks.EarlyStopping(patience=10,\n",
    "                                           restore_best_weights=True)]\n",
    "CLASS_FIRST = True\n",
    "\n",
    "if MODEL_SERIAL is None:\n",
    "    counter = 0\n",
    "    RESUME = 0\n",
    "\n",
    "    for memory_length in [10,50,200]:\n",
    "        if PREDICT_PRICES:\n",
    "            OUTPUT_SCALE = (0,1)\n",
    "            x, y = create_batch_xy(\n",
    "                        memory_length,\n",
    "                        transformed_np_arr,\n",
    "                        overlap=True,\n",
    "                        y_updown=False,\n",
    "                        diff_data=True,\n",
    "                        output_scale=OUTPUT_SCALE)\n",
    "        else:\n",
    "            x, x_ts, y = create_transformer_onehot_xy(\n",
    "                                memory_length,\n",
    "                                transformed_np_arr,\n",
    "                                DATAFRAME.to_numpy(),\n",
    "                                DATAFRAME.index.to_numpy(),\n",
    "                                0.01)\n",
    "\n",
    "        split_idx = int(x.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "        x_train = x[:split_idx,:,:]\n",
    "        x_ts_train = x_ts[:split_idx,:,:]\n",
    "        y_train = y[:split_idx,:,:]\n",
    "\n",
    "        x_test = x[split_idx:,:,:]\n",
    "        x_ts_test = x_ts[split_idx:,:,:]\n",
    "        y_test = y[split_idx:,:,:]\n",
    "\n",
    "        if CLASS_FIRST:\n",
    "            y_train = tf.transpose(y_train, (0,2,1))\n",
    "            y_test = tf.transpose(y_test, (0,2,1))\n",
    "\n",
    "        for head_size in [32,16,8]:\n",
    "            for num_heads in [32,16,8]:\n",
    "                for ff_dim in [64,32,16]:\n",
    "                    for num_transformer_blocks in [4,2,1]:\n",
    "                        for mlp_units in [64,32,16]:\n",
    "                            if counter < RESUME:\n",
    "                                counter = counter + 1\n",
    "                                continue\n",
    "                            \n",
    "                            serial = \"transformer_model_\" \\\n",
    "                                + datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                            model_dict = {\n",
    "                                \"serial\": serial,\n",
    "                                \"memory_length\": memory_length,\n",
    "                                \"head_size\": head_size,\n",
    "                                \"num_heads\": num_heads,\n",
    "                                \"ff_dim\": ff_dim,\n",
    "                                \"num_transformer_blocks\": num_transformer_blocks,\n",
    "                                \"mlp_units\": mlp_units\n",
    "                            }\n",
    "\n",
    "                            model = create_transformer_model(\n",
    "                                    m=memory_length+1,\n",
    "                                    n=len(SELECTED_TICKERS),\n",
    "                                    output_dim=3,\n",
    "                                    head_size=head_size,\n",
    "                                    num_heads=num_heads,\n",
    "                                    ff_dim=ff_dim,\n",
    "                                    num_transformer_blocks=num_transformer_blocks,\n",
    "                                    mlp_units=(mlp_units,),\n",
    "                                    class_first=CLASS_FIRST\n",
    "                                )\n",
    "                            \n",
    "\n",
    "                            model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                                        loss=MultiSoftmaxLoss(),\n",
    "                                        metrics=METRICS)\n",
    "\n",
    "                            model.fit(x = (x_train,x_ts_train,x_train,x_ts_train),\n",
    "                                    y = y_train,\n",
    "                                    batch_size=32,\n",
    "                                    epochs=100,\n",
    "                                    validation_split=0.25,\n",
    "                                    callbacks=CALLBACKS)\n",
    "                            \n",
    "                            model.save(\"./models/\"+serial+\".keras\")\n",
    "\n",
    "                            model_dict.update(model.evaluate(\n",
    "                                        x = (x_test,x_ts_test,x_test,x_ts_test),\n",
    "                                        y = y_test,\n",
    "                                        batch_size=32,\n",
    "                                        workers=4,\n",
    "                                        use_multiprocessing=True,\n",
    "                                        return_dict=True\n",
    "                                    )\n",
    "                                )\n",
    "                            \n",
    "                            if os.path.exists(\"./transformer_results.json\"):\n",
    "                                with open(\"./transformer_results.json\", \"r\",\n",
    "                                        encoding=ENCODING) as json_file:\n",
    "                                    model_list = json.load(json_file)\n",
    "                            else:\n",
    "                                model_list = [model_dict]\n",
    "                            \n",
    "                            with open(\"./transformer_results.json\", \"w\",\n",
    "                                    encoding=ENCODING) as json_file:\n",
    "                                json.dump(model_list, json_file)\n",
    "else:\n",
    "    with open(\"./transformer_results.json\", \"r\",\n",
    "              encoding=ENCODING) as json_file:\n",
    "        model_list = json.load(json_file)\n",
    "    model_dict = next(item for item in model_list\n",
    "                      if item[\"serial\"] == MODEL_SERIAL)\n",
    "\n",
    "    memory_length = model_list[\"memory_length\"]\n",
    "\n",
    "    if PREDICT_PRICES:\n",
    "        OUTPUT_SCALE = (0,1)\n",
    "        x, y = create_batch_xy(\n",
    "                    memory_length,\n",
    "                    transformed_np_arr,\n",
    "                    overlap=True,\n",
    "                    y_updown=False,\n",
    "                    diff_data=True,\n",
    "                    output_scale=OUTPUT_SCALE)\n",
    "    else:\n",
    "        x, x_ts, y = create_transformer_onehot_xy(\n",
    "                            memory_length,\n",
    "                            transformed_np_arr,\n",
    "                            DATAFRAME.to_numpy(),\n",
    "                            DATAFRAME.index.to_numpy(),\n",
    "                            0.01)\n",
    "\n",
    "    split_idx = int(x.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "    x_train = x[:split_idx,:,:]\n",
    "    x_ts_train = x_ts[:split_idx,:,:]\n",
    "    y_train = y[:split_idx,:,:]\n",
    "\n",
    "    x_test = x[split_idx:,:,:]\n",
    "    x_ts_test = x_ts[split_idx:,:,:]\n",
    "    y_test = y[split_idx:,:,:]\n",
    "\n",
    "    if CLASS_FIRST:\n",
    "        y_train = tf.transpose(y_train, (0,2,1))\n",
    "        y_test = tf.transpose(y_test, (0,2,1))\n",
    "\n",
    "    model = keras.models.load_model(\"./models/\" + MODEL_SERIAL + \".keras\")\n",
    "\n",
    "plot_model(\n",
    "        model,\n",
    "        to_file=\"./figures/transformer_model_plot.png\",\n",
    "        show_shapes=True,\n",
    "        show_layer_names = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_train, training=False)\n",
    "print(\"Y_pred: \\n\", y_pred)\n",
    "print(\"Y_test: \\n\", y_test)\n",
    "\n",
    "for stock_idx in range(y_pred.shape[2] if CLASS_FIRST else y_pred.shape[1]):\n",
    "    if CLASS_FIRST:\n",
    "        direction_preds = y_pred[:,:,stock_idx]\n",
    "        direction_true = y_test[:,:,stock_idx]\n",
    "    else:\n",
    "        direction_preds = y_pred[:,stock_idx,:]\n",
    "        direction_true = y_test[:,stock_idx,:]\n",
    "\n",
    "    accuracy = \\\n",
    "        np.sum(direction_preds == direction_true) / direction_preds.shape[0]\n",
    "    print(f\"\"\"\n",
    "            Up/Down/Flat accuracy for stock {IND_CONVERSION[stock_idx]}:\n",
    "            {accuracy}\n",
    "            \"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate profit by optimal strategy (theoretical) vs using model to predict\n",
    "test_sz = int(DATAFRAME.shape[0] * TEST_FRAC)\n",
    "df_test = DATAFRAME.iloc[-test_sz:,:].copy()\n",
    "if HAS_TIMEDELTA:\n",
    "    df_test.drop(\"Time Delta\", axis=1, inplace=True)\n",
    "np_arr_test = df_test.to_numpy()\n",
    "print(\"np_arr_test data shape: \", np_arr_test.shape)\n",
    "\n",
    "optimal_trading_mask = calculate_optimal_invest_strategy(np_arr_test)\n",
    "print(f\"Optimal mask 3rd stock: \\n {optimal_trading_mask[:,2]}\")\n",
    "profit_optimal = calculate_profit_on_invest_strategy(np_arr_test,\n",
    "                                                     optimal_trading_mask)\n",
    "print(f\"Optimal strategy matrix shape: {optimal_trading_mask.shape}\")\n",
    "print(f\"Profit by optimal strategy on test data: {profit_optimal}\")\n",
    "\n",
    "# To calculate the mask for the model, we need to give the data in the same format as it was trained in\n",
    "transformed_df_test = transformed_df.iloc[-test_sz:,:]\n",
    "transformed_np_arr_test = transformed_df_test.to_numpy()\n",
    "print(\"transformed_np_arr_test data shape: \", transformed_np_arr_test.shape)\n",
    "print(transformed_np_arr_test[0:2,:])\n",
    "prediction_trading_mask = \\\n",
    "    strategy_mask_from_direction_model(transformed_np_arr_test,\n",
    "                                       memory_length, model)\n",
    "\n",
    "if HAS_TIMEDELTA:\n",
    "    prediction_trading_mask = prediction_trading_mask[:,1:]\n",
    "\n",
    "print(f\"Prediction mask 3rd stock: \\n {prediction_trading_mask[:,2]}\")\n",
    "if HAS_TIMEDELTA:\n",
    "    profit_pred_model = \\\n",
    "        calculate_profit_on_invest_strategy(np_arr_test[:,1:],\n",
    "                                            prediction_trading_mask)\n",
    "else:\n",
    "    profit_pred_model = \\\n",
    "        calculate_profit_on_invest_strategy(np_arr_test,\n",
    "                                            prediction_trading_mask)\n",
    "\n",
    "print(f\"Prediction strategy matrix shape: {prediction_trading_mask.shape}\")\n",
    "print(\n",
    "    f\"Profit by predicting the next hour using the model: {profit_pred_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_indices = np.random.choice(np.arange(len(IND_CONVERSION)), 4,\n",
    "                                 replace=False)\n",
    "part_mask = prediction_trading_mask[:,stock_indices]\n",
    "\n",
    "if HAS_TIMEDELTA:\n",
    "    part_price = np_arr_test[:,1:][:,stock_indices]\n",
    "else:\n",
    "    part_price = np_arr_test[:,stock_indices]\n",
    "\n",
    "ind_conversion = {si : IND_CONVERSION[i] for si, i in enumerate(stock_indices)}\n",
    "plot_mask_and_data(part_mask, part_price, ind_conversion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stonks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
