{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import locale\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from stock_modules.stock_transform import (create_batch_xy,\n",
    "                                           create_transformer_onehot_xy)\n",
    "\n",
    "from stock_modules.stock_ml import create_transformer_model\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = locale.getpreferredencoding()\n",
    "DF_PATH = \"HEL_12-10-21to08-11-23.csv\"\n",
    "HISTORY_ARRAY_PATH = \"./histories_arr.npy\"\n",
    "MODEL_PATH = \"./model.h5\"\n",
    "SELECTED_TICKERS_PATH = \"./TICKERS_TO_FOLLOW.json\"\n",
    "\n",
    "TEST_FRAC = 0.2\n",
    "PREDICT_PRICES = False\n",
    "\n",
    "MHOURS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected tickers: \n",
      " ['ALBBV.HE', 'CGCBV.HE', 'EQV1V.HE', 'KNEBV.HE', 'ORNBV.HE', 'OLVAS.HE', 'DETEC.HE', 'PON1V.HE', 'ORNAV.HE', 'VALMT.HE', 'NESTE.HE', 'HUH1V.HE', 'REG1V.HE', 'VAIAS.HE']\n",
      "Dataframe columns: \n",
      " Index(['REG1V.HE', 'NESTE.HE', 'ORNBV.HE', 'KNEBV.HE', 'OLVAS.HE', 'HUH1V.HE',\n",
      "       'DETEC.HE', 'ORNAV.HE', 'CGCBV.HE', 'VAIAS.HE', 'ALBBV.HE', 'VALMT.HE',\n",
      "       'EQV1V.HE', 'PON1V.HE'],\n",
      "      dtype='object')\n",
      "Dataframe shape:  (4389, 14)\n",
      "Dataframe head: \n",
      "                       REG1V.HE   NESTE.HE   ORNBV.HE   KNEBV.HE   OLVAS.HE  \\\n",
      "date                                                                         \n",
      "2021-10-12 07:00:00  55.950001  41.820000  35.689999  60.220001  53.099998   \n",
      "2021-10-12 08:00:00  55.799999  41.720001  35.630001  60.419998  53.299999   \n",
      "\n",
      "                      HUH1V.HE  DETEC.HE   ORNAV.HE   CGCBV.HE   VAIAS.HE  \\\n",
      "date                                                                        \n",
      "2021-10-12 07:00:00  38.529999      23.0  38.049999  43.139999  46.150002   \n",
      "2021-10-12 08:00:00  38.560001      23.0  38.049999  43.500000  45.950001   \n",
      "\n",
      "                      ALBBV.HE   VALMT.HE   EQV1V.HE   PON1V.HE  \n",
      "date                                                             \n",
      "2021-10-12 07:00:00  28.700001  36.459999  24.850000  39.150002  \n",
      "2021-10-12 08:00:00  28.799999  36.599998  24.950001  39.200001  \n",
      "Index conversion: \n",
      " {0: 'REG1V.HE', 1: 'NESTE.HE', 2: 'ORNBV.HE', 3: 'KNEBV.HE', 4: 'OLVAS.HE', 5: 'HUH1V.HE', 6: 'DETEC.HE', 7: 'ORNAV.HE', 8: 'CGCBV.HE', 9: 'VAIAS.HE', 10: 'ALBBV.HE', 11: 'VALMT.HE', 12: 'EQV1V.HE', 13: 'PON1V.HE'}\n"
     ]
    }
   ],
   "source": [
    "SELECTED_TICKERS = json.load(open(SELECTED_TICKERS_PATH,\n",
    "                                  \"r\", encoding=ENCODING))\n",
    "DATAFRAME = pd.read_csv(DF_PATH, encoding=ENCODING)\n",
    "\n",
    "DATAFRAME.set_index(\"date\", inplace=True)\n",
    "HAS_TIMEDELTA = \"Time Delta\" in DATAFRAME.columns\n",
    "\n",
    "# ind transformation tells the label of each index in the np_arr_test\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(DATAFRAME.columns) if ticker in SELECTED_TICKERS}\n",
    "IND_CONVERSION = {i: ticker for i, ticker in enumerate(IND_CONVERSION.values())}\n",
    "\n",
    "print(\"Selected tickers: \\n\", SELECTED_TICKERS)\n",
    "print(\"Dataframe columns: \\n\", DATAFRAME.columns)\n",
    "print(\"Dataframe shape: \", DATAFRAME.shape)\n",
    "print(\"Dataframe head: \\n\", DATAFRAME.head(2))\n",
    "print(f\"Index conversion: \\n {IND_CONVERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed df: \n",
      "                      REG1V.HE  NESTE.HE  ORNBV.HE  KNEBV.HE  OLVAS.HE  \\\n",
      "date                                                                    \n",
      "2021-10-12 07:00:00 -0.150002 -0.099998 -0.059998  0.199997  0.200001   \n",
      "2021-10-12 08:00:00 -0.150002 -0.099998 -0.059998  0.199997  0.200001   \n",
      "\n",
      "                     HUH1V.HE  DETEC.HE  ORNAV.HE  CGCBV.HE  VAIAS.HE  \\\n",
      "date                                                                    \n",
      "2021-10-12 07:00:00  0.030003       0.0       0.0  0.360001 -0.200001   \n",
      "2021-10-12 08:00:00  0.030003       0.0       0.0  0.360001 -0.200001   \n",
      "\n",
      "                     ALBBV.HE  VALMT.HE  EQV1V.HE  PON1V.HE  \n",
      "date                                                         \n",
      "2021-10-12 07:00:00  0.099998  0.139999       0.1  0.049999  \n",
      "2021-10-12 08:00:00  0.099998  0.139999       0.1  0.049999  \n",
      "Transformed df shape:  (4389, 14)\n"
     ]
    }
   ],
   "source": [
    "test_begin_idx = int(DATAFRAME.shape[0] * (1 - TEST_FRAC))\n",
    "\n",
    "if PREDICT_PRICES:\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaler.fit(DATAFRAME.iloc[:test_begin_idx, :])\n",
    "    transformed_df = pd.DataFrame(scaler.transform(DATAFRAME), columns=DATAFRAME.columns, index=DATAFRAME.index)\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            return pd.DataFrame(scaler.inverse_transform(df), columns=df.columns, index=df.index)\n",
    "        elif isinstance(df, np.ndarray):\n",
    "            return scaler.inverse_transform(df)\n",
    "\n",
    "# If we are predicting the up/down, we create a dataframe where we subtract the previous value from the current value\n",
    "else:\n",
    "    # Do not diff the Time Delta column\n",
    "    df = DATAFRAME.copy()\n",
    "    if HAS_TIMEDELTA:\n",
    "        td_col = df[\"Time Delta\"]\n",
    "        df.drop(\"Time Delta\", axis=1, inplace=True)\n",
    "    transformed_df = df.diff()\n",
    "    # The first row is NaN, so lets copy the second row there\n",
    "    transformed_df.iloc[0, :] = transformed_df.iloc[1, :]\n",
    "    # Add back the Time Delta column\n",
    "    if HAS_TIMEDELTA:\n",
    "        transformed_df[\"Time Delta\"] = td_col\n",
    "        # Make Time Delta the first column\n",
    "        cols = transformed_df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        transformed_df = transformed_df[cols]\n",
    "    transformed_np_arr = transformed_df.to_numpy()\n",
    "\n",
    "    def inverse_transform(df):\n",
    "        return df\n",
    "\n",
    "print(\"Transformed df: \\n\", transformed_df.head(2))\n",
    "print(\"Transformed df shape: \", transformed_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.base.Index'>\n",
      "X shape: (4377, 13, 14)\n",
      "X timestamps shape:  (4377, 13, 4)\n",
      "Y shape: (4377, 14, 3)\n"
     ]
    }
   ],
   "source": [
    "if PREDICT_PRICES:\n",
    "    OUTPUT_SCALE = (0,1)\n",
    "    X, Y = create_batch_xy(MHOURS, transformed_np_arr, overlap=True, y_updown=False, diff_data=True, output_scale=OUTPUT_SCALE)\n",
    "else:\n",
    "    print(type(DATAFRAME.index))\n",
    "    X, X_MARK, Y = create_transformer_onehot_xy(MHOURS,\n",
    "                        transformed_np_arr,\n",
    "                        DATAFRAME.to_numpy(),\n",
    "                        DATAFRAME.index.to_numpy(),\n",
    "                        0.01)\n",
    "\n",
    "split_idx = test_begin_idx - MHOURS\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"X timestamps shape: \", X_MARK.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "x_train = X[:split_idx,:,:]\n",
    "x_mark_train = X_MARK[:split_idx,:,:]\n",
    "y_train = Y[:split_idx,:,:]\n",
    "\n",
    "x_test = X[split_idx:,:,:]\n",
    "x_mark_test = X_MARK[split_idx:,:,:]\n",
    "y_test = Y[split_idx:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 8s 38ms/step - loss: 2.4349 - categorical_crossentropy: 2.4349 - categorical_accuracy: 0.4496 - val_loss: 0.5335 - val_categorical_crossentropy: 0.5335 - val_categorical_accuracy: 0.6839\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 0.6095 - categorical_crossentropy: 0.6095 - categorical_accuracy: 0.6600 - val_loss: 0.5192 - val_categorical_crossentropy: 0.5192 - val_categorical_accuracy: 0.6833\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.5645 - categorical_crossentropy: 0.5645 - categorical_accuracy: 0.6586 - val_loss: 0.4317 - val_categorical_crossentropy: 0.4317 - val_categorical_accuracy: 0.6838\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.5534 - categorical_crossentropy: 0.5534 - categorical_accuracy: 0.6582 - val_loss: 0.4264 - val_categorical_crossentropy: 0.4264 - val_categorical_accuracy: 0.6835\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.5413 - categorical_crossentropy: 0.5413 - categorical_accuracy: 0.6586 - val_loss: 0.4226 - val_categorical_crossentropy: 0.4226 - val_categorical_accuracy: 0.6838\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 0.5374 - categorical_crossentropy: 0.5374 - categorical_accuracy: 0.6584 - val_loss: 0.4194 - val_categorical_crossentropy: 0.4194 - val_categorical_accuracy: 0.6836\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.5361 - categorical_crossentropy: 0.5361 - categorical_accuracy: 0.6579 - val_loss: 0.4146 - val_categorical_crossentropy: 0.4146 - val_categorical_accuracy: 0.6838\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.5346 - categorical_crossentropy: 0.5346 - categorical_accuracy: 0.6581 - val_loss: 0.4147 - val_categorical_crossentropy: 0.4147 - val_categorical_accuracy: 0.6842\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.5338 - categorical_crossentropy: 0.5338 - categorical_accuracy: 0.6579 - val_loss: 0.4122 - val_categorical_crossentropy: 0.4122 - val_categorical_accuracy: 0.6848\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 0.5337 - categorical_crossentropy: 0.5337 - categorical_accuracy: 0.6574 - val_loss: 0.4039 - val_categorical_crossentropy: 0.4039 - val_categorical_accuracy: 0.6851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fe094428390>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_transformer_model(m = MHOURS+1,\n",
    "                                 n = len(SELECTED_TICKERS),\n",
    "                                 output_dim = 3)\n",
    "plot_model(model, to_file=\"./figures/model_plot.png\",\n",
    "           show_shapes=True, show_layer_names = True)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.CategoricalCrossentropy(),\n",
    "                       keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "model.fit(x = (x_train,x_mark_train,x_train,x_mark_train),\n",
    "          y = y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_split=0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stonks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
